# Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÚ¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import logging
from pathlib import Path
import json

logger = logging.getLogger(__name__)

class DataProcessor:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÚ¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹ØµØ¨ÛŒ"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.feature_scalers = {}
        logger.info("âœ… Data Processor initialized")
    
    def process_market_data(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ"""
        try:
            processed = {
                'symbol': raw_data.get('symbol', 'UNKNOWN'),
                'timestamp': datetime.now().isoformat(),
                'features': {},
                'metadata': {}
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            market_data = raw_data.get('market_data', {})
            
            # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª
            processed['features']['price'] = market_data.get('price', 0)
            processed['features']['price_change_24h'] = market_data.get('priceChange1d', 0)
            processed['features']['volume'] = market_data.get('volume', 0)
            processed['features']['market_cap'] = market_data.get('marketCap', 0)
            processed['features']['rank'] = market_data.get('rank', 100)
            
            # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
            technical_features = self._extract_technical_features(raw_data)
            processed['features'].update(technical_features)
            
            # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ
            time_features = self._extract_time_features()
            processed['features'].update(time_features)
            
            # Ù…ØªØ§Ø¯ÛŒØªØ§
            processed['metadata']['data_quality'] = self._assess_data_quality(processed['features'])
            processed['metadata']['feature_count'] = len(processed['features'])
            processed['metadata']['processing_time'] = datetime.now().isoformat()
            
            return processed
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±: {e}")
            return self._get_default_processed_data()
    
    def _extract_technical_features(self, raw_data: Dict[str, Any]) -> Dict[str, float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„"""
        try:
            features = {}
            market_data = raw_data.get('market_data', {})
            
            # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ
            price_charts = raw_data.get('price_charts', {})
            prices = price_charts.get('prices', [])
            
            if prices and len(prices) > 10:
                price_values = [p[1] for p in prices if len(p) > 1]  # Ù…Ù‚Ø¯Ø§Ø± Ù‚ÛŒÙ…Øª
                
                if len(price_values) >= 20:
                    # Ù†ÙˆØ³Ø§Ù†
                    features['volatility'] = self._calculate_volatility(price_values[-20:])
                    
                    # Ø±ÙˆÙ†Ø¯
                    trend_info = self._calculate_trend(price_values[-50:])
                    features['trend_strength'] = trend_info['strength']
                    features['trend_direction'] = trend_info['direction']
                    
                    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú©
                    features['sma_20'] = self._calculate_sma(price_values, 20)
                    features['sma_50'] = self._calculate_sma(price_values, 50)
                    
                    # RSI Ø³Ø§Ø¯Ù‡
                    features['rsi'] = self._calculate_simple_rsi(price_values[-15:])
                else:
                    # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ
                    features.update({
                        'volatility': 0.0,
                        'trend_strength': 0.0,
                        'trend_direction': 0.0,
                        'sma_20': market_data.get('price', 0),
                        'sma_50': market_data.get('price', 0),
                        'rsi': 50.0
                    })
            else:
                # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                features.update({
                    'volatility': 0.0,
                    'trend_strength': 0.0,
                    'trend_direction': 0.0,
                    'sma_20': market_data.get('price', 0),
                    'sma_50': market_data.get('price', 0),
                    'rsi': 50.0
                })
            
            return features
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„: {e}")
            return {}
    
    def _calculate_volatility(self, prices: List[float]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ÙˆØ³Ø§Ù†"""
        try:
            if len(prices) < 2:
                return 0.0
            
            returns = np.diff(prices) / prices[:-1]
            return float(np.std(returns) * 100)  # Ø¯Ø±ØµØ¯
            
        except:
            return 0.0
    
    def _calculate_trend(self, prices: List[float]) -> Dict[str, float]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯"""
        try:
            if len(prices) < 10:
                return {'strength': 0.0, 'direction': 0.0}
            
            x = np.arange(len(prices))
            slope, _ = np.polyfit(x, prices, 1)
            
            strength = abs(slope) / (np.std(prices) + 1e-8)
            direction = 1.0 if slope > 0 else -1.0 if slope < 0 else 0.0
            
            return {
                'strength': float(min(strength, 1.0)),
                'direction': direction
            }
            
        except:
            return {'strength': 0.0, 'direction': 0.0}
    
    def _calculate_sma(self, prices: List[float], period: int) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø³Ø§Ø¯Ù‡"""
        try:
            if len(prices) < period:
                return float(prices[-1]) if prices else 0.0
            return float(np.mean(prices[-period:]))
        except:
            return 0.0
    
    def _calculate_simple_rsi(self, prices: List[float]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI Ø³Ø§Ø¯Ù‡"""
        try:
            if len(prices) < 2:
                return 50.0
            
            gains = []
            losses = []
            
            for i in range(1, len(prices)):
                change = prices[i] - prices[i-1]
                if change > 0:
                    gains.append(change)
                else:
                    losses.append(abs(change))
            
            avg_gain = np.mean(gains) if gains else 0
            avg_loss = np.mean(losses) if losses else 0
            
            if avg_loss == 0:
                return 100.0
            
            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs))
            
            return float(rsi)
            
        except:
            return 50.0
    
    def _extract_time_features(self) -> Dict[str, float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ"""
        try:
            now = datetime.now()
            
            return {
                'day_of_week': now.weekday() / 6.0,  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
                'hour_of_day': now.hour / 23.0,      # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
                'is_weekend': 1.0 if now.weekday() >= 5 else 0.0,
                'market_hours': 1.0 if 9 <= now.hour <= 17 else 0.0
            }
            
        except:
            return {}
    
    def _assess_data_quality(self, features: Dict[str, float]) -> str:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        try:
            missing_count = sum(1 for v in features.values() if v == 0)
            total_count = len(features)
            
            quality_ratio = (total_count - missing_count) / total_count
            
            if quality_ratio >= 0.9:
                return 'EXCELLENT'
            elif quality_ratio >= 0.7:
                return 'GOOD'
            elif quality_ratio >= 0.5:
                return 'FAIR'
            else:
                return 'POOR'
                
        except:
            return 'UNKNOWN'
    
    def _get_default_processed_data(self) -> Dict[str, Any]:
        """Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶"""
        return {
            'symbol': 'UNKNOWN',
            'timestamp': datetime.now().isoformat(),
            'features': {
                'price': 0.0,
                'price_change_24h': 0.0,
                'volume': 0.0,
                'market_cap': 0.0,
                'rank': 100.0,
                'volatility': 0.0,
                'trend_strength': 0.0,
                'trend_direction': 0.0,
                'sma_20': 0.0,
                'sma_50': 0.0,
                'rsi': 50.0,
                'day_of_week': 0.0,
                'hour_of_day': 0.0,
                'is_weekend': 0.0,
                'market_hours': 0.0
            },
            'metadata': {
                'data_quality': 'POOR',
                'feature_count': 15,
                'processing_time': datetime.now().isoformat(),
                'error': True
            }
        }
    
    def normalize_features(self, features: Dict[str, float]) -> Dict[str, float]:
        """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"""
        try:
            normalized = {}
            
            for key, value in features.items():
                if key in ['price', 'volume', 'market_cap']:
                    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù„Ú¯Ø§Ø±ÛŒØªÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø²Ø±Ú¯
                    normalized[key] = np.log(value + 1) / 20
                elif key in ['price_change_24h', 'volatility']:
                    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±ØµØ¯ÛŒ
                    normalized[key] = value / 100
                elif key in ['rsi']:
                    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ RSI
                    normalized[key] = value / 100
                elif key in ['rank']:
                    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø±ØªØ¨Ù‡
                    normalized[key] = value / 100
                elif key in ['trend_strength']:
                    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù‚Ø¯Ø±Øª Ø±ÙˆÙ†Ø¯
                    normalized[key] = min(value, 1.0)
                else:
                    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                    normalized[key] = value
            
            return normalized
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {e}")
            return features
    
    def create_feature_vector(self, processed_data: Dict[str, Any]) -> List[float]:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ"""
        try:
            features = processed_data.get('features', {})
            normalized_features = self.normalize_features(features)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù„ÛŒØ³Øª
            feature_vector = list(normalized_features.values())
            
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø·ÙˆÙ„ Ø«Ø§Ø¨Øª
            expected_length = 20
            if len(feature_vector) < expected_length:
                # Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¨Ø§ ØµÙØ±
                feature_vector.extend([0.0] * (expected_length - len(feature_vector)))
            elif len(feature_vector) > expected_length:
                # Ù‚Ø·Ø¹ Ú©Ø±Ø¯Ù†
                feature_vector = feature_vector[:expected_length]
            
            return feature_vector
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ: {e}")
            return [0.0] * 20
    
    def save_processed_data(self, processed_data: Dict[str, Any], filepath: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡"""
        try:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ðŸ’¾ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¯Ø± {filepath} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
    
    def load_processed_data(self, filepath: str) -> Dict[str, Any]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"ðŸ“‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø§Ø² {filepath} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            return data
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
            return self._get_default_processed_data()
