# Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import logging
from pathlib import Path
import json

logger = logging.getLogger(__name__)

class ModelTrainer:
    """Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ"""
    
    def __init__(self, neural_network, config=None):
        self.neural_network = neural_network
        self.config = config or {}
        self.training_data = []
        self.validation_data = []
        logger.info("âœ… Model Trainer initialized")
    
    def prepare_training_data(self, market_data: List[Dict[str, Any]]) -> Tuple[np.ndarray, np.ndarray]:
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´"""
        try:
            features = []
            labels = []
            
            for data in market_data:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
                feature_vector = self._extract_features(data)
                features.append(feature_vector)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
                label_vector = self._create_label(data)
                labels.append(label_vector)
            
            return np.array(features), np.array(labels)
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {e}")
            return np.array([]), np.array([])
    
    def _extract_features(self, market_data: Dict[str, Any]) -> List[float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±"""
        try:
            features = []
            
            # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            price = market_data.get('price', 0)
            price_change = market_data.get('priceChange1d', 0)
            volume = market_data.get('volume', 0)
            market_cap = market_data.get('marketCap', 0)
            rank = market_data.get('rank', 100)
            
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù†
            features.extend([
                price / 100000,
                price_change / 100,
                np.log(volume + 1) / 20,
                np.log(market_cap + 1) / 25,
                rank / 100
            ])
            
            # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
            if 'historical_prices' in market_data:
                prices = market_data['historical_prices']
                if len(prices) >= 20:
                    # Ù†ÙˆØ³Ø§Ù†
                    returns = np.diff(prices) / prices[:-1]
                    volatility = np.std(returns) * 100 if len(returns) > 0 else 0
                    features.append(volatility / 50)
                    
                    # Ø±ÙˆÙ†Ø¯
                    if len(prices) >= 50:
                        trend_slope = self._calculate_trend_slope(prices[-50:])
                        features.append(trend_slope)
                    else:
                        features.append(0.0)
                else:
                    features.extend([0.0, 0.0])
            else:
                features.extend([0.0, 0.0])
            
            # Ù¾Ø± Ú©Ø±Ø¯Ù† ØªØ§ Û²Û° ÙˆÛŒÚ˜Ú¯ÛŒ
            while len(features) < 20:
                features.append(0.0)
            
            return features[:20]
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {e}")
            return [0.0] * 20
    
    def _calculate_trend_slope(self, prices: List[float]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÛŒØ¨ Ø±ÙˆÙ†Ø¯"""
        try:
            x = np.arange(len(prices))
            slope, _ = np.polyfit(x, prices, 1)
            return float(slope / (np.std(prices) + 1e-8))
        except:
            return 0.0
    
    def _create_label(self, market_data: Dict[str, Any]) -> List[float]:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ø±Ú†Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´"""
        try:
            # Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ one-hot encoding
            # [STRONG_SELL, SELL, HOLD, BUY, STRONG_BUY]
            price_change = market_data.get('priceChange1d', 0)
            volume_change = market_data.get('volumeChange', 0)
            
            # Ù…Ù†Ø·Ù‚ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ
            if price_change > 10 and volume_change > 20:
                return [0, 0, 0, 0, 1]  # STRONG_BUY
            elif price_change > 5:
                return [0, 0, 0, 1, 0]  # BUY
            elif price_change < -10 and volume_change > 20:
                return [1, 0, 0, 0, 0]  # STRONG_SELL
            elif price_change < -5:
                return [0, 1, 0, 0, 0]  # SELL
            else:
                return [0, 0, 1, 0, 0]  # HOLD
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ø±Ú†Ø³Ø¨: {e}")
            return [0, 0, 1, 0, 0]  # HOLD Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    
    def train_model(self, training_data: List[Dict[str, Any]], 
                   validation_data: List[Dict[str, Any]] = None,
                   epochs: int = 100,
                   learning_rate: float = 0.01) -> Dict[str, Any]:
        """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ"""
        try:
            logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ {len(training_data)} Ù†Ù…ÙˆÙ†Ù‡")
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            X_train, y_train = self.prepare_training_data(training_data)
            
            if X_train.size == 0:
                raise ValueError("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø®Ø§Ù„ÛŒ Ù‡Ø³ØªÙ†Ø¯")
            
            # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
            self.neural_network.train(X_train, y_train, epochs=epochs, learning_rate=learning_rate)
            
            # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
            training_results = self.evaluate_model(training_data, "Ø¢Ù…ÙˆØ²Ø´")
            validation_results = {}
            
            if validation_data:
                validation_results = self.evaluate_model(validation_data, "Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ")
            
            results = {
                'training_samples': len(training_data),
                'validation_samples': len(validation_data) if validation_data else 0,
                'training_accuracy': training_results.get('accuracy', 0),
                'training_loss': training_results.get('loss', 0),
                'validation_accuracy': validation_results.get('accuracy', 0) if validation_results else 0,
                'validation_loss': validation_results.get('loss', 0) if validation_results else 0,
                'epochs_trained': epochs,
                'learning_rate': learning_rate,
                'completion_time': datetime.now().isoformat()
            }
            
            logger.info(f"âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ú©Ø§Ù…Ù„ Ø´Ø¯ - Ø¯Ù‚Øª: {results['training_accuracy']:.2f}")
            return results
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„: {e}")
            return {'error': str(e), 'success': False}
    
    def evaluate_model(self, test_data: List[Dict[str, Any]], dataset_name: str = "ØªØ³Øª") -> Dict[str, Any]:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡"""
        try:
            if not self.neural_network.is_trained:
                return {'accuracy': 0, 'loss': 0, 'error': 'Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù†Ø¯ÛŒØ¯Ù‡'}
            
            X_test, y_test = self.prepare_training_data(test_data)
            
            if X_test.size == 0:
                return {'accuracy': 0, 'loss': 0, 'error': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ø®Ø§Ù„ÛŒ'}
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            predictions = self.neural_network.forward(X_test)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª
            predicted_classes = np.argmax(predictions, axis=1)
            true_classes = np.argmax(y_test, axis=1)
            accuracy = np.mean(predicted_classes == true_classes)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§
            loss = -np.sum(y_test * np.log(predictions + 1e-8)) / len(y_test)
            
            # Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ
            confusion_matrix = self._compute_confusion_matrix(predicted_classes, true_classes)
            
            results = {
                'accuracy': float(accuracy),
                'loss': float(loss),
                'dataset': dataset_name,
                'samples': len(test_data),
                'confusion_matrix': confusion_matrix,
                'class_distribution': self._get_class_distribution(true_classes)
            }
            
            logger.info(f"ğŸ“Š Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ {dataset_name}: Ø¯Ù‚Øª={accuracy:.2f}, Ø®Ø·Ø§={loss:.4f}")
            return results
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„: {e}")
            return {'accuracy': 0, 'loss': 0, 'error': str(e)}
    
    def _compute_confusion_matrix(self, predictions: np.ndarray, true_labels: np.ndarray) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ"""
        try:
            classes = ['STRONG_SELL', 'SELL', 'HOLD', 'BUY', 'STRONG_BUY']
            matrix = {}
            
            for i, true_class in enumerate(classes):
                matrix[true_class] = {}
                for j, pred_class in enumerate(classes):
                    count = np.sum((true_labels == i) & (predictions == j))
                    matrix[true_class][pred_class] = int(count)
            
            return matrix
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ: {e}")
            return {}
    
    def _get_class_distribution(self, labels: np.ndarray) -> Dict[str, int]:
        """ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        try:
            classes = ['STRONG_SELL', 'SELL', 'HOLD', 'BUY', 'STRONG_BUY']
            distribution = {}
            
            for i, class_name in enumerate(classes):
                count = np.sum(labels == i)
                distribution[class_name] = int(count)
            
            return distribution
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§: {e}")
            return {}
    
    def save_training_report(self, results: Dict[str, Any], filepath: str = "training_report.json"):
        """Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù…ÙˆØ²Ø´"""
        try:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            
            report = {
                'training_results': results,
                'network_info': self.neural_network.get_network_info(),
                'training_date': datetime.now().isoformat(),
                'config': self.config
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø± {filepath} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù…ÙˆØ²Ø´: {e}")
    
    def load_training_data(self, filepath: str) -> List[Dict[str, Any]]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø§Ø² ÙØ§ÛŒÙ„"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"ğŸ“‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø§Ø² {filepath} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            return data
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {e}")
            return []
