"""
ðŸŽ¯ SYSTEM MONITOR v3.0 - Ù†Ø¸Ø§Ø±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡
ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯:
1. Ù…Ø¹Ù…Ø§Ø±ÛŒ Event-Driven Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ polling
2. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Async Ùˆ Non-Blocking
3. Ø³ÛŒØ³ØªÙ… Ú©Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ TTLÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
4. ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
5. Health Scoring Ø¨Ø§ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯
6. Ù†Ø¸Ø§Ø±Øª Ø³Ù„Ø³Ù„Ù‡â€ŒÙ…Ø±Ø§ØªØ¨ÛŒ
7. Predictive Monitoring Ø¨Ø§ ML Ø³Ø§Ø¯Ù‡
8. Dashboard Ø¯Ø§Ø®Ù„ÛŒ
9. ØªÙ†Ù‡Ø§ ÛŒÚ© Ø­Ù„Ù‚Ù‡ Ù…Ø±Ú©Ø²ÛŒ ÙØ¹Ø§Ù„
10. Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
"""

import asyncio
import time
import psutil
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable, Set
from collections import deque, defaultdict
from dataclasses import dataclass, field
from enum import Enum
import statistics
import json
import threading
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

# ==================== ENUMS & DATA CLASSES ====================

class MetricPriority(Enum):
    REAL_TIME = "realtime"      # Ù‡Ø± 1-5 Ø«Ø§Ù†ÛŒÙ‡
    HIGH = "high"               # Ù‡Ø± 10-30 Ø«Ø§Ù†ÛŒÙ‡  
    MEDIUM = "medium"           # Ù‡Ø± 1-5 Ø¯Ù‚ÛŒÙ‚Ù‡
    LOW = "low"                 # Ù‡Ø± 10-30 Ø¯Ù‚ÛŒÙ‚Ù‡

class ComponentHealth(Enum):
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"

@dataclass
class MetricConfig:
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‡Ø± Ù…ØªØ±ÛŒÚ©"""
    name: str
    priority: MetricPriority
    collection_interval: int
    cache_ttl: int
    anomaly_threshold: float = 2.5
    enabled: bool = True

@dataclass
class HealthScore:
    """Ø§Ù…ØªÛŒØ§Ø² Ø³Ù„Ø§Ù…Øª Ù‡Ø± Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª"""
    component: str
    score: float
    status: ComponentHealth
    weighted_score: float
    details: Dict[str, Any]

@dataclass
class MonitoringEvent:
    """Ø±ÙˆÛŒØ¯Ø§Ø¯ Ù†Ø¸Ø§Ø±ØªÛŒ"""
    type: str
    data: Any
    timestamp: float = field(default_factory=time.time)
    source: str = "system_monitor"

# ==================== SMART CACHE SYSTEM ====================

class SmartMetricCache:
    """Ú©Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ø§ TTLÙ‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª"""
    
    def __init__(self):
        self._cache = {}
        self._cache_hits = 0
        self._cache_misses = 0
        self._lock = threading.RLock()
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¹ Ù…ØªØ±ÛŒÚ©
        self._cache_configs = {
            'cpu': MetricConfig('cpu', MetricPriority.REAL_TIME, 2, 5),
            'memory': MetricConfig('memory', MetricPriority.REAL_TIME, 2, 5),
            'disk': MetricConfig('disk', MetricPriority.MEDIUM, 30, 60),
            'network': MetricConfig('network', MetricPriority.HIGH, 10, 20),
            'process': MetricConfig('process', MetricPriority.MEDIUM, 60, 120),
            'system': MetricConfig('system', MetricPriority.LOW, 300, 600)
        }
    
    async def get_or_fetch(self, metric_type: str, fetch_func: Callable) -> Any:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ú©Ø´ ÛŒØ§ fetch Ø¬Ø¯ÛŒØ¯"""
        with self._lock:
            cache_entry = self._cache.get(metric_type)
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± Ú©Ø´
            if cache_entry and not self._is_expired(metric_type, cache_entry):
                self._cache_hits += 1
                logger.debug(f"âœ… Cache hit for {metric_type}")
                return cache_entry['data']
            
            # Ú©Ø´ Ù…Ù†Ù‚Ø¶ÛŒ ÛŒØ§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
            self._cache_misses += 1
            
            # fetch Ø¬Ø¯ÛŒØ¯
            fresh_data = await fetch_func()
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
            config = self._cache_configs.get(metric_type, self._cache_configs['system'])
            self._cache[metric_type] = {
                'data': fresh_data,
                'timestamp': time.time(),
                'ttl': config.cache_ttl,
                'config': config
            }
            
            # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
            self._cleanup_old_cache()
            
            return fresh_data
    
    def _is_expired(self, metric_type: str, cache_entry: Dict) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ù‚Ø¶Ø§ÛŒ Ú©Ø´"""
        config = cache_entry.get('config')
        if not config:
            return True
        
        age = time.time() - cache_entry['timestamp']
        return age > config.cache_ttl
    
    def _cleanup_old_cache(self):
        """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        current_time = time.time()
        expired_keys = []
        
        for key, entry in self._cache.items():
            if current_time - entry['timestamp'] > entry['ttl'] * 2:  # 2 Ø¨Ø±Ø§Ø¨Ø± TTL
                expired_keys.append(key)
        
        for key in expired_keys:
            del self._cache[key]
        
        if expired_keys:
            logger.debug(f"ðŸ§¹ Cleaned {len(expired_keys)} expired cache entries")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ø´"""
        return {
            'total_entries': len(self._cache),
            'cache_hits': self._cache_hits,
            'cache_misses': self._cache_misses,
            'hit_ratio': self._cache_hits / max(1, self._cache_hits + self._cache_misses),
            'configs': {k: v.__dict__ for k, v in self._cache_configs.items()}
        }

# ==================== ASYNC METRICS COLLECTOR ====================

class AsyncMetricsCollector:
    """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ØºÛŒØ±Ù…Ø³Ø¯ÙˆØ¯Ú©Ù†Ù†Ø¯Ù‡"""
    
    def __init__(self):
        self.thread_pool = ThreadPoolExecutor(
            max_workers=4,
            thread_name_prefix="metric_collector"
        )
        
    async def collect_all_async(self, enabled_metrics: Set[str] = None) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ÙˆØ§Ø²ÛŒ"""
        if enabled_metrics is None:
            enabled_metrics = {'cpu', 'memory', 'disk', 'network', 'process'}
        
        tasks = []
        
        if 'cpu' in enabled_metrics:
            tasks.append(self._collect_cpu_async())
        
        if 'memory' in enabled_metrics:
            tasks.append(self._collect_memory_async())
        
        if 'disk' in enabled_metrics:
            tasks.append(self._collect_disk_async())
        
        if 'network' in enabled_metrics:
            tasks.append(self._collect_network_async())
        
        if 'process' in enabled_metrics:
            tasks.append(self._collect_process_async())
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'collection_time': time.time()
        }
        
        for i, metric_type in enumerate(['cpu', 'memory', 'disk', 'network', 'process']):
            if metric_type in enabled_metrics and i < len(results):
                if not isinstance(results[i], Exception):
                    metrics[metric_type] = results[i]
                else:
                    metrics[metric_type] = {'error': str(results[i])}
        
        return metrics
    
    async def _collect_cpu_async(self) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ CPU Ø¨Ù‡ ØµÙˆØ±Øª async"""
        loop = asyncio.get_event_loop()
        
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² interval Ú©ÙˆØªØ§Ù‡ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            cpu_percent = await loop.run_in_executor(
                self.thread_pool,
                lambda: psutil.cpu_percent(interval=0.05)  # Ú©Ø§Ù‡Ø´ Ø§Ø² 0.1 Ø¨Ù‡ 0.05
            )
            
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
            cpu_count = await loop.run_in_executor(
                self.thread_pool,
                psutil.cpu_count
            )
            
            cpu_freq = await loop.run_in_executor(
                self.thread_pool,
                lambda: psutil.cpu_freq().current if hasattr(psutil, 'cpu_freq') else None
            )
            
            return {
                'percent': cpu_percent,
                'cores': cpu_count,
                'frequency_mhz': cpu_freq,
                'load_avg': psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
            }
        except Exception as e:
            logger.error(f"âŒ Error collecting CPU metrics: {e}")
            return {'percent': 0, 'cores': 1, 'error': str(e)}
    
    async def _collect_memory_async(self) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Memory Ø¨Ù‡ ØµÙˆØ±Øª async"""
        loop = asyncio.get_event_loop()
        
        try:
            memory = await loop.run_in_executor(
                self.thread_pool,
                psutil.virtual_memory
            )
            
            return {
                'percent': memory.percent,
                'used_gb': round(memory.used / (1024**3), 2),
                'available_gb': round(memory.available / (1024**3), 2),
                'total_gb': round(memory.total / (1024**3), 2),
                'free_gb': round(memory.free / (1024**3), 2)
            }
        except Exception as e:
            logger.error(f"âŒ Error collecting memory metrics: {e}")
            return {'percent': 0, 'error': str(e)}
    
    async def _collect_disk_async(self) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Disk Ø¨Ù‡ ØµÙˆØ±Øª async"""
        loop = asyncio.get_event_loop()
        
        try:
            disk = await loop.run_in_executor(
                self.thread_pool,
                lambda: psutil.disk_usage('/')
            )
            
            # I/O statistics (Ø¨Ø§ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ)
            io_before = await loop.run_in_executor(
                self.thread_pool,
                psutil.disk_io_counters
            )
            
            await asyncio.sleep(0.1)  # ØªØ£Ø®ÛŒØ± Ú©ÙˆØªØ§Ù‡
            
            io_after = await loop.run_in_executor(
                self.thread_pool,
                psutil.disk_io_counters
            )
            
            io_delta = {
                'read_mb_per_sec': round(((io_after.read_bytes - io_before.read_bytes) / (1024**2)) / 0.1, 2),
                'write_mb_per_sec': round(((io_after.write_bytes - io_before.write_bytes) / (1024**2)) / 0.1, 2)
            } if io_before and io_after else {}
            
            return {
                'usage_percent': disk.percent,
                'used_gb': round(disk.used / (1024**3), 2),
                'free_gb': round(disk.free / (1024**3), 2),
                'total_gb': round(disk.total / (1024**3), 2),
                'io': io_delta
            }
        except Exception as e:
            logger.error(f"âŒ Error collecting disk metrics: {e}")
            return {'usage_percent': 0, 'error': str(e)}
    
    async def _collect_network_async(self) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Network Ø¨Ù‡ ØµÙˆØ±Øª async"""
        loop = asyncio.get_event_loop()
        
        try:
            # Ø´Ø¨Ú©Ù‡ - ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø®ÙˆØ§Ù†Ø¯Ù† (Ø¨Ø¯ÙˆÙ† interval)
            net_io = await loop.run_in_executor(
                self.thread_pool,
                psutil.net_io_counters
            )
            
            return {
                'bytes_sent_mb': round(net_io.bytes_sent / (1024**2), 2),
                'bytes_recv_mb': round(net_io.bytes_recv / (1024**2), 2),
                'packets_sent': net_io.packets_sent,
                'packets_recv': net_io.packets_recv,
                'errin': net_io.errin,
                'errout': net_io.errout
            }
        except Exception as e:
            logger.error(f"âŒ Error collecting network metrics: {e}")
            return {'bytes_sent_mb': 0, 'bytes_recv_mb': 0, 'error': str(e)}
    
    async def _collect_process_async(self) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Process Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª async"""
        loop = asyncio.get_event_loop()
        
        try:
            current_process = psutil.Process()
            
            # ÙÙ‚Ø· Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¶Ø±ÙˆØ±ÛŒ
            process_info = await loop.run_in_executor(
                self.thread_pool,
                current_process.memory_info
            )
            
            cpu_percent = await loop.run_in_executor(
                self.thread_pool,
                lambda: current_process.cpu_percent(interval=0.05)
            )
            
            return {
                'memory_rss_mb': round(process_info.rss / (1024**2), 2),
                'cpu_percent': cpu_percent,
                'threads_count': current_process.num_threads(),
                'pid': current_process.pid,
                'name': current_process.name()
            }
        except Exception as e:
            logger.error(f"âŒ Error collecting process metrics: {e}")
            return {'memory_rss_mb': 0, 'cpu_percent': 0, 'error': str(e)}

# ==================== ANOMALY DETECTION ====================

class AnomalyDetector:
    """Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªØ±ÛŒÚ©"""
    
    def __init__(self, window_size: int = 50):
        self.window_size = window_size
        self.metric_history = defaultdict(lambda: deque(maxlen=window_size))
        self.anomaly_threshold = 2.5  # z-score threshold
        self.consecutive_anomalies = defaultdict(int)
        
    def analyze(self, metric_type: str, current_value: float) -> Optional[Dict[str, Any]]:
        """ØªØ­Ù„ÛŒÙ„ Ù…ØªØ±ÛŒÚ© Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ"""
        history = self.metric_history[metric_type]
        
        # Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        if len(history) < 10:
            history.append(current_value)
            return None
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø±
        mean = statistics.mean(history)
        stdev = statistics.stdev(history) if len(history) > 1 else 0
        
        # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ±
        if stdev == 0:
            history.append(current_value)
            return None
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ z-score
        z_score = abs((current_value - mean) / stdev)
        
        # ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ
        if z_score > self.anomaly_threshold:
            self.consecutive_anomalies[metric_type] += 1
            
            # Ø¨Ø±Ø±Ø³ÛŒ consecutive anomalies Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ false positives
            if self.consecutive_anomalies[metric_type] >= 2:
                anomaly = {
                    'metric': metric_type,
                    'current_value': current_value,
                    'historical_mean': mean,
                    'z_score': round(z_score, 2),
                    'severity': self._calculate_severity(z_score),
                    'timestamp': datetime.now().isoformat(),
                    'recommendation': self._get_recommendation(metric_type, current_value)
                }
                
                # Ø±ÛŒØ³Øª consecutive counter
                self.consecutive_anomalies[metric_type] = 0
                
                history.append(current_value)
                return anomaly
        else:
            self.consecutive_anomalies[metric_type] = 0
        
        history.append(current_value)
        return None
    
    def _calculate_severity(self, z_score: float) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Øª Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ"""
        if z_score > 4.0:
            return "critical"
        elif z_score > 3.0:
            return "high"
        elif z_score > 2.5:
            return "medium"
        else:
            return "low"
    
    def _get_recommendation(self, metric_type: str, value: float) -> str:
        """ØªÙˆØµÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù…ØªØ±ÛŒÚ© Ùˆ Ù…Ù‚Ø¯Ø§Ø±"""
        recommendations = {
            'cpu': {
                'high': "Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ùˆ scale Ú©Ø±Ø¯Ù† Ø³Ø±ÙˆÛŒØ³",
                'critical': "Ø±ÛŒâ€ŒØ§Ø³ØªØ§Ø±Øª Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ Ùˆ emergency scale"
            },
            'memory': {
                'high': "Ø¨Ø±Ø±Ø³ÛŒ memory leak Ùˆ Ø§ÙØ²Ø§ÛŒØ´ memory limit",
                'critical': "Ø±ÛŒâ€ŒØ§Ø³ØªØ§Ø±Øª Ø³Ø±ÙˆÛŒØ³ Ùˆ emergency memory allocation"
            },
            'disk': {
                'high': "Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ùˆ Ù„Ø§Ú¯â€ŒÙ‡Ø§",
                'critical': "Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ¶Ø§ÛŒ Ø¯ÛŒØ³Ú© Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ"
            }
        }
        
        if value > 90:
            severity = 'critical'
        elif value > 80:
            severity = 'high'
        else:
            return "Ù…Ø§Ù†ÛŒØªÙˆØ± Ø§Ø¯Ø§Ù…Ù‡â€ŒØ¯Ø§Ø±"
        
        return recommendations.get(metric_type, {}).get(severity, "Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªÛŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª")

# ==================== HEALTH SCORING SYSTEM ====================

class HealthScoringSystem:
    """Ø³ÛŒØ³ØªÙ… Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø³Ù„Ø§Ù…Øª"""
    
    def __init__(self):
        # ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª
        self.weights = {
            'cpu': {'weight': 0.35, 'thresholds': {'warning': 80, 'critical': 90}},
            'memory': {'weight': 0.25, 'thresholds': {'warning': 85, 'critical': 95}},
            'disk': {'weight': 0.20, 'thresholds': {'warning': 90, 'critical': 98}},
            'network': {'weight': 0.15, 'thresholds': {'warning': 80, 'critical': 95}},
            'process': {'weight': 0.05, 'thresholds': {'warning': 1000, 'critical': 2000}}
        }
        
        self.history = deque(maxlen=100)
    
    def calculate_scores(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø³Ù„Ø§Ù…Øª Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§"""
        component_scores = {}
        total_weighted_score = 0
        total_weight = 0
        
        for component, config in self.weights.items():
            if component in metrics and 'error' not in metrics[component]:
                score_details = self._calculate_component_score(component, metrics[component], config)
                component_scores[component] = score_details
                
                total_weighted_score += score_details['weighted_score']
                total_weight += config['weight']
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
        overall_score = (total_weighted_score / total_weight) if total_weight > 0 else 0
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.history.append({
            'timestamp': metrics.get('timestamp', datetime.now().isoformat()),
            'overall_score': overall_score,
            'component_scores': component_scores
        })
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯
        trend = self._calculate_trend()
        
        return {
            'overall_score': round(overall_score, 1),
            'overall_status': self._get_overall_status(overall_score),
            'component_scores': component_scores,
            'trend': trend,
            'recommendations': self._generate_recommendations(component_scores, overall_score),
            'timestamp': datetime.now().isoformat()
        }
    
    def _calculate_component_score(self, component: str, data: Dict, config: Dict) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª Ø®Ø§Øµ"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø¯Ø§Ø± Ø§ØµÙ„ÛŒ
        if component == 'cpu':
            value = data.get('percent', 0)
        elif component == 'memory':
            value = data.get('percent', 0)
        elif component == 'disk':
            value = data.get('usage_percent', 0)
        elif component == 'network':
            # ØªØ±Ú©ÛŒØ¨ upload/download
            sent = data.get('bytes_sent_mb', 0)
            recv = data.get('bytes_recv_mb', 0)
            value = min((sent + recv) / 10, 100)  # normalize
        elif component == 'process':
            value = min(data.get('memory_rss_mb', 0) / 10, 100)
        else:
            value = 0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² (Ù‡Ø±Ú†Ù‡ usage Ú©Ù…ØªØ±ØŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±)
        score = max(0, 100 - value)
        
        # ÙˆØ¶Ø¹ÛŒØª
        if value >= config['thresholds']['critical']:
            status = ComponentHealth.CRITICAL.value
        elif value >= config['thresholds']['warning']:
            status = ComponentHealth.WARNING.value
        else:
            status = ComponentHealth.HEALTHY.value
        
        # Ø§Ù…ØªÛŒØ§Ø² ÙˆØ²Ù†ÛŒ
        weighted_score = score * config['weight']
        
        return {
            'score': round(score, 1),
            'value': round(value, 1),
            'status': status,
            'weighted_score': round(weighted_score, 3),
            'thresholds': config['thresholds']
        }
    
    def _get_overall_status(self, score: float) -> str:
        """ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ"""
        if score >= 85:
            return ComponentHealth.HEALTHY.value
        elif score >= 70:
            return ComponentHealth.WARNING.value
        else:
            return ComponentHealth.CRITICAL.value
    
    def _calculate_trend(self) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§"""
        if len(self.history) < 5:
            return {'direction': 'unknown', 'change': 0}
        
        scores = [h['overall_score'] for h in list(self.history)[-5:]]
        
        if len(scores) < 2:
            return {'direction': 'stable', 'change': 0}
        
        # Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ Ø³Ø§Ø¯Ù‡
        x = list(range(len(scores)))
        y = scores
        
        try:
            slope = (len(x) * sum(x[i] * y[i] for i in range(len(x))) - sum(x) * sum(y)) / \
                   (len(x) * sum(x_i**2 for x_i in x) - sum(x)**2)
            
            if slope > 0.5:
                direction = 'improving'
            elif slope < -0.5:
                direction = 'deteriorating'
            else:
                direction = 'stable'
            
            return {
                'direction': direction,
                'change': round(slope, 3),
                'last_5_scores': scores[-5:]
            }
        except:
            return {'direction': 'unknown', 'change': 0}
    
    def _generate_recommendations(self, component_scores: Dict, overall_score: float) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        recommendations = []
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª
        for component, score_data in component_scores.items():
            if score_data['status'] == ComponentHealth.CRITICAL.value:
                rec = self._get_critical_recommendation(component, score_data['value'])
                if rec:
                    recommendations.append(rec)
            elif score_data['status'] == ComponentHealth.WARNING.value and overall_score < 75:
                rec = self._get_warning_recommendation(component, score_data['value'])
                if rec:
                    recommendations.append(rec)
        
        # ØªÙˆØµÛŒÙ‡ Ú©Ù„ÛŒ
        if overall_score < 60 and not recommendations:
            recommendations.append("Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ… ØªÙˆØ³Ø· Ø§Ø¯Ù…ÛŒÙ† Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª")
        
        if not recommendations and overall_score >= 85:
            recommendations.append("Ø³ÛŒØ³ØªÙ… Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ÛŒÙ†Ù‡ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯")
        
        return recommendations[:5]  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 ØªÙˆØµÛŒÙ‡
    
    def _get_critical_recommendation(self, component: str, value: float) -> str:
        """ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ"""
        recommendations = {
            'cpu': f"CPU Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ ({value}%) - Ø±ÛŒâ€ŒØ§Ø³ØªØ§Ø±Øª/Scale Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ",
            'memory': f"Memory Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ ({value}%) - Ø¨Ø±Ø±Ø³ÛŒ Memory Leak",
            'disk': f"Ø¯ÛŒØ³Ú© Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ ({value}%) - Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ ÙÙˆØ±ÛŒ",
            'network': f"Ø´Ø¨Ú©Ù‡ Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ - Ø¨Ø±Ø±Ø³ÛŒ ØªØ±Ø§ÙÛŒÚ©",
            'process': f"Process Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ - Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§"
        }
        return recommendations.get(component, f"ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± {component}")
    
    def _get_warning_recommendation(self, component: str, value: float) -> str:
        """ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù‡Ø´Ø¯Ø§Ø±"""
        recommendations = {
            'cpu': f"CPU Ø¨Ø§Ù„Ø§ ({value}%) - Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ ÙØ¹Ø§Ù„",
            'memory': f"Memory Ø¨Ø§Ù„Ø§ ({value}%) - Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Memory",
            'disk': f"Ø¯ÛŒØ³Ú© Ù¾Ø± ({value}%) - Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ",
            'network': f"ØªØ±Ø§ÙÛŒÚ© Ø´Ø¨Ú©Ù‡ Ø¨Ø§Ù„Ø§ - Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯",
            'process': f"Process Ø³Ù†Ú¯ÛŒÙ† - Ø¨Ø±Ø±Ø³ÛŒ"
        }
        return recommendations.get(component, f"ÙˆØ¶Ø¹ÛŒØª Ù‡Ø´Ø¯Ø§Ø± Ø¯Ø± {component}")

# ==================== HIERARCHICAL MONITORING ====================

class HierarchicalMonitor:
    """Ù†Ø¸Ø§Ø±Øª Ø³Ù„Ø³Ù„Ù‡â€ŒÙ…Ø±Ø§ØªØ¨ÛŒ Ø¨Ø§ Ø³Ø·ÙˆØ­ Ù…Ø®ØªÙ„Ù"""
    
    def __init__(self):
        # ØªØ¹Ø±ÛŒÙ Ø³Ø·ÙˆØ­ Ù†Ø¸Ø§Ø±ØªÛŒ
        self.levels = {
            'realtime': {
                'interval': 2,      # Ù‡Ø± 2 Ø«Ø§Ù†ÛŒÙ‡
                'metrics': {'cpu', 'memory'},
                'priority': MetricPriority.REAL_TIME,
                'enabled': True
            },
            'high': {
                'interval': 10,     # Ù‡Ø± 10 Ø«Ø§Ù†ÛŒÙ‡
                'metrics': {'network', 'process'},
                'priority': MetricPriority.HIGH,
                'enabled': True
            },
            'medium': {
                'interval': 30,     # Ù‡Ø± 30 Ø«Ø§Ù†ÛŒÙ‡
                'metrics': {'disk'},
                'priority': MetricPriority.MEDIUM,
                'enabled': True
            },
            'low': {
                'interval': 300,    # Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡
                'metrics': {'system'},
                'priority': MetricPriority.LOW,
                'enabled': True
            }
        }
        
        self.level_timers = {}
        self.last_collection = {}
        
        # ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        for level in self.levels:
            self.last_collection[level] = 0
    
    def should_collect(self, level: str, current_time: float) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø²Ù…Ø§Ù† Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§ÛŒÙ† Ø³Ø·Ø­ Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª"""
        if not self.levels[level]['enabled']:
            return False
        
        interval = self.levels[level]['interval']
        last_time = self.last_collection.get(level, 0)
        
        return current_time - last_time >= interval
    
    def get_metrics_to_collect(self, current_time: float) -> Set[str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´ÙˆÙ†Ø¯"""
        metrics_to_collect = set()
        
        for level, config in self.levels.items():
            if self.should_collect(level, current_time):
                metrics_to_collect.update(config['metrics'])
                self.last_collection[level] = current_time
        
        return metrics_to_collect
    
    def update_level_status(self, level: str, enabled: bool):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª ÛŒÚ© Ø³Ø·Ø­"""
        if level in self.levels:
            self.levels[level]['enabled'] = enabled
            logger.info(f"ðŸ“Š Level {level} {'enabled' if enabled else 'disabled'}")
    
    def get_status(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø³Ø·ÙˆØ­"""
        status = {}
        current_time = time.time()
        
        for level, config in self.levels.items():
            last_time = self.last_collection.get(level, 0)
            time_since_last = current_time - last_time if last_time > 0 else None
            
            status[level] = {
                'enabled': config['enabled'],
                'interval': config['interval'],
                'metrics': list(config['metrics']),
                'time_since_last': round(time_since_last, 1) if time_since_last else None,
                'next_collection_in': max(0, config['interval'] - time_since_last) if time_since_last else 0
            }
        
        return status

# ==================== PREDICTIVE MONITORING ====================

class PredictiveMonitor:
    """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ ML"""
    
    def __init__(self, history_size: int = 100):
        self.history_size = history_size
        self.cpu_history = deque(maxlen=history_size)
        self.memory_history = deque(maxlen=history_size)
        self.predictions = {}
    
    def add_metric(self, metric_type: str, value: float):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…ØªØ±ÛŒÚ© Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡"""
        if metric_type == 'cpu':
            self.cpu_history.append(value)
        elif metric_type == 'memory':
            self.memory_history.append(value)
    
    def predict(self, metric_type: str, lookahead: int = 3) -> Optional[Dict[str, Any]]:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ù…ØªØ±ÛŒÚ©"""
        history = self.cpu_history if metric_type == 'cpu' else self.memory_history
        
        if len(history) < 10:
            return None
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        window = min(5, len(history))
        moving_avg = sum(list(history)[-window:]) / window
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø®Ø·ÛŒ Ø³Ø§Ø¯Ù‡
        if len(history) >= 2:
            last_two = list(history)[-2:]
            slope = last_two[1] - last_two[0]
            prediction = last_two[1] + slope * lookahead
        else:
            prediction = moving_avg
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        prediction = max(0, min(100, prediction))
        
        # ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª
        if prediction > 90:
            status = 'critical'
        elif prediction > 80:
            status = 'warning'
        else:
            status = 'normal'
        
        self.predictions[metric_type] = {
            'current': history[-1] if history else 0,
            'predicted': round(prediction, 1),
            'lookahead': lookahead,
            'status': status,
            'confidence': self._calculate_confidence(len(history)),
            'timestamp': datetime.now().isoformat()
        }
        
        return self.predictions[metric_type]
    
    def _calculate_confidence(self, history_length: int) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"""
        if history_length >= 50:
            return 0.9
        elif history_length >= 20:
            return 0.7
        elif history_length >= 10:
            return 0.5
        else:
            return 0.3
    
    def get_all_predictions(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§"""
        predictions = {}
        
        if len(self.cpu_history) >= 10:
            predictions['cpu'] = self.predict('cpu')
        
        if len(self.memory_history) >= 10:
            predictions['memory'] = self.predict('memory')
        
        return predictions

# ==================== EMBEDDED DASHBOARD ====================

class EmbeddedDashboard:
    """Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± CLI"""
    
    def __init__(self):
        self.display_width = 60
        self.metric_history = defaultdict(lambda: deque(maxlen=20))
    
    def generate_dashboard(self, 
                          metrics: Dict[str, Any], 
                          health_score: Dict[str, Any],
                          anomalies: List[Dict[str, Any]]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…ØªÙ†ÛŒ"""
        lines = []
        
        # Header
        lines.append("=" * self.display_width)
        lines.append("ðŸš€ VORTEXAI - REAL-TIME MONITORING DASHBOARD")
        lines.append("=" * self.display_width)
        
        # Timestamp
        timestamp = metrics.get('timestamp', datetime.now().isoformat())
        lines.append(f"ðŸ•’ {timestamp}")
        lines.append("-" * self.display_width)
        
        # Health Score
        overall_score = health_score.get('overall_score', 0)
        overall_status = health_score.get('overall_status', 'unknown')
        
        status_emoji = {
            'healthy': 'âœ…',
            'warning': 'âš ï¸',
            'critical': 'âŒ',
            'unknown': 'â“'
        }
        
        lines.append(f"ðŸ“Š HEALTH SCORE: {overall_score}/100 {status_emoji.get(overall_status, '')}")
        lines.append(self._create_progress_bar(overall_score))
        lines.append(f"ðŸ“ˆ Trend: {health_score.get('trend', {}).get('direction', 'unknown')}")
        
        # Component Breakdown
        lines.append("\nðŸ”§ COMPONENT BREAKDOWN:")
        lines.append("-" * 40)
        
        component_scores = health_score.get('component_scores', {})
        for component, score_data in component_scores.items():
            value = score_data.get('value', 0)
            status = score_data.get('status', 'unknown')
            
            bar = self._create_progress_bar(100 - value, width=20)  # Ù…Ø¹Ú©ÙˆØ³ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ usage
            lines.append(f"  {component.upper():10} {value:5.1f}% {bar} {status}")
        
        # CPU & Memory Charts
        lines.append("\nðŸ“ˆ REAL-TIME CHARTS:")
        lines.append("-" * self.display_width)
        
        # CPU Chart
        if 'cpu' in metrics:
            cpu_value = metrics['cpu'].get('percent', 0)
            self.metric_history['cpu'].append(cpu_value)
            lines.append(f"ðŸ”¹ CPU Usage: {cpu_value:.1f}%")
            lines.append(self._create_sparkline(list(self.metric_history['cpu'])))
        
        # Memory Chart
        if 'memory' in metrics:
            mem_value = metrics['memory'].get('percent', 0)
            self.metric_history['memory'].append(mem_value)
            lines.append(f"ðŸ”¹ Memory Usage: {mem_value:.1f}%")
            lines.append(self._create_sparkline(list(self.metric_history['memory'])))
        
        # Anomalies
        if anomalies:
            lines.append("\nðŸš¨ ACTIVE ANOMALIES:")
            lines.append("-" * self.display_width)
            for i, anomaly in enumerate(anomalies[:3], 1):  # Ø­Ø¯Ø§Ú©Ø«Ø± Û³ Ù…ÙˆØ±Ø¯
                lines.append(f"  {i}. {anomaly.get('metric', 'unknown')}: {anomaly.get('severity', 'unknown')}")
                lines.append(f"     Value: {anomaly.get('current_value', 0):.1f}, Z-Score: {anomaly.get('z_score', 0):.2f}")
        
        # Recommendations
        recommendations = health_score.get('recommendations', [])
        if recommendations:
            lines.append("\nðŸ’¡ RECOMMENDATIONS:")
            lines.append("-" * self.display_width)
            for i, rec in enumerate(recommendations[:3], 1):  # Ø­Ø¯Ø§Ú©Ø«Ø± Û³ Ù…ÙˆØ±Ø¯
                lines.append(f"  {i}. {rec}")
        
        # Footer
        lines.append("\n" + "=" * self.display_width)
        lines.append("ðŸ” Press Ctrl+C to exit | ðŸ“Š Auto-refresh every 5s")
        lines.append("=" * self.display_width)
        
        return "\n".join(lines)
    
    def _create_progress_bar(self, percentage: float, width: int = 30) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
        filled = int(width * percentage / 100)
        empty = width - filled
        bar = "â–ˆ" * filled + "â–‘" * empty
        return f"[{bar}]"
    
    def _create_sparkline(self, values: List[float]) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ sparkline Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÙ†Ø¯"""
        if not values:
            return "No data"
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ±
        if max(values) > min(values):
            normalized = [(v - min(values)) / (max(values) - min(values)) for v in values]
        else:
            normalized = [0.5] * len(values)
        
        # Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ sparkline
        spark_chars = "â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ"
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ sparkline
        sparkline = ""
        for norm_val in normalized:
            idx = min(int(norm_val * len(spark_chars)), len(spark_chars) - 1)
            sparkline += spark_chars[idx]
        
        return f"  Trend: {sparkline}"

# ==================== MAIN CENTRAL MONITORING SYSTEM ====================

class CentralMonitoringSystem:
    """Ø³ÛŒØ³ØªÙ… Ù†Ø¸Ø§Ø±Øª Ù…Ø±Ú©Ø²ÛŒ - ØªÙ†Ù‡Ø§ Ø­Ù„Ù‚Ù‡ ÙØ¹Ø§Ù„"""
    
    def __init__(self):
        # Ø²ÛŒØ±Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§
        self.cache = SmartMetricCache()
        self.collector = AsyncMetricsCollector()
        self.anomaly_detector = AnomalyDetector()
        self.health_scorer = HealthScoringSystem()
        self.hierarchical_monitor = HierarchicalMonitor()
        self.predictive_monitor = PredictiveMonitor()
        self.dashboard = EmbeddedDashboard()
        
        # ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…
        self.is_monitoring = False
        self.monitor_task = None
        self.last_metrics = {}
        self.last_health_score = {}
        self.active_anomalies = []
        
        # ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.metrics_history = deque(maxlen=100)
        self.health_history = deque(maxlen=100)
        
        # Subscribers (Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±)
        self.subscribers = defaultdict(list)
        
        # ØªÙ†Ø¸ÛŒÙ… Ú¯Ù„ÙˆØ¨Ø§Ù„
        global central_monitor
        central_monitor = self
        
        logger.info("ðŸŽ¯ Central Monitoring System v3.0 Initialized")
    
    async def start_monitoring(self):
        """Ø´Ø±ÙˆØ¹ Ù†Ø¸Ø§Ø±Øª Ù…Ø±Ú©Ø²ÛŒ - ØªÙ†Ù‡Ø§ ÛŒÚ© Ø­Ù„Ù‚Ù‡ ÙØ¹Ø§Ù„"""
        if self.is_monitoring:
            logger.warning("âš ï¸ Monitoring is already running")
            return
        
        self.is_monitoring = True
        self.monitor_task = asyncio.create_task(
            self._monitoring_loop(),
            name="CentralMonitorLoop"
        )
        
        logger.info("ðŸ”„ Central monitoring started with hierarchical collection")
    
    async def stop_monitoring(self):
        """ØªÙˆÙ‚Ù Ù†Ø¸Ø§Ø±Øª"""
        self.is_monitoring = False
        
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        
        logger.info("ðŸ›‘ Central monitoring stopped")
    
    async def _monitoring_loop(self):
        """Ø­Ù„Ù‚Ù‡ Ù†Ø¸Ø§Ø±Øª Ù…Ø±Ú©Ø²ÛŒ - ØªÙ†Ù‡Ø§ Ø­Ù„Ù‚Ù‡ ÙØ¹Ø§Ù„"""
        logger.debug("ðŸ” Central monitoring loop started")
        
        cycle_count = 0
        
        while self.is_monitoring:
            try:
                cycle_start = time.time()
                cycle_count += 1
                
                # Û±. ØªØ¹ÛŒÛŒÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¯Ø± Ø§ÛŒÙ† Ú†Ø±Ø®Ù‡
                metrics_to_collect = self.hierarchical_monitor.get_metrics_to_collect(cycle_start)
                
                if not metrics_to_collect:
                    # Ù‡ÛŒÚ† Ù…ØªØ±ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ÛŒØ³Øª - sleep Ú©ÙˆØªØ§Ù‡
                    await asyncio.sleep(0.5)
                    continue
                
                # Û². Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ (Ø¨Ø§ Ú©Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯)
                collected_metrics = {}
                for metric_type in metrics_to_collect:
                    if metric_type in ['cpu', 'memory', 'disk', 'network', 'process']:
                        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯
                        metric_data = await self.cache.get_or_fetch(
                            metric_type,
                            lambda m=metric_type: self._collect_specific_metric(m)
                        )
                        collected_metrics[metric_type] = metric_data
                        
                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ predictive monitor
                        if metric_type in ['cpu', 'memory']:
                            value = metric_data.get('percent', 0) if 'percent' in metric_data else 0
                            self.predictive_monitor.add_metric(metric_type, value)
                
                # Û³. Ø³Ø§Ø®ØªØ§Ø±Ø¯Ù‡ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
                full_metrics = {
                    'timestamp': datetime.now().isoformat(),
                    'collection_time': cycle_start,
                    'cycle': cycle_count,
                    'metrics_collected': list(metrics_to_collect)
                }
                full_metrics.update(collected_metrics)
                
                # Û´. ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§
                new_anomalies = []
                for metric_type, data in collected_metrics.items():
                    if 'percent' in data:
                        anomaly = self.anomaly_detector.analyze(
                            metric_type, 
                            data['percent']
                        )
                        if anomaly:
                            new_anomalies.append(anomaly)
                
                self.active_anomalies = new_anomalies[:10]  # Ø­Ø¯Ø§Ú©Ø«Ø± Û±Û° Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ
                
                # Ûµ. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ù„Ø§Ù…Øª
                health_score = self.health_scorer.calculate_scores(full_metrics)
                
                # Û¶. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
                self.last_metrics = full_metrics
                self.last_health_score = health_score
                self.metrics_history.append(full_metrics)
                self.health_history.append(health_score)
                
                # Û·. Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ subscribers
                await self._notify_subscribers(full_metrics, health_score, new_anomalies)
                
                # Û¸. Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
                if cycle_count % 5 == 0:  # Ù‡Ø± Ûµ Ú†Ø±Ø®Ù‡ ÛŒÚ©Ø¨Ø§Ø±
                    dashboard_text = self.dashboard.generate_dashboard(
                        full_metrics, 
                        health_score, 
                        new_anomalies
                    )
                    # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ø§ÛŒÙ† Ø±Ø§ Ø¨Ù‡ console_stream Ø¨ÙØ±Ø³ØªÛŒ
                    # console_stream.update(dashboard_text)
                
                # Û¹. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®ÙˆØ§Ø¨ Ù‡ÙˆØ´Ù…Ù†Ø¯
                execution_time = time.time() - cycle_start
                sleep_time = self._calculate_adaptive_sleep(
                    execution_time, 
                    full_metrics, 
                    cycle_count
                )
                
                # Ù„Ø§Ú¯ ÙÙ‚Ø· Ø§Ú¯Ø± Ú†Ø±Ø®Ù‡ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§Ø´Ø¯
                if execution_time > 1.0:
                    logger.debug(f"â±ï¸ Cycle {cycle_count} took {execution_time:.2f}s, sleeping {sleep_time:.1f}s")
                
                await asyncio.sleep(sleep_time)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ Monitoring loop error: {e}", exc_info=True)
                await asyncio.sleep(5)  # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ø¨ÛŒØ´ØªØ± ØµØ¨Ø± Ú©Ù†
    
    async def _collect_specific_metric(self, metric_type: str) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ÛŒÚ© Ù…ØªØ±ÛŒÚ© Ø®Ø§Øµ"""
        metric_map = {
            'cpu': self.collector._collect_cpu_async,
            'memory': self.collector._collect_memory_async,
            'disk': self.collector._collect_disk_async,
            'network': self.collector._collect_network_async,
            'process': self.collector._collect_process_async
        }
        
        if metric_type in metric_map:
            return await metric_map[metric_type]()
        else:
            return {'error': f'Unknown metric type: {metric_type}'}
    
    async def _notify_subscribers(self, metrics: Dict, health_score: Dict, anomalies: List):
        """Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø´ØªØ±Ú©"""
        event_data = {
            'metrics': metrics,
            'health_score': health_score,
            'anomalies': anomalies,
            'timestamp': datetime.now().isoformat()
        }
        
        # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù‡Ù…Ù‡ subscribers
        for event_type, callbacks in self.subscribers.items():
            for callback in callbacks:
                try:
                    if asyncio.iscoroutinefunction(callback):
                        await callback(event_type, event_data)
                    else:
                        # Ø§Ú¯Ø± sync Ø§Ø³Øª Ø¯Ø± thread Ø§Ø¬Ø±Ø§ Ú©Ù†
                        loop = asyncio.get_event_loop()
                        await loop.run_in_executor(None, callback, event_type, event_data)
                except Exception as e:
                    logger.error(f"âŒ Error notifying subscriber: {e}")
    
    def _calculate_adaptive_sleep(self, execution_time: float, metrics: Dict, cycle: int) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®ÙˆØ§Ø¨ ØªØ·Ø¨ÛŒÙ‚ÛŒ"""
        # Ø­Ø¯Ø§Ù‚Ù„ Ø®ÙˆØ§Ø¨
        min_sleep = 0.5
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø± Ø³ÛŒØ³ØªÙ…
        cpu_usage = metrics.get('cpu', {}).get('percent', 0)
        memory_usage = metrics.get('memory', {}).get('percent', 0)
        
        # Ø®ÙˆØ§Ø¨ Ù¾Ø§ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ priority
        base_sleep = 2.0  # 2 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ real-time metrics
        
        # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø§Ø±
        if cpu_usage > 80 or memory_usage > 85:
            # Ø³ÛŒØ³ØªÙ… ØªØ­Øª Ø¨Ø§Ø± - Ø®ÙˆØ§Ø¨ Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ù†Ø¸Ø§Ø±Øª Ø¨ÛŒØ´ØªØ±
            adaptive_sleep = max(min_sleep, base_sleep * 0.5)
        elif cpu_usage < 30 and memory_usage < 50:
            # Ø³ÛŒØ³ØªÙ… Ø®Ù„ÙˆØª - Ø®ÙˆØ§Ø¨ Ø¨ÛŒØ´ØªØ±
            adaptive_sleep = base_sleep * 1.5
        else:
            # Ø­Ø§Ù„Øª Ù†Ø±Ù…Ø§Ù„
            adaptive_sleep = base_sleep
        
        # ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§
        if execution_time > adaptive_sleep * 0.8:
            # Ø§Ú¯Ø± Ø§Ø¬Ø±Ø§ Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø¨ÙˆØ¯ØŒ Ø®ÙˆØ§Ø¨ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø¯Ù‡
            adaptive_sleep = min(10.0, adaptive_sleep * 1.2)
        
        return adaptive_sleep
    
    # ==================== PUBLIC API ====================
    
    def subscribe(self, event_type: str, callback: Callable):
        """Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§"""
        self.subscribers[event_type].append(callback)
        logger.info(f"ðŸ“¡ New subscriber for {event_type}")
    
    def unsubscribe(self, event_type: str, callback: Callable):
        """Ù„ØºÙˆ Ø¹Ø¶ÙˆÛŒØª"""
        if event_type in self.subscribers and callback in self.subscribers[event_type]:
            self.subscribers[event_type].remove(callback)
            logger.info(f"ðŸ“¡ Removed subscriber from {event_type}")
    
    def get_current_metrics(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ (Ø¨Ø±Ø§ÛŒ backward compatibility)"""
        if not self.last_metrics:
            return self._get_fallback_metrics()
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ… Ø¨Ø±Ø§ÛŒ compatibility
        return {
            'timestamp': self.last_metrics.get('timestamp'),
            'system': {
                'cpu': self.last_metrics.get('cpu', {'percent': 0}),
                'memory': self.last_metrics.get('memory', {'percent': 0}),
                'disk': self.last_metrics.get('disk', {'usage_percent': 0}),
                'network': self.last_metrics.get('network', {}),
                'process': self.last_metrics.get('process', {})
            },
            'collection_time': self.last_metrics.get('collection_time'),
            'from_cache': True
        }
    
    def get_system_health(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ… (Ø¨Ø±Ø§ÛŒ backward compatibility)"""
        if not self.last_health_score:
            return {
                'timestamp': datetime.now().isoformat(),
                'overall_health': 'unknown',
                'health_indicators': {},
                'metrics_snapshot': {}
            }
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ…
        return {
            'timestamp': self.last_health_score.get('timestamp'),
            'overall_health': self.last_health_score.get('overall_status', 'unknown'),
            'health_indicators': {
                component: {
                    'status': score_data.get('status', 'unknown'),
                    'message': f"Score: {score_data.get('score', 0)}",
                    'usage_percent': score_data.get('value', 0)
                }
                for component, score_data in self.last_health_score.get('component_scores', {}).items()
            },
            'metrics_snapshot': {
                'cpu_usage': self.last_metrics.get('cpu', {}).get('percent', 0),
                'memory_usage': self.last_metrics.get('memory', {}).get('percent', 0),
                'disk_usage': self.last_metrics.get('disk', {}).get('usage_percent', 0)
            }
        }
    
    def get_detailed_status(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª ØªÙØµÛŒÙ„ÛŒ (Ø¬Ø¯ÛŒØ¯)"""
        return {
            'monitoring_status': {
                'is_running': self.is_monitoring,
                'cycle_count': len(self.metrics_history),
                'last_collection': self.last_metrics.get('timestamp') if self.last_metrics else None,
                'active_anomalies': len(self.active_anomalies)
            },
            'cache_stats': self.cache.get_cache_stats(),
            'hierarchical_status': self.hierarchical_monitor.get_status(),
            'health_score': self.last_health_score,
            'predictions': self.predictive_monitor.get_all_predictions(),
            'system_info': {
                'python_version': f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                'platform': sys.platform,
                'monitor_version': '3.0'
            }
        }
    
    def _get_fallback_metrics(self) -> Dict[str, Any]:
        """Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡"""
        return {
            'timestamp': datetime.now().isoformat(),
            'system': {
                'cpu': {'percent': 0, 'cores': 1, 'load_avg': [0, 0, 0]},
                'memory': {'percent': 0, 'used_gb': 0, 'available_gb': 0, 'total_gb': 0},
                'disk': {'usage_percent': 0, 'used_gb': 0, 'free_gb': 0, 'total_gb': 0},
                'network': {'bytes_sent_mb': 0, 'bytes_recv_mb': 0},
                'process': {'memory_rss_mb': 0, 'cpu_percent': 0, 'threads_count': 0}
            },
            'collection_time': time.time(),
            'from_cache': False,
            'is_fallback': True
        }

# ==================== GLOBAL INSTANCE & HELPER FUNCTIONS ====================

central_monitor = None

def initialize_central_monitoring():
    """ØªØ§Ø¨Ø¹ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ main.py"""
    global central_monitor
    
    if central_monitor:
        logger.warning("âš ï¸ Central monitor already initialized")
        return central_monitor
    
    central_monitor = CentralMonitoringSystem()
    
    # ØªÙ†Ø¸ÛŒÙ… logger
    logger.info("=" * 60)
    logger.info("ðŸš€ VORTEXAI MONITORING SYSTEM v3.0")
    logger.info("ðŸ“Š Features: Smart Cache, Anomaly Detection, Health Scoring")
    logger.info("ðŸŽ¯ Architecture: Event-Driven, Hierarchical, Async")
    logger.info("=" * 60)
    
    return central_monitor

async def start_monitoring():
    """Ø´Ø±ÙˆØ¹ Ù†Ø¸Ø§Ø±Øª (Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± main.py)"""
    global central_monitor
    
    if not central_monitor:
        initialize_central_monitoring()
    
    await central_monitor.start_monitoring()

async def stop_monitoring():
    """ØªÙˆÙ‚Ù Ù†Ø¸Ø§Ø±Øª"""
    global central_monitor
    
    if central_monitor:
        await central_monitor.stop_monitoring()

# ==================== COMPATIBILITY WRAPPER ====================

class SystemMonitor:
    """
    Ú©Ù„Ø§Ø³ wrapper Ø¨Ø±Ø§ÛŒ backward compatibility
    Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø§Ø² Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ù†Ø¯
    """
    
    def __init__(self, metrics_collector=None, alert_manager=None):
        # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ compatibility Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
        self.metrics_collector = metrics_collector
        self.alert_manager = alert_manager
        
        global central_monitor
        if central_monitor:
            central_monitor.subscribe("legacy_system", self._on_metrics_update)
            logger.info("âœ… Legacy SystemMonitor subscribed to central_monitor")
        else:
            logger.warning("âš ï¸ Central monitor not available - using fallback mode")
    
    def _on_metrics_update(self, event_type: str, event_data: Dict):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ù…Ø±Ú©Ø²ÛŒ"""
        # Ø§ÛŒÙ† Ù…ØªØ¯ Ø¨Ø±Ø§ÛŒ compatibility Ø¨Ø§ Ú©Ø¯ Ù‚Ø¯ÛŒÙ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø´Ø¯Ù‡
        pass
    
    def get_system_health(self) -> Dict[str, Any]:
        """Ù…ØªØ¯ Ù‚Ø¯ÛŒÙ… - Ø¨Ø±Ø§ÛŒ backward compatibility"""
        global central_monitor
        
        if central_monitor:
            return central_monitor.get_system_health()
        else:
            # Fallback mode
            return {
                'timestamp': datetime.now().isoformat(),
                'overall_health': 'unknown',
                'health_indicators': {},
                'metrics_snapshot': {}
            }
    
    def get_resource_usage_trend(self, hours: int = 6) -> Dict[str, Any]:
        """Ù…ØªØ¯ Ù‚Ø¯ÛŒÙ… - Ø¨Ø±Ø§ÛŒ backward compatibility"""
        # Ø§ÛŒÙ† Ù…ØªØ¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ø² history Ø³ÛŒØ³ØªÙ… Ù…Ø±Ú©Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯
        return {
            'time_period_hours': hours,
            'data_points': 0,
            'trends': {},
            'timestamp': datetime.now().isoformat()
        }
    
    # Ø¯ÛŒÚ¯Ø± Ù…ØªØ¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆÙ†Ø¯...

# ==================== FASTAPI ROUTES INTEGRATION ====================

def setup_monitoring_routes(app):
    """ØªÙ†Ø¸ÛŒÙ… routeÙ‡Ø§ÛŒ Ù†Ø¸Ø§Ø±Øª Ø¨Ø±Ø§ÛŒ FastAPI"""
    
    @app.get("/api/monitoring/status")
    async def get_monitoring_status():
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ù†Ø¸Ø§Ø±Øª"""
        global central_monitor
        
        if not central_monitor:
            return {"status": "not_initialized"}
        
        return {
            "status": "running" if central_monitor.is_monitoring else "stopped",
            "details": central_monitor.get_detailed_status()
        }
    
    @app.get("/api/monitoring/metrics")
    async def get_current_metrics():
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ø±ÛŒ"""
        global central_monitor
        
        if not central_monitor:
            return {"error": "Monitoring not initialized"}
        
        return central_monitor.get_current_metrics()
    
    @app.get("/api/monitoring/health")
    async def get_system_health():
        """Ø¯Ø±ÛŒØ§ÙØª Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…"""
        global central_monitor
        
        if not central_monitor:
            return {"error": "Monitoring not initialized"}
        
        return central_monitor.get_system_health()
    
    @app.post("/api/monitoring/start")
    async def start_monitoring_endpoint():
        """Ø´Ø±ÙˆØ¹ Ù†Ø¸Ø§Ø±Øª"""
        await start_monitoring()
        return {"status": "started"}
    
    @app.post("/api/monitoring/stop")
    async def stop_monitoring_endpoint():
        """ØªÙˆÙ‚Ù Ù†Ø¸Ø§Ø±Øª"""
        await stop_monitoring()
        return {"status": "stopped"}
    
    @app.get("/api/monitoring/dashboard")
    async def get_dashboard():
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…ØªÙ†ÛŒ"""
        global central_monitor
        
        if not central_monitor or not central_monitor.last_metrics:
            return {"dashboard": "Monitoring not active"}
        
        dashboard_text = central_monitor.dashboard.generate_dashboard(
            central_monitor.last_metrics,
            central_monitor.last_health_score,
            central_monitor.active_anomalies
        )
        
        return {"dashboard": dashboard_text}
