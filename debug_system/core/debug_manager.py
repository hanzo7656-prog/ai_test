import time
import asyncio
import psutil
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable
from collections import defaultdict, deque
import threading
import json
import traceback
from dataclasses import dataclass
from enum import Enum

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø³ÛŒØ³ØªÙ… Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø¯ÛŒØ¯
try:
    from ..utils.data_normalizer import data_normalizer
except ImportError:
    # Fallback Ø¨Ø±Ø§ÛŒ Ù…ÙˆØ§Ù‚Ø¹ ØªÙˆØ³Ø¹Ù‡
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from debug_system.utils.data_normalizer import data_normalizer

logger = logging.getLogger(__name__)

class DebugLevel(Enum):
    INFO = "INFO"
    WARNING = "WARNING" 
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

@dataclass
class EndpointCall:
    endpoint: str
    method: str
    timestamp: datetime
    params: Dict[str, Any]
    response_time: float
    status_code: int
    cache_used: bool
    api_calls: int
    memory_used: float
    cpu_impact: float
    normalization_info: Optional[Dict[str, Any]] = None  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯

@dataclass
class SystemMetrics:
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    network_io: Dict[str, int]
    active_connections: int
    normalization_metrics: Optional[Dict[str, Any]] = None  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯

class DebugManager:
    def __init__(self):
        self.endpoint_calls = deque(maxlen=10000)  # Ø¢Ø®Ø±ÛŒÙ† Û±Û°Û°Û°Û° ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ
        self.system_metrics_history = deque(maxlen=1000)  # Ø¢Ø®Ø±ÛŒÙ† Û±Û°Û°Û° Ù…ØªØ±ÛŒÚ© Ø³ÛŒØ³ØªÙ…
        self.endpoint_stats = defaultdict(lambda: {
            'total_calls': 0,
            'successful_calls': 0,
            'failed_calls': 0,
            'total_response_time': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'api_calls': 0,
            'normalization_stats': {  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                'total_normalized': 0,
                'normalization_errors': 0,
                'avg_quality_score': 0,
                'common_structures': {}
            },
            'errors': [],
            'last_call': None
        })
        
        self.alerts = []
        self.performance_thresholds = {
            'response_time_warning': 1.0,  # Ø«Ø§Ù†ÛŒÙ‡
            'response_time_critical': 3.0,
            'cpu_warning': 80.0,  # Ø¯Ø±ØµØ¯
            'cpu_critical': 95.0,
            'memory_warning': 85.0,
            'memory_critical': 95.0,
            'normalization_error_threshold': 10  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
        }
        
        self.alert_manager = None  # Ø§Ø¨ØªØ¯Ø§ NoneØŒ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒØ´ÙˆØ¯
        
        self._start_background_monitoring()
    
    def set_alert_manager(self, alert_manager):
        """ØªÙ†Ø¸ÛŒÙ… alert manager"""
        self.alert_manager = alert_manager
        logger.info("âœ… Alert Manager set for Debug Manager")
        
    def log_endpoint_call(self, endpoint: str, method: str, params: Dict[str, Any], 
                         response_time: float, status_code: int, cache_used: bool, 
                         api_calls: int = 0, normalization_info: Dict[str, Any] = None):
        """Ø«Ø¨Øª ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª"""
        try:
            # Ú¯Ø±ÙØªÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø¯Ø± Ù„Ø­Ø¸Ù‡ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ
            memory_used = psutil.virtual_memory().percent
            cpu_impact = psutil.cpu_percent(interval=0.1)
            
            call = EndpointCall(
                endpoint=endpoint,
                method=method,
                timestamp=datetime.now(),
                params=params,
                response_time=response_time,
                status_code=status_code,
                cache_used=cache_used,
                api_calls=api_calls,
                memory_used=memory_used,
                cpu_impact=cpu_impact,
                normalization_info=normalization_info  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
            )
            
            self.endpoint_calls.append(call)
            
            # Ø¢Ù¾Ø¯ÛŒØª Ø¢Ù…Ø§Ø± Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª
            stats = self.endpoint_stats[endpoint]
            stats['total_calls'] += 1
            stats['total_response_time'] += response_time
            
            if 200 <= status_code < 300:
                stats['successful_calls'] += 1
            else:
                stats['failed_calls'] += 1
                stats['errors'].append({
                    'timestamp': datetime.now().isoformat(),
                    'status_code': status_code,
                    'params': params
                })
                
            if cache_used:
                stats['cache_hits'] += 1
            else:
                stats['cache_misses'] += 1
                
            stats['api_calls'] += api_calls
            stats['last_call'] = datetime.now().isoformat()
            
            # âœ… Ø¢Ù¾Ø¯ÛŒØª Ø¢Ù…Ø§Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            if normalization_info:
                norm_stats = stats['normalization_stats']
                norm_stats['total_normalized'] += 1
                
                if normalization_info.get('status') == 'error':
                    norm_stats['normalization_errors'] += 1
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©ÛŒÙÛŒØª
                quality_score = normalization_info.get('quality_score', 0)
                current_avg = norm_stats['avg_quality_score']
                total_norm = norm_stats['total_normalized']
                norm_stats['avg_quality_score'] = (current_avg * (total_norm - 1) + quality_score) / total_norm
                
                # Ø¢Ù¾Ø¯ÛŒØª Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬
                structure = normalization_info.get('detected_structure', 'unknown')
                norm_stats['common_structures'][structure] = norm_stats['common_structures'].get(structure, 0) + 1
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ performance
            self._check_performance_alerts(endpoint, call)
            
            logger.debug(f"ğŸ“Š Endpoint logged: {endpoint} - {response_time:.3f}s")
            
        except Exception as e:
            logger.error(f"âŒ Error logging endpoint call: {e}")
    
    def log_error(self, endpoint: str, error: Exception, traceback_str: str, context: Dict[str, Any] = None):
        """Ø«Ø¨Øª Ø®Ø·Ø§"""
        error_data = {
            'endpoint': endpoint,
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback_str,
            'context': context or {},
            'timestamp': datetime.now().isoformat()
        }
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¢Ù…Ø§Ø± Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª
        self.endpoint_stats[endpoint]['errors'].append(error_data)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ critical
        if self._is_critical_error(error):
            self._create_alert(
                level=DebugLevel.CRITICAL,
                message=f"Critical error in {endpoint}: {str(error)}",
                source=endpoint,
                data=error_data
            )
        
        logger.error(f"ğŸš¨ Error in {endpoint}: {error}")
    
    def get_endpoint_stats(self, endpoint: str = None) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª"""
        if endpoint:
            if endpoint not in self.endpoint_stats:
                return {'error': 'Endpoint not found'}
            
            stats = self.endpoint_stats[endpoint]
            avg_response_time = (stats['total_response_time'] / stats['total_calls']) if stats['total_calls'] > 0 else 0
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            norm_stats = stats['normalization_stats']
            normalization_success_rate = ((norm_stats['total_normalized'] - norm_stats['normalization_errors']) / norm_stats['total_normalized'] * 100) if norm_stats['total_normalized'] > 0 else 0
            
            return {
                'endpoint': endpoint,
                'total_calls': stats['total_calls'],
                'successful_calls': stats['successful_calls'],
                'failed_calls': stats['failed_calls'],
                'success_rate': (stats['successful_calls'] / stats['total_calls'] * 100) if stats['total_calls'] > 0 else 0,
                'average_response_time': round(avg_response_time, 3),
                'cache_performance': {
                    'hits': stats['cache_hits'],
                    'misses': stats['cache_misses'],
                    'hit_rate': (stats['cache_hits'] / (stats['cache_hits'] + stats['cache_misses']) * 100) if (stats['cache_hits'] + stats['cache_misses']) > 0 else 0
                },
                'api_calls': stats['api_calls'],
                'normalization_performance': {  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                    'total_normalized': norm_stats['total_normalized'],
                    'normalization_errors': norm_stats['normalization_errors'],
                    'success_rate': round(normalization_success_rate, 2),
                    'avg_quality_score': round(norm_stats['avg_quality_score'], 2),
                    'common_structures': norm_stats['common_structures']
                },
                'recent_errors': stats['errors'][-10:],  # Ø¢Ø®Ø±ÛŒÙ† Û±Û° Ø®Ø·Ø§
                'last_call': stats['last_call']
            }
        else:
            # Ø¢Ù…Ø§Ø± ØªÙ…Ø§Ù… Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§
            all_stats = {}
            total_calls = 0
            total_success = 0
            total_normalized = 0
            total_norm_errors = 0
            
            for endpoint, stats in self.endpoint_stats.items():
                norm_stats = stats['normalization_stats']
                total_normalized += norm_stats['total_normalized']
                total_norm_errors += norm_stats['normalization_errors']
                
                all_stats[endpoint] = {
                    'total_calls': stats['total_calls'],
                    'success_rate': (stats['successful_calls'] / stats['total_calls'] * 100) if stats['total_calls'] > 0 else 0,
                    'average_response_time': round((stats['total_response_time'] / stats['total_calls']), 3) if stats['total_calls'] > 0 else 0,
                    'normalization_success_rate': ((norm_stats['total_normalized'] - norm_stats['normalization_errors']) / norm_stats['total_normalized'] * 100) if norm_stats['total_normalized'] > 0 else 0,
                    'last_call': stats['last_call']
                }
                total_calls += stats['total_calls']
                total_success += stats['successful_calls']
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            overall_norm_metrics = data_normalizer.get_health_metrics()
            
            return {
                'overall': {
                    'total_endpoints': len(self.endpoint_stats),
                    'total_calls': total_calls,
                    'overall_success_rate': (total_success / total_calls * 100) if total_calls > 0 else 0,
                    'normalization_overview': {  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                        'total_normalized': total_normalized,
                        'normalization_errors': total_norm_errors,
                        'normalization_success_rate': ((total_normalized - total_norm_errors) / total_normalized * 100) if total_normalized > 0 else 0,
                        'system_success_rate': overall_norm_metrics.success_rate,
                        'common_structures': overall_norm_metrics.common_structures
                    },
                    'timestamp': datetime.now().isoformat()
                },
                'endpoints': all_stats
            }
    
    def get_recent_calls(self, limit: int = 50) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒâ€ŒÙ‡Ø§"""
        recent_calls = list(self.endpoint_calls)[-limit:]
        return [
            {
                'endpoint': call.endpoint,
                'method': call.method,
                'timestamp': call.timestamp.isoformat(),
                'response_time': call.response_time,
                'status_code': call.status_code,
                'cache_used': call.cache_used,
                'api_calls': call.api_calls,
                'memory_used': call.memory_used,
                'cpu_impact': call.cpu_impact,
                'normalization_info': call.normalization_info  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
            }
            for call in recent_calls
        ]
    
    def get_system_metrics_history(self, hours: int = 1) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙØ¹Ù„ÛŒ
        current_norm_metrics = data_normalizer.get_health_metrics()
        
        return [
            {
                'timestamp': metrics.timestamp.isoformat(),
                'cpu_percent': metrics.cpu_percent,
                'memory_percent': metrics.memory_percent,
                'disk_usage': metrics.disk_usage,
                'network_io': metrics.network_io,
                'active_connections': metrics.active_connections,
                'normalization_metrics': {  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                    'success_rate': current_norm_metrics.success_rate,
                    'total_processed': current_norm_metrics.total_processed,
                    'data_quality': current_norm_metrics.data_quality
                } if metrics.normalization_metrics is None else metrics.normalization_metrics
            }
            for metrics in self.system_metrics_history
            if metrics.timestamp >= cutoff_time
        ]
    
    def _start_background_monitoring(self):
        """Ø´Ø±ÙˆØ¹ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø³ÛŒØ³ØªÙ…"""
        def monitor_system():
            while True:
                try:
                    self._collect_system_metrics()
                    self._check_normalization_alerts()  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                    time.sleep(5)  # Ù‡Ø± Ûµ Ø«Ø§Ù†ÛŒÙ‡
                except Exception as e:
                    logger.error(f"âŒ System monitoring error: {e}")
                    time.sleep(10)
        
        monitor_thread = threading.Thread(target=monitor_system, daemon=True)
        monitor_thread.start()
        logger.info("âœ… Background system monitoring started")
    
    def _collect_system_metrics(self):
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            disk_usage = psutil.disk_usage('/').percent
            
            net_io = psutil.net_io_counters()
            network_io = {
                'bytes_sent': net_io.bytes_sent,
                'bytes_recv': net_io.bytes_recv,
                'packets_sent': net_io.packets_sent,
                'packets_recv': net_io.packets_recv
            }
            
            active_connections = len(psutil.net_connections())
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            norm_metrics = data_normalizer.get_health_metrics()
            
            metrics = SystemMetrics(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                disk_usage=disk_usage,
                network_io=network_io,
                active_connections=active_connections,
                normalization_metrics={  # âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                    'success_rate': norm_metrics.success_rate,
                    'total_processed': norm_metrics.total_processed,
                    'data_quality': norm_metrics.data_quality
                }
            )
            
            self.system_metrics_history.append(metrics)
            
        except Exception as e:
            logger.error(f"âŒ Error collecting system metrics: {e}")
    
    def _check_normalization_alerts(self):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ"""
        try:
            metrics = data_normalizer.get_health_metrics()
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø§ÛŒÛŒÙ† Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            if metrics.success_rate < 90:
                self._create_alert(
                    level=DebugLevel.WARNING,
                    message=f"Low normalization success rate: {metrics.success_rate}%",
                    source="data_normalizer",
                    data={
                        'success_rate': metrics.success_rate,
                        'total_processed': metrics.total_processed,
                        'total_errors': metrics.total_errors
                    }
                )
            
            # Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            if metrics.total_errors > self.performance_thresholds['normalization_error_threshold']:
                self._create_alert(
                    level=DebugLevel.ERROR,
                    message=f"High normalization errors: {metrics.total_errors}",
                    source="data_normalizer",
                    data={
                        'total_errors': metrics.total_errors,
                        'threshold': self.performance_thresholds['normalization_error_threshold']
                    }
                )
                
        except Exception as e:
            logger.error(f"âŒ Error checking normalization alerts: {e}")
    
    def _check_performance_alerts(self, endpoint: str, call: EndpointCall):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ performance"""
        # Ù‡Ø´Ø¯Ø§Ø± Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®â€ŒÚ¯ÙˆÛŒÛŒ
        if call.response_time > self.performance_thresholds['response_time_critical']:
            self._create_alert(
                level=DebugLevel.CRITICAL,
                message=f"Critical response time in {endpoint}: {call.response_time:.2f}s",
                source=endpoint,
                data={
                    'response_time': call.response_time,
                    'threshold': self.performance_thresholds['response_time_critical']
                }
            )
        elif call.response_time > self.performance_thresholds['response_time_warning']:
            self._create_alert(
                level=DebugLevel.WARNING,
                message=f"High response time in {endpoint}: {call.response_time:.2f}s",
                source=endpoint,
                data={
                    'response_time': call.response_time,
                    'threshold': self.performance_thresholds['response_time_warning']
                }
            )
        
        # Ù‡Ø´Ø¯Ø§Ø± Ù…ØµØ±Ù CPU
        if call.cpu_impact > self.performance_thresholds['cpu_critical']:
            self._create_alert(
                level=DebugLevel.CRITICAL,
                message=f"Critical CPU usage in {endpoint}: {call.cpu_impact:.1f}%",
                source=endpoint,
                data={'cpu_usage': call.cpu_impact}
            )
        
        # âœ… Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        if call.normalization_info and call.normalization_info.get('status') == 'error':
            self._create_alert(
                level=DebugLevel.ERROR,
                message=f"Normalization error in {endpoint}: {call.normalization_info.get('error', 'Unknown error')}",
                source=endpoint,
                data=call.normalization_info
            )
    
    def _create_alert(self, level: DebugLevel, message: str, source: str, data: Dict[str, Any]):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ø´Ø¯Ø§Ø± Ø¬Ø¯ÛŒØ¯"""
        alert = {
            'id': len(self.alerts) + 1,
            'level': level.value,
            'message': message,
            'source': source,
            'timestamp': datetime.now().isoformat(),
            'data': data,
            'acknowledged': False
        }
        
        self.alerts.append(alert)
        
        # Ø§Ú¯Ø± alert_manager ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if self.alert_manager:
            try:
                # ğŸ”§ Ø§ØµÙ„Ø§Ø­: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² string-based comparison Ø¨Ù‡ Ø¬Ø§ÛŒ import Ù…Ø³ØªÙ‚ÛŒÙ…
                # Ø§ÛŒÙ† Ø§Ø² circular import Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                alert_level_map = {
                    DebugLevel.INFO.value: "INFO",
                    DebugLevel.WARNING.value: "WARNING", 
                    DebugLevel.ERROR.value: "ERROR",
                    DebugLevel.CRITICAL.value: "CRITICAL"
                }
                
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ alert_manager Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ import
                self.alert_manager.create_alert(
                    level=level.value
                    alert_type="PERFORMANCE",  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² string Ø¨Ù‡ Ø¬Ø§ÛŒ enum
                    title=f"Performance Alert: {message}",
                    message=message,
                    source=source,
                    data=data
                )
            except Exception as e:
                logger.error(f"âŒ Error creating alert in alert_manager: {e}")
        
        logger.warning(f"ğŸš¨ {level.value} Alert: {message}")
    
    def _is_critical_error(self, error: Exception) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø®Ø·Ø§ critical Ø§Ø³Øª"""
        critical_errors = [
            'Timeout',
            'ConnectionError', 
            'MemoryError',
            'OSError'
        ]
        
        return any(critical_error in type(error).__name__ for critical_error in critical_errors)
    
    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„"""
        return [alert for alert in self.alerts if not alert['acknowledged']]
    
    def acknowledge_alert(self, alert_id: int):
        """ØªØ£ÛŒÛŒØ¯ Ù‡Ø´Ø¯Ø§Ø±"""
        for alert in self.alerts:
            if alert['id'] == alert_id:
                alert['acknowledged'] = True
                break
    
    def clear_old_data(self, days: int = 7):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        cutoff_time = datetime.now() - timedelta(days=days)
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
        self.endpoint_calls = deque(
            [call for call in self.endpoint_calls if call.timestamp > cutoff_time],
            maxlen=10000
        )
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
        self.system_metrics_history = deque(
            [metrics for metrics in self.system_metrics_history if metrics.timestamp > cutoff_time],
            maxlen=1000
        )
        
        logger.info(f"ğŸ§¹ Cleared data older than {days} days")

# Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ú¯Ù„ÙˆØ¨Ø§Ù„
debug_manager = DebugManager()
