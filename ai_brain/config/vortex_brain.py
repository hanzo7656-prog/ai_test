from fastapi import APIRouter, HTTPException, Request
from typing import Dict, Any, Optional
import logging
import time
import asyncio

from ai_brain.config.ai_config import AIConfig
from ai_brain.core.neural_network import SparseNeuralNetwork
from ai_brain.core.text_processor import TextProcessor
from ai_brain.core.learning_engine import LearningEngine
from ai_brain.memory.memory_manager import MemoryManager
from ai_brain.memory.knowledge_compressor import KnowledgeCompressor
from ai_brain.integration.api_handler import APIHandler
from ai_brain.integration.response_formatter import ResponseFormatter

logger = logging.getLogger(__name__)

class VortexBrain:
    """Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    
    def __init__(self):
        self.config = AIConfig()
        self.initialized = False
        self.redis_manager = None
        
        # Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        self.neural_network = None
        self.text_processor = None
        self.learning_engine = None
        self.memory_manager = None
        self.knowledge_compressor = None
        self.api_handler = None
        self.response_formatter = None
        
        # ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…
        self.start_time = time.time()
        self.total_requests = 0
        self.successful_requests = 0
        
        logger.info("ğŸ§  VortexAI Brain Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    
    async def initialize(self, redis_manager=None):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ØªÙ…Ø§Ù… Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§"""
        if self.initialized:
            return
        
        try:
            logger.info("ğŸš€ Ø´Ø±ÙˆØ¹ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ VortexAI Brain...")
            
            # ØªØ£ÛŒÛŒØ¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
            if not self.config.validate_config():
                raise Exception("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ù‡Ø³ØªÙ†Ø¯")
            
            # Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
            self.text_processor = TextProcessor(self.config.get('text_processing', {}))
            self.neural_network = SparseNeuralNetwork(self.config.get_neural_network_config())
            self.learning_engine = LearningEngine(self.config.get_learning_config())
            
            self.memory_manager = MemoryManager(self.config.get_memory_config())
            self.knowledge_compressor = KnowledgeCompressor(self.config.get_memory_config())
            
            self.api_handler = APIHandler(self.config.get_api_config())
            self.response_formatter = ResponseFormatter(self.config.get_response_config())
            
            # ØªÙ†Ø¸ÛŒÙ… Ø§ØªØµØ§Ù„ Ø±Ø¯ÛŒØ³
            if redis_manager:
                self.redis_manager = redis_manager
                self.memory_manager.initialize_redis(redis_manager)
                logger.info("âœ… Ø§ØªØµØ§Ù„ Ø±Ø¯ÛŒØ³ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯")
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø­Ø§Ù„Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
            await self._load_saved_state()
            
            # ØªØ³Øª Ø§ØªØµØ§Ù„ APIÙ‡Ø§
            api_test = await self.api_handler.test_api_connections()
            logger.info(f"ğŸ”— ØªØ³Øª Ø§ØªØµØ§Ù„ API: {api_test}")
            
            self.initialized = True
            startup_time = time.time() - self.start_time
            logger.info(f"âœ… VortexAI Brain Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯ - Ø²Ù…Ø§Ù†: {startup_time:.2f}Ø«Ø§Ù†ÛŒÙ‡")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ VortexAI: {e}")
            raise
    
    async def process_query(self, user_input: str, user_id: str = "default") -> Dict[str, Any]:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®"""
        if not self.initialized:
            raise Exception("Ø³ÛŒØ³ØªÙ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
        
        start_time = time.time()
        self.total_requests += 1
        
        try:
            logger.info(f"ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø± {user_id}: {user_input}")
            
            # Ù…Ø±Ø­Ù„Ù‡ Û±: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ùˆ ØªØ´Ø®ÛŒØµ intent
            complexity = self.text_processor.estimate_complexity(user_input)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¸Ø±ÙÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´
            if not self.neural_network.can_process_complexity(complexity):
                response_text = self.response_formatter.format_capacity_error()
                return self._create_response(False, response_text, start_time)
            
            tokens = self.text_processor.preprocess_text(user_input)
            input_vector = self.text_processor.text_to_vector(tokens)
            
            intent, confidence = self.text_processor.detect_intent(user_input)
            extracted_params = self.text_processor.extract_parameters(user_input, intent)
            
            # Ù…Ø±Ø­Ù„Ù‡ Û²: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ
            neural_output = self.neural_network.process_input(input_vector)
            activated_neurons = [i for i, val in enumerate(neural_output) if val > 0.1]
            
            # Ù…Ø±Ø­Ù„Ù‡ Û³: Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
            cached_response = self.memory_manager.retrieve(f"response:{intent}:{user_id}", user_id)
            if cached_response:
                logger.info("ğŸ’¾ Ù¾Ø§Ø³Ø® Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯")
                self.successful_requests += 1
                return self._create_response(True, cached_response, start_time, intent, confidence)
            
            # Ù…Ø±Ø­Ù„Ù‡ Û´: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API
            api_request = self.api_handler.map_intent_to_api(intent, user_input, extracted_params)
            api_response = await self.api_handler.call_api(intent, api_request['params'])
            
            if not api_response.get('success', False):
                error_msg = api_response.get('error', 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± API')
                response_text = self.response_formatter.format_error_response(error_msg)
                
                # ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§
                await self.learning_engine.process_interaction(
                    user_input, activated_neurons, api_response, False
                )
                
                return self._create_response(False, response_text, start_time, intent, confidence)
            
            # Ù…Ø±Ø­Ù„Ù‡ Ûµ: ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù¾Ø§Ø³Ø®
            user_language = self.response_formatter.detect_user_language(user_input)
            response_text = self.response_formatter.format_response(intent, api_response, user_language)
            
            # Ù…Ø±Ø­Ù„Ù‡ Û¶: ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡
            await self.learning_engine.process_interaction(
                user_input, activated_neurons, api_response, True
            )
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
            self.memory_manager.store_sensory(f"response:{intent}:{user_id}", response_text, user_id)
            
            # ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù‡Ø¨ÛŒØ§Ù†
            self.neural_network.hebbian_learn(activated_neurons)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…ÙØ§Ù‡ÛŒÙ…
            if activated_neurons:
                concept_key = f"concept:{intent}:{user_input[:20]}"
                self.neural_network.learn_concept(concept_key, activated_neurons)
            
            self.successful_requests += 1
            
            logger.info(f"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆÙÙ‚ - Intent: {intent}, Confidence: {confidence:.2f}")
            
            return self._create_response(True, response_text, start_time, intent, confidence, api_response)
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„: {e}")
            error_response = self.response_formatter.format_error_response("Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø³ÛŒØ³ØªÙ…")
            return self._create_response(False, error_response, start_time)
    
    def _create_response(self, success: bool, response_text: str, start_time: float, 
                        intent: str = None, confidence: float = None, 
                        api_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """Ø³Ø§Ø®Øª Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        response_time = time.time() - start_time
        
        response = {
            'success': success,
            'response': response_text,
            'response_time': round(response_time, 3),
            'timestamp': time.time(),
            'version': self.config.get('system.version')
        }
        
        if intent:
            response['intent'] = intent
        if confidence:
            response['confidence'] = round(confidence, 3)
        if api_data:
            response['api_data'] = {
                'endpoint': api_data.get('endpoint'),
                'response_time': api_data.get('response_time')
            }
        
        return response
    
    async def _load_saved_state(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø­Ø§Ù„Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø³ÛŒØ³ØªÙ…"""
        try:
            model_path = self.config.get('storage.model_save_path')
            # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø­Ø§Ù„Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø±Ø¯
            logger.info("ğŸ“‚ Ø­Ø§Ù„Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        except Exception as e:
            logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø­Ø§Ù„Øª: {e}")
    
    async def save_state(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø­Ø§Ù„Øª ÙØ¹Ù„ÛŒ Ø³ÛŒØ³ØªÙ…"""
        try:
            model_path = self.config.get('storage.model_save_path')
            # Ø°Ø®ÛŒØ±Ù‡ Ø­Ø§Ù„Øª Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ
            self.neural_network.save_state(model_path)
            
            # Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
            self.config.save_to_file(model_path.replace('.json', '_config.json'))
            
            logger.info("ğŸ’¾ Ø­Ø§Ù„Øª Ø³ÛŒØ³ØªÙ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø­Ø§Ù„Øª: {e}")
    
    def get_system_health(self) -> Dict[str, Any]:
        """Ú¯Ø²Ø§Ø±Ø´ Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…"""
        if not self.initialized:
            return {'status': 'not_initialized', 'message': 'Ø³ÛŒØ³ØªÙ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡'}
        
        try:
            # Ø¢Ù…Ø§Ø± Ø§Ø² Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            nn_stats = self.neural_network.get_network_stats()
            memory_stats = self.memory_manager.get_memory_stats()
            learning_stats = self.learning_engine.get_learning_stats()
            compression_stats = self.knowledge_compressor.get_compression_stats()
            
            uptime = time.time() - self.start_time
            success_rate = (self.successful_requests / self.total_requests) * 100 if self.total_requests > 0 else 0
            
            return {
                'status': 'healthy',
                'uptime_seconds': round(uptime, 2),
                'total_requests': self.total_requests,
                'success_rate': round(success_rate, 2),
                'components': {
                    'neural_network': nn_stats,
                    'memory': memory_stats,
                    'learning': learning_stats,
                    'compression': compression_stats
                },
                'config_summary': self.config.get_config_summary()
            }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ø³Ù„Ø§Ù…Øª: {e}")
            return {'status': 'error', 'error': str(e)}
    
    async def cleanup(self):
        """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø®Ø§ØªÙ…Ù‡"""
        try:
            # Ø°Ø®ÛŒØ±Ù‡ Ø­Ø§Ù„Øª Ù†Ù‡Ø§ÛŒÛŒ
            await self.save_state()
            
            # Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„Ø§Øª
            if self.api_handler:
                await self.api_handler.close()
            
            # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡
            if self.memory_manager:
                self.memory_manager.cleanup_expired()
            
            logger.info("ğŸ§¹ VortexAI Brain Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ: {e}")

# Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ø§ØµÙ„ÛŒ Ùˆ Ø±ÙˆØª FastAPI
vortex_brain = VortexBrain()
ai_router = APIRouter()

@ai_router.on_event("startup")
async def startup_event():
    """Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ"""
    try:
        from debug_system.storage.redis_manager import redis_manager
        await vortex_brain.initialize(redis_manager)
    except ImportError:
        await vortex_brain.initialize()
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ: {e}")

@ai_router.on_event("shutdown")
async def shutdown_event():
    """Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø®Ø§Ù…ÙˆØ´â€ŒØ³Ø§Ø²ÛŒ"""
    await vortex_brain.cleanup()

@ai_router.post("/query")
async def process_ai_query(request: Request):
    """Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø§ØµÙ„ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„Ø§Øª"""
    try:
        data = await request.json()
        user_input = data.get('question', '').strip()
        user_id = data.get('user_id', 'default')
        
        if not user_input:
            raise HTTPException(status_code=400, detail="Ø³ÙˆØ§Ù„ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª")
        
        response = await vortex_brain.process_query(user_input, user_id)
        return response
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª query: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@ai_router.get("/health")
async def get_ai_health():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    health_report = vortex_brain.get_system_health()
    return health_report

@ai_router.get("/stats")
async def get_ai_stats():
    """Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    health = vortex_brain.get_system_health()
    return {
        'performance': {
            'total_requests': vortex_brain.total_requests,
            'successful_requests': vortex_brain.successful_requests,
            'success_rate': health.get('success_rate', 0)
        },
        'system': health.get('components', {})
    }

@ai_router.post("/learn")
async def submit_learning_material(request: Request):
    """Ø§Ø±Ø³Ø§Ù„ Ù…Ø·Ø§Ù„Ø¨ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
    try:
        data = await request.json()
        text_material = data.get('text', '').strip()
        
        if not text_material:
            raise HTTPException(status_code=400, detail="Ù…ØªÙ† Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª")
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¢Ù…ÙˆØ²Ø´ÛŒ
        tokens = vortex_brain.text_processor.preprocess_text(text_material)
        input_vector = vortex_brain.text_processor.text_to_vector(tokens)
        neural_output = vortex_brain.neural_network.process_input(input_vector)
        activated_neurons = [i for i, val in enumerate(neural_output) if val > 0.1]
        
        # ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù…ØªÙ† Ø¢Ù…ÙˆØ²Ø´ÛŒ
        vortex_brain.neural_network.hebbian_learn(activated_neurons)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª
        vortex_brain.memory_manager.store_long_term(
            f"training:{hash(text_material)}", 
            {'text': text_material, 'type': 'training'}, 
            "system"
        )
        
        return {
            'success': True,
            'message': 'Ù…Ø·Ù„Ø¨ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯',
            'activated_neurons': len(activated_neurons)
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø² health router
async def get_ai_health():
    """ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± health router Ø§ØµÙ„ÛŒ"""
    return vortex_brain.get_system_health()
