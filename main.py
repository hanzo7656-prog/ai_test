# main.py - Ø³Ø±ÙˆØ± Ø§ØµÙ„ÛŒ VortexAI Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
from fastapi import FastAPI, HTTPException, Query, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import os
from datetime import datetime
import logging
import time
import psutil
from pathlib import Path

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="VortexAI API", version="2.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø¯ÛŒØ± CoinStats
try:
    from complete_coinstats_manager import coin_stats_manager
    COINSTATS_AVAILABLE = True
    logger.info("âœ… CoinStats Manager loaded successfully")
except ImportError as e:
    COINSTATS_AVAILABLE = False
    logger.error(f"âŒ CoinStats Manager import failed: {e}")

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø³ÛŒØ³ØªÙ… GitHub DB
try:
    from github_db import GitHubDBCache, BatchScanner, DataCompressor, ProgressTracker
    GITHUB_DB_AVAILABLE = True
    logger.info("âœ… GitHub DB System loaded successfully")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§
    github_cache = GitHubDBCache()
    batch_scanner = BatchScanner(github_cache)
    data_compressor = DataCompressor()
    progress_tracker = ProgressTracker()
    
except ImportError as e:
    GITHUB_DB_AVAILABLE = False
    logger.error(f"âŒ GitHub DB import failed: {e}")

# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª
class ScanRequest(BaseModel):
    symbols: List[str]
    limit: Optional[int] = 100

class MultiScanRequest(BaseModel):
    symbols: List[str]
    scan_type: str = "basic"
    limit: Optional[int] = 100

# Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
class DataProcessor:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÛŒÙ†"""
    
    @staticmethod
    def get_ai_scan_data(symbol: str, limit: int = 500) -> Dict[str, Any]:
        """Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªØ­Ù„ÛŒÙ„Ú¯Ø± ØªÚ©Ù†ÛŒÚ©Ø§Ù„"""
        try:
            start_time = time.time()
            
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø² API
            raw_details = coin_stats_manager.get_coin_details(symbol, "USD")
            raw_charts = coin_stats_manager.get_coin_charts(symbol, "1w")
            market_context = coin_stats_manager.get_coins_list(limit=min(limit, 1000))
            
            response_time = round((time.time() - start_time) * 1000, 2)
            
            # Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… Ø¨Ø±Ø§ÛŒ AI
            ai_data = {
                "data_type": "raw",
                "purpose": "ai_technical_analysis",
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "response_time_ms": response_time,
                
                # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§ØµÙ„ÛŒ
                "raw_data": {
                    "coin_details": raw_details,
                    "price_charts": raw_charts,
                    "market_context": market_context
                },
                
                # Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ ÙÙ†ÛŒ
                "technical_metadata": {
                    "data_sources": ["coinstats_api"],
                    "update_frequency": "real_time",
                    "data_quality": "high",
                    "fields_available": list(raw_details.keys()) if isinstance(raw_details, dict) else []
                }
            }
            
            return ai_data
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ AI Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
            return {
                "data_type": "raw",
                "purpose": "ai_technical_analysis", 
                "symbol": symbol,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    @staticmethod
    def get_basic_scan_data(symbol: str, limit: int = 100) -> Dict[str, Any]:
        """Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¹Ù…ÙˆÙ„ÛŒ"""
        try:
            start_time = time.time()
            
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù…
            raw_details = coin_stats_manager.get_coin_details(symbol, "USD")
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø·Ø§
            if isinstance(raw_details, dict) and "error" in raw_details:
                return {
                    "success": False,
                    "error": raw_details["error"],
                    "symbol": symbol
                }
            
            # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ ÛŒÚ© Ù„ÛŒØ³Øª Ø¨Ø§Ø´Ø¯ (Ø³Ø§Ø®ØªØ§Ø± ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡)
            if isinstance(raw_details, list):
                if len(raw_details) > 0:
                    coin_data = raw_details[0]  # Ø§ÙˆÙ„ÛŒÙ† Ø¢ÛŒØªÙ… Ø±Ø§ Ø¨Ú¯ÛŒØ±
                else:
                    return {
                        "success": False,
                        "error": "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯",
                        "symbol": symbol
                    }
            else:
                coin_data = raw_details  # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            
            response_time = round((time.time() - start_time) * 1000, 2)
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯
            processed_data = {
                "data_type": "processed",
                "purpose": "basic_display",
                "success": True,
                "symbol": symbol,
                "response_time_ms": response_time,
                "timestamp": datetime.now().isoformat(),
                
                # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ
                "display_data": {
                    "name": coin_data.get('name', 'Unknown'),
                    "symbol": coin_data.get('symbol', 'UNKNOWN'),
                    "price": coin_data.get('price', 0),
                    "price_formatted": f"${coin_data.get('price', 0):,.2f}",
                    "price_change_24h": coin_data.get('priceChange1d', 0),
                    "price_change_24h_formatted": f"{coin_data.get('priceChange1d', 0):+.2f}%",
                    "volume_24h": coin_data.get('volume', 0),
                    "volume_24h_formatted": f"${coin_data.get('volume', 0):,.0f}",
                    "market_cap": coin_data.get('marketCap', 0),
                    "market_cap_formatted": f"${coin_data.get('marketCap', 0):,.0f}",
                    "rank": coin_data.get('rank', 0),
                    "rank_formatted": f"#{coin_data.get('rank', 0)}"
                },
                
                # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡
                "analysis": {
                    "signal": DataProcessor._generate_signal(coin_data),
                    "confidence": DataProcessor._calculate_confidence(coin_data),
                    "trend": DataProcessor._analyze_trend(coin_data),
                    "risk_level": DataProcessor._assess_risk(coin_data),
                    "volatility": DataProcessor._calculate_volatility(coin_data)
                },
                
                # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
                "metadata": {
                    "website": coin_data.get('websiteUrl'),
                    "social_links": {
                        "twitter": coin_data.get('twitterUrl'),
                        "reddit": coin_data.get('redditUrl')
                    }
                }
            }
            
            return processed_data
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ {symbol}: {e}")
            return {
                "data_type": "processed",
                "success": False,
                "error": str(e),
                "symbol": symbol,
                "timestamp": datetime.now().isoformat()
            }
    
    @staticmethod
    def _generate_signal(coin_data: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø³Ø§Ø¯Ù‡"""
        change = coin_data.get('priceChange1d', 0)
        if change > 5:
            return "STRONG_BUY"
        elif change > 2:
            return "BUY"
        elif change < -5:
            return "STRONG_SELL"
        elif change < -2:
            return "SELL"
        else:
            return "HOLD"
    
    @staticmethod
    def _calculate_confidence(coin_data: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯"""
        volume = coin_data.get('volume', 0)
        market_cap = coin_data.get('marketCap', 0)
        
        base_confidence = 0.5
        volume_boost = min(0.3, volume / 10000000000)  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø­Ø¬Ù…
        market_cap_boost = min(0.2, market_cap / 1000000000000)  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ø§Ø±Ú©Øª Ú©Ù¾
        
        return round(base_confidence + volume_boost + market_cap_boost, 2)
    
    @staticmethod
    def _analyze_trend(coin_data: Dict) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯"""
        change_1h = coin_data.get('priceChange1h', 0)
        change_1d = coin_data.get('priceChange1d', 0)
        
        if change_1d > 3 and change_1h > 0:
            return "STRONG_UPTREND"
        elif change_1d > 0:
            return "UPTREND"
        elif change_1d < -3 and change_1h < 0:
            return "STRONG_DOWNTREND"
        elif change_1d < 0:
            return "DOWNTREND"
        else:
            return "SIDEWAYS"
    
    @staticmethod
    def _assess_risk(coin_data: Dict) -> str:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÛŒØ³Ú©"""
        volatility = abs(coin_data.get('priceChange1d', 0))
        if volatility > 15:
            return "VERY_HIGH"
        elif volatility > 8:
            return "HIGH"
        elif volatility > 4:
            return "MEDIUM"
        else:
            return "LOW"
    
    @staticmethod
    def _calculate_volatility(coin_data: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ÙˆØ³Ø§Ù†"""
        changes = [
            abs(coin_data.get('priceChange1h', 0)),
            abs(coin_data.get('priceChange1d', 0)),
            abs(coin_data.get('priceChange1w', 0))
        ]
        return round(sum(changes) / len(changes), 2)

# ==================== Ø±ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¬Ø¯ÛŒØ¯ ====================

@app.post("/api/scan/batch/raw")
async def batch_scan_raw(
    request: ScanRequest,
    background_tasks: BackgroundTasks
):
    """Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù… - Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    try:
        if not COINSTATS_AVAILABLE:
            raise HTTPException(status_code=503, detail="CoinStats service unavailable")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§ÛŒØ² Ø¯Ø³ØªÙ‡
        batch_size = min(request.limit, 25)  # Ø­Ø¯Ø§Ú©Ø«Ø± 25 ØªØ§ÛŒÛŒ
        symbols_to_scan = request.symbols[:request.limit]
        
        # Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
        background_tasks.add_task(
            process_raw_batch_scan,
            symbols_to_scan,
            batch_size
        )
        
        return {
            "status": "started",
            "scan_type": "raw",
            "total_symbols": len(symbols_to_scan),
            "batch_size": batch_size,
            "message": "Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù… Ø´Ø±ÙˆØ¹ Ø´Ø¯",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù…: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/scan/batch/processed")
async def batch_scan_processed(
    request: ScanRequest,
    background_tasks: BackgroundTasks
):
    """Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ - Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´"""
    try:
        if not COINSTATS_AVAILABLE:
            raise HTTPException(status_code=503, detail="CoinStats service unavailable")
        
        batch_size = min(request.limit, 25)
        symbols_to_scan = request.symbols[:request.limit]
        
        background_tasks.add_task(
            process_processed_batch_scan,
            symbols_to_scan,
            batch_size
        )
        
        return {
            "status": "started", 
            "scan_type": "processed",
            "total_symbols": len(symbols_to_scan),
            "batch_size": batch_size,
            "message": "Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø´Ø±ÙˆØ¹ Ø´Ø¯",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/scan/progress")
async def get_scan_progress():
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ´Ø±ÙØª Ø§Ø³Ú©Ù†â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ø±ÛŒ"""
    try:
        if not GITHUB_DB_AVAILABLE:
            return {"status": "github_db_unavailable"}
        
        progress = progress_tracker.get_progress()
        cache_stats = github_cache.get_cache_stats()
        
        return {
            "status": "success",
            "progress": progress,
            "cache_stats": cache_stats,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ´Ø±ÙØª: {e}")
        return {"status": "error", "error": str(e)}

# ==================== ØªÙˆØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ ====================

async def process_raw_batch_scan(symbols: List[str], batch_size: int):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù…"""
    try:
        logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù… Ø¨Ø±Ø§ÛŒ {len(symbols)} Ø§Ø±Ø²")
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª
        progress_tracker.update_progress(
            total_symbols=len(symbols),
            scanned=0,
            current_batch=0,
            status="running_raw"
        )
        
        # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§
        batches = [symbols[i:i + batch_size] for i in range(0, len(symbols), batch_size)]
        
        for batch_num, batch_symbols in enumerate(batches):
            batch_results = []
            
            for symbol in batch_symbols:
                try:
                    # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù…
                    raw_data = DataProcessor.get_ai_scan_data(symbol)
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± GitHub DB
                    github_cache.save_live_data(symbol, {
                        "scan_type": "raw",
                        "data": raw_data,
                        "batch_number": batch_num + 1
                    })
                    
                    batch_results.append({
                        "symbol": symbol,
                        "status": "success",
                        "data_type": "raw"
                    })
                    
                except Exception as e:
                    batch_results.append({
                        "symbol": symbol,
                        "status": "error", 
                        "error": str(e)
                    })
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª
            current_scanned = (batch_num * batch_size) + len(batch_symbols)
            progress_tracker.update_progress(
                total_symbols=len(symbols),
                scanned=current_scanned,
                current_batch=batch_num + 1,
                status="running_raw"
            )
            
            logger.info(f"âœ… Ø¯Ø³ØªÙ‡ {batch_num + 1} Ú©Ø§Ù…Ù„ Ø´Ø¯: {len(batch_symbols)} Ø§Ø±Ø²")
            
        # ØªÚ©Ù…ÛŒÙ„ Ø§Ø³Ú©Ù†
        progress_tracker.update_progress(
            total_symbols=len(symbols),
            scanned=len(symbols),
            current_batch=len(batches),
            status="completed_raw"
        )
        
        logger.info(f"ğŸ‰ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù… Ú©Ø§Ù…Ù„ Ø´Ø¯: {len(symbols)} Ø§Ø±Ø²")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø®Ø§Ù…: {e}")
        progress_tracker.update_progress(
            total_symbols=len(symbols),
            scanned=0,
            current_batch=0,
            status="error"
        )

async def process_processed_batch_scan(symbols: List[str], batch_size: int):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡"""
    try:
        logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {len(symbols)} Ø§Ø±Ø²")
        
        progress_tracker.update_progress(
            total_symbols=len(symbols),
            scanned=0,
            current_batch=0,
            status="running_processed"
        )
        
        batches = [symbols[i:i + batch_size] for i in range(0, len(symbols), batch_size)]
        
        for batch_num, batch_symbols in enumerate(batches):
            batch_results = []
            
            for symbol in batch_symbols:
                try:
                    # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
                    processed_data = DataProcessor.get_basic_scan_data(symbol)
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± GitHub DB
                    github_cache.save_live_data(symbol, {
                        "scan_type": "processed", 
                        "data": processed_data,
                        "batch_number": batch_num + 1
                    })
                    
                    batch_results.append({
                        "symbol": symbol,
                        "status": "success",
                        "data_type": "processed"
                    })
                    
                except Exception as e:
                    batch_results.append({
                        "symbol": symbol,
                        "status": "error",
                        "error": str(e)
                    })
            
            current_scanned = (batch_num * batch_size) + len(batch_symbols)
            progress_tracker.update_progress(
                total_symbols=len(symbols),
                scanned=current_scanned,
                current_batch=batch_num + 1, 
                status="running_processed"
            )
            
            logger.info(f"âœ… Ø¯Ø³ØªÙ‡ {batch_num + 1} Ú©Ø§Ù…Ù„ Ø´Ø¯: {len(batch_symbols)} Ø§Ø±Ø²")
            
        progress_tracker.update_progress(
            total_symbols=len(symbols),
            scanned=len(symbols),
            current_batch=len(batches),
            status="completed_processed"
        )
        
        logger.info(f"ğŸ‰ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯: {len(symbols)} Ø§Ø±Ø²")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
        progress_tracker.update_progress(
            total_symbols=len(symbols),
            scanned=0, 
            current_batch=0,
            status="error"
        )

# ==================== Ø±ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ API ====================

@app.get("/")
async def root():
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ - Ø³Ø±Ùˆ Ú©Ø±Ø¯Ù† frontend"""
    try:
        return FileResponse("frontend/index.html")
    except:
        return JSONResponse(
            status_code=200,
            content={
                "message": "VortexAI API Server",
                "status": "running",
                "version": "2.0.0",
                "timestamp": datetime.now().isoformat(),
                "endpoints": {
                    "ai_scan": "GET /api/scan/ai/{symbol}",
                    "basic_scan": "GET /api/scan/basic/{symbol}",
                    "batch_raw": "POST /api/scan/batch/raw",
                    "batch_processed": "POST /api/scan/batch/processed",
                    "scan_progress": "GET /api/scan/progress",
                    "system_status": "GET /api/system/status",
                    "clear_cache": "GET /api/debug/clear-cache"
                }
            }
        )

@app.get("/api/scan/ai/{symbol}")
async def ai_scan(
    symbol: str,
    limit: int = Query(500, ge=1, le=1000, description="ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ")
):
    """Ø§Ø³Ú©Ù† Ù…Ø®ØµÙˆØµ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªØ­Ù„ÛŒÙ„Ú¯Ø± ØªÚ©Ù†ÛŒÚ©Ø§Ù„ - Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù…"""
    try:
        if not COINSTATS_AVAILABLE:
            raise HTTPException(status_code=503, detail="CoinStats service unavailable")
        
        ai_data = DataProcessor.get_ai_scan_data(symbol.lower(), limit)
        
        return {
            "status": "success" if "error" not in ai_data else "error",
            "data_type": "raw",
            "purpose": "ai_technical_analysis",
            "symbol": symbol,
            "limit": limit,
            "data": ai_data,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³Ú©Ù† AI Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/scan/basic/{symbol}")
async def basic_scan(
    symbol: str,
    limit: int = Query(100, ge=1, le=500, description="ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ")
):
    """Ø§Ø³Ú©Ù† Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ - Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡"""
    try:
        if not COINSTATS_AVAILABLE:
            raise HTTPException(status_code=503, detail="CoinStats service unavailable")
        
        basic_data = DataProcessor.get_basic_scan_data(symbol.lower(), limit)
        
        return {
            "status": "success" if basic_data.get("success") else "error",
            "data_type": "processed", 
            "purpose": "basic_display",
            "symbol": symbol,
            "limit": limit,
            "data": basic_data,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³Ú©Ù† Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/system/status")
async def system_status():
    """ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ… Ùˆ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§"""
    try:
        # ØªØ³Øª Ø³Ù„Ø§Ù…Øª Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ API
        endpoint_health = {}
        if COINSTATS_AVAILABLE:
            endpoint_health = coin_stats_manager.test_all_endpoints()
        
        # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
        system_metrics = {}
        if COINSTATS_AVAILABLE:
            system_metrics = coin_stats_manager.get_system_metrics()
        
        # Ø¢Ù…Ø§Ø± Ú©Ø´ - Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
        cache_files = []
        cache_size = 0
        if os.path.exists("./coinstats_cache"):
            cache_files = [f for f in os.listdir("./coinstats_cache") if f.endswith('.json')]
            for file in cache_files:
                file_path = os.path.join("./coinstats_cache", file)
                cache_size += os.path.getsize(file_path)
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ…
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=1)
        disk = psutil.disk_usage('/')
        
        return {
            "status": "operational",
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.0",
            
            "services": {
                "coinstats_api": COINSTATS_AVAILABLE,
                "github_db": GITHUB_DB_AVAILABLE,
                "total_healthy_endpoints": sum(1 for r in endpoint_health.values() if r.get('status') == 'success'),
                "total_endpoints": len(endpoint_health)
            },
            
            "endpoints_health": endpoint_health,
            
            "system_metrics": {
                "memory": {
                    "total_gb": round(memory.total / (1024**3), 2),
                    "used_gb": round(memory.used / (1024**3), 2),
                    "percent": memory.percent
                },
                "cpu": {
                    "percent": cpu_percent
                },
                "disk": {
                    "total_gb": round(disk.total / (1024**3), 2),
                    "used_gb": round(disk.used / (1024**3), 2),
                    "percent": disk.percent
                }
            },
            
            "cache": {
                "total_files": len(cache_files),
                "total_size_mb": round(cache_size / (1024 * 1024), 2),
                "cache_dir": "./coinstats_cache"
            },
            
            "github_db_stats": github_cache.get_cache_stats() if GITHUB_DB_AVAILABLE else {},
            
            "usage_stats": {
                "active_connections": 0,
                "uptime_seconds": int(time.time() - psutil.boot_time())
            }
        }
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…: {e}")
        return {
            "status": "degraded",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/debug/clear-cache")
async def clear_cache():
    """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ø´ (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯)"""
    try:
        if COINSTATS_AVAILABLE:
            coin_stats_manager.clear_cache()
            return {
                "status": "success", 
                "message": "Cache cleared successfully",
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "status": "error", 
                "message": "CoinStats not available",
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÙˆØªâ€ŒÙ‡Ø§ÛŒ SPA Ø¨Ø±Ø§ÛŒ frontend
@app.get("/{full_path:path}")
async def serve_spa(full_path: str):
    """Ø³Ø±Ùˆ Ú©Ø±Ø¯Ù† frontend Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù…Ø³ÛŒØ±Ù‡Ø§"""
    try:
        return FileResponse("frontend/index.html")
    except:
        return JSONResponse(
            status_code=404,
            content={"error": "Frontend not found"}
        )

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port, access_log=True)
