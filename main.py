import time
import asyncio
import psutil
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable
from collections import defaultdict, deque
import threading
import json
import traceback
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class DebugLevel(Enum):
    INFO = "INFO"
    WARNING = "WARNING" 
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

@dataclass
class EndpointCall:
    endpoint: str
    method: str
    timestamp: datetime
    params: Dict[str, Any]
    response_time: float
    status_code: int
    cache_used: bool
    api_calls: int
    memory_used: float
    cpu_impact: float

@dataclass
class SystemMetrics:
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    network_io: Dict[str, int]
    active_connections: int

class DebugManager:
    def __init__(self):
        self.endpoint_calls = deque(maxlen=10000)
        self.system_metrics_history = deque(maxlen=1000)
        self.endpoint_stats = defaultdict(lambda: {
            'total_calls': 0,
            'successful_calls': 0,
            'failed_calls': 0,
            'total_response_time': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'api_calls': 0,
            'errors': [],
            'last_call': None
        })
        
        self.alerts = []
        self.performance_thresholds = {
            'response_time_warning': 1.0,
            'response_time_critical': 3.0,
            'cpu_warning': 80.0,
            'cpu_critical': 95.0,
            'memory_warning': 85.0,
            'memory_critical': 95.0
        }
        
        self._connect_to_central_monitor()
        
    def _connect_to_central_monitor(self):
        """Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…ØªÙ…Ø±Ú©Ø²"""
        try:
            from debug_system.monitors.system_monitor import central_monitor
            
            if central_monitor:
                central_monitor.subscribe("debug_manager", self._on_metrics_update)
                logger.info("âœ… DebugManager connected to central_monitor")
            else:
                logger.warning("âš ï¸ Central monitor not available, DebugManager will use cached data")
                
        except ImportError as e:
            logger.warning(f"âš ï¸ Could not connect to central_monitor: {e}")
    
    def _on_metrics_update(self, metrics: Dict[str, Any]):
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ù…ØªÙ…Ø±Ú©Ø²"""
        # Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ DebugManager Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒ
        system_metrics = metrics.get('system', {})
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª SystemMetrics Ù‚Ø¯ÛŒÙ…ÛŒ
        sys_metric = SystemMetrics(
            timestamp=datetime.fromisoformat(metrics['timestamp']),
            cpu_percent=system_metrics.get('cpu', {}).get('percent', 0),
            memory_percent=system_metrics.get('memory', {}).get('percent', 0),
            disk_usage=system_metrics.get('disk', {}).get('usage_percent', 0),
            network_io={
                'bytes_sent': system_metrics.get('network', {}).get('bytes_sent_mb', 0) * 1024 * 1024,
                'bytes_recv': system_metrics.get('network', {}).get('bytes_recv_mb', 0) * 1024 * 1024
            },
            active_connections=0  # Ø§Ú¯Ø± Ø¯Ø± Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª
        )
        
        self.system_metrics_history.append(sys_metric)
        
    def log_endpoint_call(self, endpoint: str, method: str, params: Dict[str, Any], 
                         response_time: float, status_code: int, cache_used: bool, 
                         api_calls: int = 0):
        """Ø«Ø¨Øª ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª"""
        try:
            memory_used = psutil.virtual_memory().percent
            cpu_impact = psutil.cpu_percent(interval=0.1)
            
            call = EndpointCall(
                endpoint=endpoint,
                method=method,
                timestamp=datetime.now(),
                params=params,
                response_time=response_time,
                status_code=status_code,
                cache_used=cache_used,
                api_calls=api_calls,
                memory_used=memory_used,
                cpu_impact=cpu_impact
            )
            
            self.endpoint_calls.append(call)
            
            stats = self.endpoint_stats[endpoint]
            stats['total_calls'] += 1
            stats['total_response_time'] += response_time
            
            if 200 <= status_code < 300:
                stats['successful_calls'] += 1
            else:
                stats['failed_calls'] += 1
                stats['errors'].append({
                    'timestamp': datetime.now().isoformat(),
                    'status_code': status_code,
                    'params': params
                })
                
            if cache_used:
                stats['cache_hits'] += 1
            else:
                stats['cache_misses'] += 1
                
            stats['api_calls'] += api_calls
            stats['last_call'] = datetime.now().isoformat()
            
            self._check_performance_alerts(endpoint, call)
            
            logger.debug(f"ğŸ“Š Endpoint logged: {endpoint} - {response_time:.3f}s")
            
        except Exception as e:
            logger.error(f"âŒ Error logging endpoint call: {e}")
    
    def log_error(self, endpoint: str, error: Exception, traceback_str: str, context: Dict[str, Any] = None):
        """Ø«Ø¨Øª Ø®Ø·Ø§"""
        error_data = {
            'endpoint': endpoint,
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback_str,
            'context': context or {},
            'timestamp': datetime.now().isoformat()
        }
        
        self.endpoint_stats[endpoint]['errors'].append(error_data)
        
        if self._is_critical_error(error):
            self._create_alert(
                level=DebugLevel.CRITICAL,
                message=f"Critical error in {endpoint}: {str(error)}",
                source=endpoint,
                data=error_data
            )
        
        logger.error(f"ğŸš¨ Error in {endpoint}: {error}")
    
    def get_endpoint_stats(self, endpoint: str = None) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª"""
        if endpoint:
            if endpoint not in self.endpoint_stats:
                return {'error': 'Endpoint not found'}
            
            stats = self.endpoint_stats[endpoint]
            avg_response_time = (stats['total_response_time'] / stats['total_calls']) if stats['total_calls'] > 0 else 0
            
            return {
                'endpoint': endpoint,
                'total_calls': stats['total_calls'],
                'successful_calls': stats['successful_calls'],
                'failed_calls': stats['failed_calls'],
                'success_rate': (stats['successful_calls'] / stats['total_calls'] * 100) if stats['total_calls'] > 0 else 0,
                'average_response_time': round(avg_response_time, 3),
                'cache_performance': {
                    'hits': stats['cache_hits'],
                    'misses': stats['cache_misses'],
                    'hit_rate': (stats['cache_hits'] / (stats['cache_hits'] + stats['cache_misses']) * 100) if (stats['cache_hits'] + stats['cache_misses']) > 0 else 0
                },
                'api_calls': stats['api_calls'],
                'recent_errors': stats['errors'][-10:],
                'last_call': stats['last_call']
            }
        else:
            all_stats = {}
            total_calls = 0
            total_success = 0
            
            for endpoint, stats in self.endpoint_stats.items():
                all_stats[endpoint] = {
                    'total_calls': stats['total_calls'],
                    'success_rate': (stats['successful_calls'] / stats['total_calls'] * 100) if stats['total_calls'] > 0 else 0,
                    'average_response_time': round((stats['total_response_time'] / stats['total_calls']), 3) if stats['total_calls'] > 0 else 0,
                    'last_call': stats['last_call']
                }
                total_calls += stats['total_calls']
                total_success += stats['successful_calls']
            
            return {
                'overall': {
                    'total_endpoints': len(self.endpoint_stats),
                    'total_calls': total_calls,
                    'overall_success_rate': (total_success / total_calls * 100) if total_calls > 0 else 0,
                    'timestamp': datetime.now().isoformat()
                },
                'endpoints': all_stats
            }
    
    def get_recent_calls(self, limit: int = 50) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒâ€ŒÙ‡Ø§"""
        recent_calls = list(self.endpoint_calls)[-limit:]
        return [
            {
                'endpoint': call.endpoint,
                'method': call.method,
                'timestamp': call.timestamp.isoformat(),
                'response_time': call.response_time,
                'status_code': call.status_code,
                'cache_used': call.cache_used,
                'api_calls': call.api_calls,
                'memory_used': call.memory_used,
                'cpu_impact': call.cpu_impact
            }
            for call in recent_calls
        ]
    
    def get_system_metrics_history(self, hours: int = 1) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        return [
            {
                'timestamp': metrics.timestamp.isoformat(),
                'cpu_percent': metrics.cpu_percent,
                'memory_percent': metrics.memory_percent,
                'disk_usage': metrics.disk_usage,
                'network_io': metrics.network_io,
                'active_connections': metrics.active_connections
            }
            for metrics in self.system_metrics_history
            if metrics.timestamp >= cutoff_time
        ]
    
    def _start_background_monitoring(self):
        """Ø´Ø±ÙˆØ¹ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø³ÛŒØ³ØªÙ…"""
        def monitor_system():
            while True:
                try:
                    self._collect_system_metrics()
                    time.sleep(5)
                except Exception as e:
                    logger.error(f"âŒ System monitoring error: {e}")
                    time.sleep(10)
        
        monitor_thread = threading.Thread(target=monitor_system, daemon=True)
        monitor_thread.start()
        logger.info("âœ… Background system monitoring started")
    
    def _collect_system_metrics(self):
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            disk_usage = psutil.disk_usage('/').percent
            
            net_io = psutil.net_io_counters()
            network_io = {
                'bytes_sent': net_io.bytes_sent,
                'bytes_recv': net_io.bytes_recv,
                'packets_sent': net_io.packets_sent,
                'packets_recv': net_io.packets_recv
            }
            
            active_connections = len(psutil.net_connections())
            
            metrics = SystemMetrics(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                disk_usage=disk_usage,
                network_io=network_io,
                active_connections=active_connections
            )
            
            self.system_metrics_history.append(metrics)
            
        except Exception as e:
            logger.error(f"âŒ Error collecting system metrics: {e}")
    
    def _check_performance_alerts(self, endpoint: str, call: EndpointCall):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ performance"""
        if call.response_time > self.performance_thresholds['response_time_critical']:
            self._create_alert(
                level=DebugLevel.CRITICAL,
                message=f"Critical response time in {endpoint}: {call.response_time:.2f}s",
                source=endpoint,
                data={
                    'response_time': call.response_time,
                    'threshold': self.performance_thresholds['response_time_critical']
                }
            )
        elif call.response_time > self.performance_thresholds['response_time_warning']:
            self._create_alert(
                level=DebugLevel.WARNING,
                message=f"High response time in {endpoint}: {call.response_time:.2f}s",
                source=endpoint,
                data={
                    'response_time': call.response_time,
                    'threshold': self.performance_thresholds['response_time_warning']
                }
            )
        
        if call.cpu_impact > self.performance_thresholds['cpu_critical']:
            self._create_alert(
                level=DebugLevel.CRITICAL,
                message=f"Critical CPU usage in {endpoint}: {call.cpu_impact:.1f}%",
                source=endpoint,
                data={'cpu_usage': call.cpu_impact}
            )
    
    def _create_alert(self, level: DebugLevel, message: str, source: str, data: Dict[str, Any]):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ø´Ø¯Ø§Ø± Ø¬Ø¯ÛŒØ¯"""
        alert = {
            'id': len(self.alerts) + 1,
            'level': level.value,
            'message': message,
            'source': source,
            'timestamp': datetime.now().isoformat(),
            'data': data,
            'acknowledged': False
        }
        
        self.alerts.append(alert)
        logger.warning(f"ğŸš¨ {level.value} Alert: {message}")
    
    def _is_critical_error(self, error: Exception) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø®Ø·Ø§ critical Ø§Ø³Øª"""
        critical_errors = [
            'Timeout',
            'ConnectionError',
            'MemoryError',
            'OSError'
        ]
        
        return any(critical_error in type(error).__name__ for critical_error in critical_errors)
    
    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„"""
        return [alert for alert in self.alerts if not alert['acknowledged']]
    
    def acknowledge_alert(self, alert_id: int):
        """ØªØ£ÛŒÛŒØ¯ Ù‡Ø´Ø¯Ø§Ø±"""
        for alert in self.alerts:
            if alert['id'] == alert_id:
                alert['acknowledged'] = True
                break
    
    def clear_old_data(self, days: int = 7):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        cutoff_time = datetime.now() - timedelta(days=days)
        
        self.endpoint_calls = deque(
            [call for call in self.endpoint_calls if call.timestamp > cutoff_time],
            maxlen=10000
        )
        
        self.system_metrics_history = deque(
            [metrics for metrics in self.system_metrics_history if metrics.timestamp > cutoff_time],
            maxlen=1000
        )
        
        logger.info(f"ğŸ§¹ Cleared data older than {days} days")

# Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ú¯Ù„ÙˆØ¨Ø§Ù„
debug_manager = DebugManager()

from fastapi import FastAPI, HTTPException, Query, BackgroundTasks, WebSocket
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import os
from datetime import datetime
import logging
import time
import psutil
from pathlib import Path
import json
import asyncio
import logging
import sys

# ==================== DEBUG CODE ====================
print("=" * 60)
print("ğŸ› ï¸  VORTEXAI DEBUG - SYSTEM INITIALIZATION")
print("=" * 60)

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø±ÙˆØªâ€ŒÙ‡Ø§
try:
    from routes.health import health_router
    from routes.coins import coins_router
    from routes.health import health_router
    from routes.coins import coins_router
    from routes.exchanges import exchanges_router
    from routes.news import news_router
    from routes.insights import insights_router
    from routes.raw_data.raw_coins import raw_coins_router
    from routes.raw_data.raw_news import raw_news_router
    from routes.raw_data.raw_insights import raw_insights_router
    from routes.raw_data.raw_exchanges import raw_exchanges_router
    from routes.docs import docs_router
    
    print("âœ… All routers imported successfully!")
except ImportError as e:
    print(f"âŒ Router import error: {e}")

try:
    from complete_coinstats_manager import coin_stats_manager
    print("âœ… coin_stats_manager imported successfully!")
    COINSTATS_AVAILABLE = True
except ImportError as e:
    print(f"âŒ CoinStats import error: {e}")
    COINSTATS_AVAILABLE = False

# Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
try:
    print("ğŸ” Attempting to import AI brain...")
    
    # ØªØ³Øª ÙˆØ¬ÙˆØ¯ Ù¾Ú©ÛŒØ¬
    import ai_brain
    print("âœ… ai_brain package found")
    
    # ØªØ³Øª Ù…Ø­ØªÙˆÛŒØ§Øª Ù¾Ú©ÛŒØ¬
    print(f"ğŸ“¦ Package contents: {dir(ai_brain)}")
    
    # import Ù…Ø³ØªÙ‚ÛŒÙ…
    from ai_brain import vortex_brain, ai_router
    AI_SYSTEM_AVAILABLE = True
    print("ğŸ‰ AI Brain system imported successfully!")
    
except ImportError as e:
    print(f"âŒ AI Brain import error: {e}")
    import traceback
    traceback.print_exc()
    AI_SYSTEM_AVAILABLE = False

# Ø³ÛŒØ³ØªÙ… Ú©Ø´
try:
    from debug_system.storage import redis_manager, cache_debugger
    
    # ØªØ³Øª Ø³Ù„Ø§Ù…Øª Redis
    redis_health = redis_manager.health_check()
    
    # ğŸ”½ Ø§ÛŒÙ† Ø±Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†:
    status = getattr(redis_health, 'status', 
                    redis_health.get('status', 'unknown') if isinstance(redis_health, dict) else 'checked')
    
    print(f"âœ… Cache system imported - Redis: {status}")
    
    # ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ø´
    test_success = cache_debugger.set_data("system_startup_test", {"status": "ok", "time": datetime.now().isoformat()}, 60)
    if test_success:
        print("âœ… Cache system test: PASSED")
    else:
        print("âš ï¸ Cache system test: FAILED")
    
    CACHE_AVAILABLE = True
    
except Exception as e:
    print(f"âŒ Cache system initialization error: {e}")
    CACHE_AVAILABLE = False
# ==================== DEBUG SYSTEM IMPORTS ====================
DEBUG_SYSTEM_AVAILABLE = False
live_dashboard_manager = None
console_stream_manager = None

try:
    from debug_system.core import core_system, metrics_collector, alert_manager
    from debug_system.monitors import monitors_system, endpoint_monitor, system_monitor, performance_monitor, security_monitor
    from debug_system.storage import history_manager, log_manager, cache_debugger
    from debug_system.realtime import websocket_manager, console_stream
    from debug_system.tools import dev_tools, testing_tools, report_generator, initialize_tools_system

    # Ùˆ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¯Ø± Ú©Ø¯:
    try:
        from debug_system.tools import tools_system
    except ImportError:
        tools_system = None
        print("âš ï¸ tools_system not available - using fallback")
    from debug_system.realtime.live_dashboard import LiveDashboardManager
    
    DEBUG_SYSTEM_AVAILABLE = True
    print("âœ… Complete debug system imported successfully!")
except ImportError as e:
    print(f"âŒ Debug system import error: {e}")
    DEBUG_SYSTEM_AVAILABLE = False

print("=" * 60)

# ==================== DEBUG SYSTEM INITIALIZATION ====================
if DEBUG_SYSTEM_AVAILABLE:
    try:
        print("ğŸ”„ Initializing debug system...")
        
        # Ù…Ø¯ÛŒØ±ÛŒØª event loop
        print("   ğŸ”§ Setting up event loop...")
        try:
            loop = asyncio.get_event_loop()
            if loop.is_closed():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                print("   âœ… New event loop created")
            else:
                print("   âœ… Existing event loop used")
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            print("   âœ… New event loop created for runtime error")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ core
        print("   ğŸ”§ Setting up core systems...")
        if not core_system:
            from debug_system.core import initialize_core_system
            core_system = initialize_core_system()
            print("   âœ… Core systems initialized")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø§Ù†ÛŒØªÙˆØ±Ù‡Ø§
        print("   ğŸ“Š Setting up monitors...")
        if not monitors_system:
            from debug_system.monitors import initialize_monitors_system
            monitors_system = initialize_monitors_system()
            print("   âœ… Monitors system initialized")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§
        print("   ğŸ› ï¸ Setting up tools...")
        if not tools_system:
            from debug_system.tools import initialize_tools_system
            tools_system = initialize_tools_system(monitors_system["endpoint_monitor"])
            print("   âœ… Tools system initialized")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… real-time
        print("   âš¡ Setting up real-time systems...")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Live Dashboard
        try:
            live_dashboard_manager = LiveDashboardManager(
                debug_manager, 
                metrics_collector
            )
            print("   âœ… Live Dashboard Manager created")
        except Exception as e:
            print(f"   âŒ Live Dashboard Manager error: {e}")
            live_dashboard_manager = None
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Console Stream
        try:
            console_stream_manager = console_stream
            print("   âœ… Console Stream Manager created")
    
            
        except Exception as e:
            print(f"   âŒ Console Stream Manager error: {e}")
            
            # Ø§ÛŒØ¬Ø§Ø¯ fallback
            class SimpleConsoleManager:
                def __init__(self):
                    self.active_connections = []
                async def connect(self, websocket):
                    await websocket.accept()
                    self.active_connections.append(websocket)
                def disconnect(self, websocket):
                    if websocket in self.active_connections:
                        self.active_connections.remove(websocket)
                async def broadcast_message(self, message):
                    pass
    
            console_stream_manager = SimpleConsoleManager()
            print("   âœ… Fallback Console Manager created")
            
        # ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø¨Ø±ÙˆØ¯Ú©Ø³Øª Ø¯Ø´Ø¨ÙˆØ±Ø¯
        async def start_dashboard_broadcast():
            if live_dashboard_manager:
                try:
                    await live_dashboard_manager.start_dashboard_broadcast()
                except Exception as e:
                    print(f"   âŒ Dashboard broadcast error: {e}")
            else:
                print("   âš ï¸ Dashboard manager not available")
        
        # ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ
        async def periodic_cleanup():
            while True:
                try:
                    debug_manager.clear_old_data(days=7)
                    if hasattr(alert_manager, 'cleanup_old_alerts'):
                        alert_manager.cleanup_old_alerts()
                    if hasattr(alert_manager, 'auto_resolve_alerts'):
                        alert_manager.auto_resolve_alerts()
                    
                    if hasattr(websocket_manager, 'cleanup_inactive_connections'):
                        websocket_manager.cleanup_inactive_connections()
                    
                    await asyncio.sleep(300)
                except Exception as e:
                    logger.error(f"   âŒ Cleanup error: {e}")
                    await asyncio.sleep(60)
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ WebSocket Manager
        try:
            async def handle_debug_message(client_id: str, message: Dict):
                try:
                    message_type = message.get('type')
                    if message_type == 'get_metrics':
                        current_metrics = metrics_collector.get_current_metrics()
                        await websocket_manager.send_message(client_id, {
                            'type': 'metrics_update',
                            'data': current_metrics,
                            'timestamp': datetime.now().isoformat()
                        })
                    elif message_type == 'get_alerts':
                        active_alerts = alert_manager.get_active_alerts()
                        await websocket_manager.send_message(client_id, {
                            'type': 'alerts_update',
                            'data': active_alerts,
                            'timestamp': datetime.now().isoformat()
                        })
                except Exception as e:
                    print(f"   âŒ WebSocket message handler error: {e}")
            
            websocket_manager.message_handlers['debug_message'] = handle_debug_message
            print("   âœ… WebSocket message handlers registered")
            
        except Exception as e:
            print(f"   âŒ WebSocket setup error: {e}")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯ÛŒÙ†Ú¯ real-time
        try:
            def log_to_console(level: str, message: str, data: Dict = None):
                if console_stream_manager:
                    console_stream_manager.broadcast_message({
                        'type': 'log_message',
                        'level': level,
                        'message': message,
                        'data': data or {},
                        'timestamp': datetime.now().isoformat()
                    })
            
            if hasattr(alert_manager, 'set_console_logger'):
                alert_manager.set_console_logger(log_to_console)
            
            if hasattr(debug_manager, 'set_console_logger'):
                debug_manager.set_console_logger(log_to_console)
                
            print("   âœ… Real-time logging configured")
            
        except Exception as e:
            print(f"   âŒ Real-time logging setup error: {e}")
        
        # ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§
        print("   ğŸ§ª Running initial system tests...")
        try:
            current_metrics = metrics_collector.get_current_metrics()
            print(f"   âœ… Metrics collector: {len(current_metrics)} metrics collected")
            
            # ğŸ”§ Ø®Ø· 550 Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡: ØªØ³Øª debug_manager
            try:
                endpoint_stats = debug_manager.get_endpoint_stats()
                total_endpoints = len(endpoint_stats.get('endpoints', {}))
                print(f"   âœ… Debug manager: {total_endpoints} endpoints monitored")
            except AttributeError as e:
                print(f"   âš ï¸ Debug manager method not available: {e}")
                print(f"   âœ… Debug manager: Custom DebugManager initialized")
            
            active_alerts = alert_manager.get_active_alerts()
            print(f"   âœ… Alert manager: {len(active_alerts)} active alerts")
            
            system_health = system_monitor.get_system_health()
            print(f"   âœ… System monitor: {system_health.get('overall_health', 'unknown')}")
            
            performance_report = performance_monitor.analyze_endpoint_performance()
            print(f"   âœ… Performance monitor: {len(performance_report.get('endpoint_performance', {}))} endpoints analyzed")
            
            security_report = security_monitor.get_security_report()
            print(f"   âœ… Security monitor: {security_report.get('total_suspicious_activities', 0)} security events")
            
        except Exception as e:
            print(f"   âš ï¸ Initial tests had issues: {e}")
        
        print("âœ… Complete debug system initialized and activated!")
        print(f"   ğŸ“ˆ System Status:")
        print(f"   â€¢ Core Modules: {len(core_system) if core_system else 0} systems")
        print(f"   â€¢ Monitors: {len(monitors_system) if monitors_system else 0} monitors")
        print(f"   â€¢ Tools: {len(tools_system) if tools_system else 0} tools")
        print(f"   â€¢ Real-time: {'Active' if live_dashboard_manager else 'Inactive'}")
        print(f"   â€¢ WebSocket: {'Ready' if websocket_manager else 'Not ready'}")
        print(f"   â€¢ Console: {'Active' if console_stream_manager else 'Inactive'}")
        
    except Exception as e:
        print(f"âŒ Debug system initialization error: {e}")
        import traceback
        traceback.print_exc()
        DEBUG_SYSTEM_AVAILABLE = False
        live_dashboard_manager = None
        console_stream_manager = None
else:
    print("âŒ Debug system is not available")
    live_dashboard_manager = None
    console_stream_manager = None
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="VortexAI API", 
    version="4.0.0",
    description="Complete Crypto AI System with Advanced Debugging",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



@app.on_event("shutdown")
async def shutdown_cleanup():
    """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø®Ø§ØªÙ…Ù‡ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§"""
    print("ğŸ›‘ Starting system shutdown...")
    
    # Ø®Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
    if AI_SYSTEM_AVAILABLE:
        try:
            print("ğŸ§  Shutting down AI Brain system...")
            await vortex_brain.cleanup()
            print("âœ… AI Brain system cleaned up successfully!")
        except Exception as e:
            print(f"âŒ AI Brain shutdown error: {e}")
    
    # Ø®Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† Ø³ÛŒØ³ØªÙ… Ø¯ÛŒØ¨Ø§Ú¯
    if DEBUG_SYSTEM_AVAILABLE:
        try:
            print("ğŸ”§ Shutting down debug system...")
            # Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø®Ø§ØµÛŒ Ø¯Ø± Ø¯ÛŒØ¨Ø§Ú¯ Ø³ÛŒØ³ØªÙ… Ø¯Ø§Ø±ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
            print("âœ… Debug system shutdown completed!")
        except Exception as e:
            print(f"âŒ Debug system shutdown error: {e}")
    
    print("ğŸ¯ All systems shutdown completed!")


# Ø«Ø¨Øª Ø±ÙˆØªâ€ŒÙ‡Ø§
app.include_router(health_router)
app.include_router(coins_router)
app.include_router(exchanges_router)
app.include_router(news_router)
app.include_router(insights_router)
app.include_router(raw_coins_router)
app.include_router(raw_news_router)
app.include_router(raw_insights_router)
app.include_router(raw_exchanges_router)
app.include_router(docs_router)
app.include_router(ai_router, prefix="/api/ai", tags=["AI Brain"])

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø±ÙˆØª Ú†Øª - Ø¨Ø§ ØªØ§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² circular import
def register_chat_routes():
    try:
        from routes.chat_routes import chat_router
        app.include_router(chat_router, prefix="/api/ai/chat", tags=["AI Chat"])
        print("âœ… Chat routes imported successfully!")
        return True
    except ImportError as e:
        print(f"âŒ Chat routes import error: {e}")
        return False

# Ø«Ø¨Øª Ø±ÙˆØª Ú†Øª
register_chat_routes()

# ==================== DEBUG ROUTES ====================
def activate_complete_background_system():
    """ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Background Worker Ø§Ø² Ù…Ø³ÛŒØ± debug_system.tools"""
    
    print("ğŸ¯ ACTIVATING COMPLETE BACKGROUND WORKER SYSTEM FROM debug_system.tools...")
    
    # ğŸ¯ **ØªØ£Ø®ÛŒØ± Ù…Ù‡Ù…**: Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù† ØªØ§ central_monitor Ú©Ø§Ù…Ù„Ø§Ù‹ ÙØ¹Ø§Ù„ Ø´ÙˆØ¯
    print("â³ Waiting 20 seconds for central_monitor to be fully ready...")
    import time
    time.sleep(20)
    
    # ğŸ¯ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ central_monitor Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¯Ø§Ù…Ù‡
    try:
        from debug_system.monitors.system_monitor import central_monitor
        if not central_monitor:
            print("âš ï¸ Central monitor still not available, waiting 10 more seconds...")
            time.sleep(10)
    except ImportError:
        print("âš ï¸ Cannot import central_monitor, proceeding with caution...")
        time.sleep(10)
    
    try:
        # Û±. Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ Ø§Ø² Ù…Ø³ÛŒØ± debug_system.tools
        print("ğŸ“¦ Importing background worker components from debug_system.tools...")
        
        # ØªØ¹Ø±ÛŒÙ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Fallback Ú©Ø§Ù…Ù„ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
        class FallbackWorker:
            def __init__(self):
                self.max_workers = 2
                self.is_running = False
                self.task_queue = type('Queue', (), {'qsize': lambda: 0})()
            def start(self): 
                self.is_running = True
                print("âš ï¸ Fallback worker started")
            def stop(self):
                self.is_running = False
                print("âš ï¸ Fallback worker stopped")
            def submit_real_tasks(self): 
                print("âš ï¸ Fallback tasks submitted")
            def submit_task(self, *args, **kwargs):
                print("âš ï¸ Fallback task submitted")
                return True, "Task submitted to fallback worker"
            def get_detailed_metrics(self):
                return {
                    'queue_status': {'queue_size': 0, 'active_tasks': 0, 'completed_tasks': 0, 'failed_tasks': 0},
                    'worker_status': {'active_workers': 0, 'total_workers': self.max_workers},
                    'performance_stats': {'total_tasks_processed': 0}
                }
        
        class FallbackResource:
            def __init__(self):
                self.adaptive_limits = {}
                self.is_monitoring = False
            def start_monitoring(self): 
                self.is_monitoring = True
                print("âš ï¸ Fallback resource monitoring started")
            def stop_monitoring(self):
                self.is_monitoring = False
                print("âš ï¸ Fallback resource monitoring stopped")
            def _check_system_health(self):
                return {'status': 'healthy'}
            def _collect_comprehensive_metrics(self):
                return {'cpu': {'percent': 0}, 'memory': {'percent': 0}}
            def get_detailed_resource_report(self):
                return {
                    'real_time_metrics': {'system_health_score': 100},
                    'performance_analysis': {'health_score': 100, 'bottlenecks': [], 'optimization_opportunities': []}
                }
        
        class FallbackScheduler:
            def __init__(self):
                self.is_scheduling = False
                self.scheduled_tasks = {}
            def start_scheduling(self): 
                self.is_scheduling = True
                print("âš ï¸ Fallback scheduler started")
            def stop_scheduling(self):
                self.is_scheduling = False
                print("âš ï¸ Fallback scheduler stopped")
            def get_scheduling_analytics(self):
                return {
                    'scheduling_status': {'active_tasks': 0, 'upcoming_tasks': 0},
                    'performance_analysis': {'overall_success_rate': 100, 'efficiency_score': 100},
                    'predictions': {'optimal_scheduling_windows': []}
                }
        
        class FallbackRecovery:
            def __init__(self):
                self.is_monitoring = False
                self.snapshots_metadata = []
            def start_monitoring(self): 
                self.is_monitoring = True
                print("âš ï¸ Fallback recovery started")
            def stop_monitoring(self):
                self.is_monitoring = False
                print("âš ï¸ Fallback recovery stopped")
            def get_recovery_status(self):
                return {
                    'snapshots_summary': {'total_snapshots': 0, 'healthy_snapshots': 0, 'total_storage_mb': 0},
                    'recovery_queue_status': {'pending_recoveries': 0},
                    'health_assessment': {'recovery_readiness': 'ready'}
                }
        
        class FallbackDashboard:
            def __init__(self):
                self.background_worker = None
                self.resource_manager = None
                self.time_scheduler = None
                self.recovery_manager = None
                self.is_monitoring = False
            def start_monitoring(self): 
                self.is_monitoring = True
                print("âš ï¸ Fallback dashboard started")
            def stop_monitoring(self):
                self.is_monitoring = False
                print("âš ï¸ Fallback dashboard stopped")
        
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø§Ø² Ù…Ø³ÛŒØ± debug_system.tools
        background_worker = None
        resource_guardian = None
        time_scheduler = None
        recovery_manager = None
        monitoring_dashboard = None
        
        try:
            from debug_system.tools.background_worker import background_worker as bg_worker
            background_worker = bg_worker
            print("âœ… background_worker imported from debug_system.tools")
        except ImportError as e:
            print(f"âŒ debug_system.tools background_worker import failed: {e}")
            background_worker = FallbackWorker()
        
        try:
            from debug_system.tools.resource_manager import resource_guardian as res_guard
            resource_guardian = res_guard
            print("âœ… resource_guardian imported from debug_system.tools")
        except ImportError as e:
            print(f"âŒ debug_system.tools resource_guardian import failed: {e}")
            resource_guardian = FallbackResource()
        
        try:
            from debug_system.tools.time_scheduler import time_scheduler as time_sched
            time_scheduler = time_sched
            print("âœ… time_scheduler imported from debug_system.tools")
        except ImportError as e:
            print(f"âŒ debug_system.tools time_scheduler import failed: {e}")
            time_scheduler = FallbackScheduler()
        
        try:
            from debug_system.tools.recovery_system import recovery_manager as rec_manager
            recovery_manager = rec_manager
            print("âœ… recovery_manager imported from debug_system.tools")
        except ImportError as e:
            print(f"âŒ debug_system.tools recovery_manager import failed: {e}")
            recovery_manager = FallbackRecovery()
        
        try:
            from debug_system.tools.monitoring_dashboard import monitoring_dashboard as monitor_dash
            monitoring_dashboard = monitor_dash
            print("âœ… monitoring_dashboard imported from debug_system.tools")
        except ImportError as e:
            print(f"âŒ debug_system.tools monitoring_dashboard import failed: {e}")
            monitoring_dashboard = FallbackDashboard()
            
        # ğŸ¯ Ø§ØªØµØ§Ù„ Ø¨Ù‡ central_monitor
        try:
            from debug_system.monitors.system_monitor import central_monitor
            
            if central_monitor and hasattr(central_monitor, 'subscribe'):
                # Ø§ØªØµØ§Ù„ background_worker
                if hasattr(background_worker, '_on_metrics_update'):
                    central_monitor.subscribe("background_worker", background_worker._on_metrics_update)
                
                # Ø§ØªØµØ§Ù„ resource_guardian  
                if hasattr(resource_guardian, '_on_metrics_update'):
                    central_monitor.subscribe("resource_guardian", resource_guardian._on_metrics_update)
                
                # Ø§ØªØµØ§Ù„ monitoring_dashboard
                if hasattr(monitoring_dashboard, '_on_metrics_update'):
                    central_monitor.subscribe("monitoring_dashboard", monitoring_dashboard._on_metrics_update)
                
                print("âœ… All components subscribed to central_monitor")
            else:
                print("âš ï¸ Central monitor not available for subscription")
                
        except Exception as e:
            print(f"âš ï¸ Could not connect to central_monitor: {e}")
            
        # Û². ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
        print("ğŸš€ Starting background components from debug_system.tools...")
        
        try:
            background_worker.start()
            print("âœ… IntelligentBackgroundWorker STARTED")
        except Exception as e:
            print(f"âŒ Background worker start failed: {e}")
        
        try:
            resource_guardian.start_monitoring()
            print("âœ… ResourceGuardian MONITORING STARTED")
        except Exception as e:
            print(f"âŒ Resource guardian start failed: {e}")
        
        try:
            time_scheduler.start_scheduling()
            print("âœ… TimeAwareScheduler STARTED")
        except Exception as e:
            print(f"âŒ Time scheduler start failed: {e}")
        
        try:
            recovery_manager.start_monitoring()
            print("âœ… RecoveryManager MONITORING STARTED")
        except Exception as e:
            print(f"âŒ Recovery manager start failed: {e}")
        
        try:
            monitoring_dashboard.start_monitoring()
            print("âœ… MonitoringDashboard STARTED")
        except Exception as e:
            print(f"âŒ Monitoring dashboard start failed: {e}")
        
        # Û³. Ø§ØªØµØ§Ù„ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ Ù‡Ù…
        print("ğŸ”— Connecting components from debug_system.tools...")
        
        try:
            # Ø§ØªØµØ§Ù„ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø´Ø¨ÙˆØ±Ø¯
            monitoring_dashboard.background_worker = background_worker
            monitoring_dashboard.resource_manager = resource_guardian
            monitoring_dashboard.time_scheduler = time_scheduler
            monitoring_dashboard.recovery_manager = recovery_manager
            print("âœ… Components connected to dashboard")
        except Exception as e:
            print(f"âŒ Component connection failed: {e}")
        
        try:
            # Ø§ØªØµØ§Ù„ resource manager Ø¨Ù‡ scheduler
            time_scheduler.resource_manager = resource_guardian
            print("âœ… Resource manager connected to scheduler")
        except Exception as e:
            print(f"âŒ Scheduler connection failed: {e}")
        
        # Û´. Ø«Ø¨Øª Ú©Ø§Ø±Ù‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
        print("ğŸ“¥ Submitting real tasks from debug_system.tools...")
        
        try:
            background_worker.submit_real_tasks()
            print("âœ… Real tasks submitted")
        except Exception as e:
            print(f"âŒ Task submission failed: {e}")
            # Ø«Ø¨Øª Ú©Ø§Ø±Ù‡Ø§ÛŒ fallback
            try:
                from background_tasks import background_tasks
                background_worker.submit_task(
                    task_id="fallback_data_processing",
                    task_func=background_tasks.perform_real_data_processing,
                    task_type="normal",
                    priority=1,
                    data_type="coins"
                )
                print("âœ… Fallback tasks submitted")
            except Exception as fallback_e:
                print(f"âŒ Fallback task submission also failed: {fallback_e}")
        
        print("ğŸ‰ BACKGROUND WORKER SYSTEM FROM debug_system.tools ACTIVATION COMPLETED!")
        
        return {
            "status": "success",
            "components": {
                "background_worker": "active" if hasattr(background_worker, 'is_running') and background_worker.is_running else "unknown",
                "resource_guardian": "active" if hasattr(resource_guardian, 'is_monitoring') and resource_guardian.is_monitoring else "unknown",
                "time_scheduler": "active" if hasattr(time_scheduler, 'is_scheduling') and time_scheduler.is_scheduling else "unknown",
                "recovery_manager": "active" if hasattr(recovery_manager, 'is_monitoring') and recovery_manager.is_monitoring else "unknown",
                "monitoring_dashboard": "active" if hasattr(monitoring_dashboard, 'is_monitoring') and monitoring_dashboard.is_monitoring else "unknown"
            },
            "source": "debug_system.tools"
        }
        
    except Exception as e:
        print(f"âŒ CRITICAL ERROR in background system activation: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "failed", "error": str(e), "source": "debug_system.tools"}
        
@app.get("/api/debug/routes")
async def debug_all_routes():
    """Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø«Ø¨Øª Ø´Ø¯Ù‡"""
    routes = []
    for route in app.routes:
        if hasattr(route, "methods") and hasattr(route, "path"):
            routes.append({
                "path": route.path,
                "methods": list(route.methods),
                "name": getattr(route, "name", "Unknown")
            })
    return {
        "total_routes": len(routes),
        "routes": routes
    }
    
if DEBUG_SYSTEM_AVAILABLE and live_dashboard_manager and console_stream_manager:
    @app.get("/debug/dashboard")
    async def debug_dashboard():
        """ØµÙØ­Ù‡ Ø¯Ø´Ø¨ÙˆØ±Ø¯ Ø¯ÛŒØ¨Ø§Ú¯"""
        return FileResponse("debug_system/realtime/templates/dashboard.html")
    
    @app.get("/debug/console")
    async def debug_console():
        """ØµÙØ­Ù‡ Ú©Ù†Ø³ÙˆÙ„ Ø¯ÛŒØ¨Ø§Ú¯"""
        return FileResponse("debug_system/realtime/templates/console.html")
    
    @app.websocket("/debug/ws/dashboard")
    async def websocket_dashboard(websocket: WebSocket):
        """WebSocket Ø¨Ø±Ø§ÛŒ Ø¯Ø´Ø¨ÙˆØ±Ø¯ real-time"""
        await live_dashboard_manager.connect_dashboard(websocket)
        try:
            while True:
                await websocket.receive_text()
        except Exception:
            live_dashboard_manager.disconnect_dashboard(websocket)
    
    @app.websocket("/debug/ws/console")
    async def websocket_console(websocket: WebSocket):
        """WebSocket Ø¨Ø±Ø§ÛŒ Ú©Ù†Ø³ÙˆÙ„ real-time"""
        await console_stream_manager.connect(websocket)
        try:
            while True:
                await websocket.receive_text()
        except Exception:
            console_stream_manager.disconnect(websocket)

# ==================== ğŸ—ºï¸ ROADMAP COMPLETE ====================

VORTEXAI_ROADMAP = {
    "project": "VortexAI API v4.0.0",
    "description": "Complete Crypto AI System with 9 Main Routes",
    "version": "4.0.0",
    "timestamp": datetime.now().isoformat(),
    
    "ğŸš€ MAIN ROUTES": {
        "description": "Û¸ Ø±ÙˆØª Ù…Ø§Ø¯Ø± Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ…",
        "routes": {
            "HEALTH": {
                "base_path": "/api/health",
                "description": "Ø³Ù„Ø§Ù…Øª Ùˆ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø³ÛŒØ³ØªÙ…",
                "endpoints": {
                    "status": "GET /api/health/status - ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…",
                    "overview": "GET /api/health/overview - Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…",
                    "ping": "GET /api/health/ping - ØªØ³Øª Ø­ÛŒØ§Øª Ø³ÛŒØ³ØªÙ…",
                    "version": "GET /api/health/version - Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…",
                    "debug_endpoints": "GET /api/health/debug/endpoints - Ø¯ÛŒØ¨Ø§Ú¯ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§",
                    "debug_system": "GET /api/health/debug/system - Ø¯ÛŒØ¨Ø§Ú¯ Ø³ÛŒØ³ØªÙ…",
                    "debug_reports_daily": "GET /api/health/debug/reports/daily - Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡",
                    "debug_reports_performance": "GET /api/health/debug/reports/performance - Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯",
                    "debug_reports_security": "GET /api/health/debug/reports/security - Ú¯Ø²Ø§Ø±Ø´ Ø§Ù…Ù†ÛŒØªÛŒ",
                    "debug_metrics_live": "GET /api/health/debug/metrics/live - Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ù‡"
                }
            },
            
            "COINS": {
                "base_path": "/api/coins",
                "description": "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§",
                "endpoints": {
                    "list": "GET /api/coins/list - Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§",
                    "details": "GET /api/coins/details/{coin_id} - Ø¬Ø²Ø¦ÛŒØ§Øª Ù†Ù…Ø§Ø¯",
                    "charts": "GET /api/coins/charts/{coin_id} - Ú†Ø§Ø±Øª Ù†Ù…Ø§Ø¯", 
                    "multi_charts": "GET /api/coins/multi-charts - Ú†Ø§Ø±Øª Ú†Ù†Ø¯Ù†Ù…Ø§Ø¯",
                    "price_avg": "GET /api/coins/price/avg - Ù‚ÛŒÙ…Øª Ù…ØªÙˆØ³Ø·"
                }
            },
            
            "EXCHANGES": {
                "base_path": "/api/exchanges", 
                "description": "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§",
                "endpoints": {
                    "list": "GET /api/exchanges/list - Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§",
                    "markets": "GET /api/exchanges/markets - Ù…Ø§Ø±Ú©Øªâ€ŒÙ‡Ø§",
                    "fiats": "GET /api/exchanges/fiats - Ø§Ø±Ø²Ù‡Ø§ÛŒ ÙÛŒØ§Øª",
                    "currencies": "GET /api/exchanges/currencies - Ø§Ø±Ø²Ù‡Ø§",
                    "price": "GET /api/exchanges/price - Ù‚ÛŒÙ…Øª ØµØ±Ø§ÙÛŒ"
                }
            },
            
            "NEWS": {
                "base_path": "/api/news",
                "description": "Ø§Ø®Ø¨Ø§Ø± Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡", 
                "endpoints": {
                    "all": "GET /api/news/all - Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ",
                    "by_type": "GET /api/news/type/{news_type} - Ø§Ø®Ø¨Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹",
                    "sources": "GET /api/news/sources - Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ",
                    "detail": "GET /api/news/detail/{news_id} - Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø¨Ø±"
                }
            },
            
            "INSIGHTS": {
                "base_path": "/api/insights",
                "description": "ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§",
                "endpoints": {
                    "btc_dominance": "GET /api/insights/btc-dominance - Ø¯Ø§Ù…ÛŒÙ†Ù†Ø³ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†",
                    "fear_greed": "GET /api/insights/fear-greed - Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹",
                    "fear_greed_chart": "GET /api/insights/fear-greed/chart - Ú†Ø§Ø±Øª ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹",
                    "rainbow_chart": "GET /api/insights/rainbow-chart/{coin_id} - Ú†Ø§Ø±Øª Ø±Ù†Ú¯ÛŒÙ†â€ŒÚ©Ù…Ø§Ù†"
                }
            },
            
            "RAW_COINS": {
                "base_path": "/api/raw/coins", 
                "description": "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ - Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
                "endpoints": {
                    "list": "GET /api/raw/coins/list - Ù„ÛŒØ³Øª Ø®Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§",
                    "details": "GET /api/raw/coins/details/{coin_id} - Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø§Ù… Ù†Ù…Ø§Ø¯",
                    "charts": "GET /api/raw/coins/charts/{coin_id} - Ú†Ø§Ø±Øª Ø®Ø§Ù… Ù†Ù…Ø§Ø¯",
                    "multi_charts": "GET /api/raw/coins/multi-charts - Ú†Ø§Ø±Øª Ø®Ø§Ù… Ú†Ù†Ø¯Ù†Ù…Ø§Ø¯",
                    "price_avg": "GET /api/raw/coins/price/avg - Ù‚ÛŒÙ…Øª Ù…ØªÙˆØ³Ø· Ø®Ø§Ù…",
                    "exchange_price": "GET /api/raw/coins/price/exchange - Ù‚ÛŒÙ…Øª ØµØ±Ø§ÙÛŒ Ø®Ø§Ù…",
                    "metadata": "GET /api/raw/coins/metadata - Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§",
                    "filters": "GET /api/raw/coins/filters - ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"
                }
            },
            
            "RAW_NEWS": {
                "base_path": "/api/raw/news",
                "description": "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± - Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
                "endpoints": {
                    "all": "GET /api/raw/news/all - Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ Ø®Ø§Ù…", 
                    "by_type": "GET /api/raw/news/type/{news_type} - Ø§Ø®Ø¨Ø§Ø± Ø®Ø§Ù… Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹",
                    "sources": "GET /api/raw/news/sources - Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ø®Ø§Ù…",
                    "detail": "GET /api/raw/news/detail/{news_id} - Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø¨Ø± Ø®Ø§Ù…",
                    "sentiment_analysis": "GET /api/raw/news/sentiment-analysis - ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª",
                    "metadata": "GET /api/raw/news/metadata - Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ø§Ø®Ø¨Ø§Ø±"
                }
            },

            "ğŸ¤– AI BRAIN SYSTEM": {
                "base_path": "/api/ai",
                "description": "Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø®ÙˆØ¯Ø¢Ù…ÙˆØ² VortexAI",
                "endpoints": {
                    "query": "POST /api/ai/query - Ù¾Ø±Ø³Ø´ Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
                    "health": "GET /api/ai/health - Ø³Ù„Ø§Ù…Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", 
                    "stats": "GET /api/ai/stats - Ø¢Ù…Ø§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
                    "learn": "POST /api/ai/learn - Ø¢Ù…ÙˆØ²Ø´ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"
                }
            },
            
            "RAW_INSIGHTS": {
                "base_path": "/api/raw/insights",
                "description": "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø¨ÛŒÙ†Ø´ Ùˆ ØªØ­Ù„ÛŒÙ„ - Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
                "endpoints": {
                    "btc_dominance": "GET /api/raw/insights/btc-dominance - Ø¯Ø§Ù…ÛŒÙ†Ù†Ø³ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ø®Ø§Ù…",
                    "fear_greed": "GET /api/raw/insights/fear-greed - Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø®Ø§Ù…", 
                    "fear_greed_chart": "GET /api/raw/insights/fear-greed/chart - Ú†Ø§Ø±Øª ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø®Ø§Ù…",
                    "rainbow_chart": "GET /api/raw/insights/rainbow-chart/{coin_id} - Ú†Ø§Ø±Øª Ø±Ù†Ú¯ÛŒÙ†â€ŒÚ©Ù…Ø§Ù† Ø®Ø§Ù…",
                    "market_analysis": "GET /api/raw/insights/market-analysis - ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§Ø²Ø§Ø±",
                    "metadata": "GET /api/raw/insights/metadata - Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§"
                }
            }
        }
    },
    
    "ğŸ“š DOCUMENTATION": {
        "description": "Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ùˆ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ",
        "routes": {
            "complete_docs": "GET /api/docs/complete - Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ API",
            "coins_docs": "GET /api/docs/coins - Ù…Ø³ØªÙ†Ø¯Ø§Øª ØªØ®ØµØµÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§", 
            "code_examples": "GET /api/docs/examples - Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø¯",
            "interactive_docs": "GET /docs - Ù…Ø³ØªÙ†Ø¯Ø§Øª ØªØ¹Ø§Ù…Ù„ÛŒ (Swagger UI)",
            "redoc_docs": "GET /redoc - Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø²ÛŒØ¨Ø§ (ReDoc)"
        }
    },
    
    "ğŸ”§ DEBUG & MONITORING": {
        "description": "Ø³ÛŒØ³ØªÙ… Ø¯ÛŒØ¨Ø§Ú¯ Ùˆ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡",
        "routes": {
            "DEBUG_DASHBOARD": "GET /debug/dashboard - Ø¯Ø´Ø¨ÙˆØ±Ø¯ Ø¯ÛŒØ¨Ø§Ú¯",
            "DEBUG_CONSOLE": "GET /debug/console - Ú©Ù†Ø³ÙˆÙ„ Ø¯ÛŒØ¨Ø§Ú¯",
            "DEBUG_WS_DASHBOARD": "WS /debug/ws/dashboard - WebSocket Ø¯Ø´Ø¨ÙˆØ±Ø¯",
            "DEBUG_WS_CONSOLE": "WS /debug/ws/console - WebSocket Ú©Ù†Ø³ÙˆÙ„",
            "METRICS_ALL": "GET /api/health/metrics - ØªÙ…Ø§Ù… Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§",
            "ALERTS_ACTIVE": "GET /api/health/alerts - Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„",
            "REPORTS_DAILY": "GET /api/health/reports/daily - Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡",
            "REALTIME_CONSOLE": "WS /api/health/debug/realtime/console - Ú©Ù†Ø³ÙˆÙ„ Real-Time",
            "REALTIME_DASHBOARD": "WS /api/health/debug/realtime/dashboard - Ø¯Ø´Ø¨ÙˆØ±Ø¯ Real-Time"
        }
    }
}

@app.get("/")
async def root():
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø±ÙˆØªâ€ŒÙ‡Ø§"""
    return {
        "message": "ğŸš€ VortexAI API Server v4.0.0 - Complete Crypto AI System",
        "version": "4.0.0", 
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "documentation": {
            "swagger": "/docs",
            "redoc": "/redoc", 
            "roadmap": "/api/roadmap",
            "complete_docs": "/api/docs/complete",
            "code_examples": "/api/docs/examples"
        },
        "quick_start": {
            "health_check": "/api/health/status",
            "bitcoin_data": "/api/coins/details/bitcoin",
            "latest_news": "/api/news/all?limit=5",
            "market_sentiment": "/api/insights/fear-greed",
            "ai_data_samples": "/api/raw/coins/metadata",
            "debug_endpoints": "/api/health/debug/endpoints",
            "debug_system": "/api/health/debug/system"
        },
        "system_info": {
            "total_routes": len(app.routes),
            "ai_system_available": AI_SYSTEM_AVAILABLE,
            "ai_system_status": "active" if AI_SYSTEM_AVAILABLE else "inactive",
            "debug_system": "active" if DEBUG_SYSTEM_AVAILABLE else "inactive",
            "coinstats_available": COINSTATS_AVAILABLE,
            "cache_system": "active" if CACHE_AVAILABLE else "inactive",
            "startup_time": datetime.now().isoformat(),
            "ai_ready": True
        }
    }

@app.get("/api/roadmap")
async def get_roadmap():
    """Ø¯Ø±ÛŒØ§ÙØª Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø±ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
    return VORTEXAI_ROADMAP

@app.get("/api/quick-reference")
async def quick_reference():
    """Ù…Ø±Ø¬Ø¹ Ø³Ø±ÛŒØ¹ Ø±ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…"""
    return {
        "title": "VortexAI API - Quick Reference",
        "description": "Ù…Ø±Ø¬Ø¹ Ø³Ø±ÛŒØ¹ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ",
        "timestamp": datetime.now().isoformat(),
        
        "essential_endpoints": {
            "health": {
                "url": "/api/health/status",
                "description": "Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…"
            },
            "coins_list": {
                "url": "/api/coins/list", 
                "description": "Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§"
            },
            "coin_details": {
                "url": "/api/coins/details/{coin_id}",
                "description": "Ø¬Ø²Ø¦ÛŒØ§Øª Ù†Ù…Ø§Ø¯ Ø®Ø§Øµ"
            },
            "coin_charts": {
                "url": "/api/coins/charts/{coin_id}",
                "description": "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Ø§Ø±Øª"
            },
            "news": {
                "url": "/api/news/all",
                "description": "Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§Ø²Ø§Ø±"
            },
            "fear_greed": {
                "url": "/api/insights/fear-greed",
                "description": "Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹"
            },
            "exchanges": {
                "url": "/api/exchanges/list",
                "description": "Ù„ÛŒØ³Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§"
            }
        }
    }

@app.get("/api/endpoints/count")
async def count_endpoints():
    """Ø´Ù…Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§"""
    total_endpoints = 0
    routes_info = []
    
    for route in app.routes:
        if hasattr(route, "methods") and hasattr(route, "path"):
            total_endpoints += len(route.methods)
            routes_info.append({
                "path": route.path,
                "methods": list(route.methods),
                "name": getattr(route, "name", "Unknown")
            })
    
    return {
        "total_endpoints": total_endpoints,
        "total_routes": len(app.routes),
        "timestamp": datetime.now().isoformat(),
        "routes_by_category": {
            "health": len([r for r in routes_info if '/api/health' in r['path']]),
            "coins": len([r for r in routes_info if '/api/coins' in r['path']]),
            "raw_coins": len([r for r in routes_info if '/api/raw/coins' in r['path']]),
            "news": len([r for r in routes_info if '/api/news' in r['path']]),
            "raw_news": len([r for r in routes_info if '/api/raw/news' in r['path']]),
            "insights": len([r for r in routes_info if '/api/insights' in r['path']]),
            "raw_insights": len([r for r in routes_info if '/api/raw/insights' in r['path']]),
            "exchanges": len([r for r in routes_info if '/api/exchanges' in r['path']]),
            "documentation": len([r for r in routes_info if '/api/docs' in r['path']]),
            "debug": len([r for r in routes_info if '/debug' in r['path']])
        },
        "sample_routes": routes_info[:10]
    }

@app.get("/api/monitoring/status")
async def get_monitoring_status():
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ - Dynamic"""
    try:
        from debug_system.monitors.system_monitor import central_monitor
        
        if central_monitor:
            # Dynamic checking
            background_worker_connected = "background_worker" in central_monitor.subscribers
            resource_guardian_connected = "resource_guardian" in central_monitor.subscribers
            
            return {
                "central_monitoring": {
                    "status": "active" if central_monitor.is_monitoring else "inactive",
                    "subscribers": len(central_monitor.subscribers),
                    "subscriber_names": list(central_monitor.subscribers.keys()),
                    "collection_interval": central_monitor.collection_interval,
                    "last_collection": central_monitor.last_collection_time.isoformat() if central_monitor.last_collection_time else None,
                    "metrics_cache_age": round((datetime.now() - central_monitor.last_collection_time).total_seconds(), 1) if central_monitor.last_collection_time else None
                },
                "component_status": {
                    "background_worker": "connected" if background_worker_connected else "disconnected",
                    "resource_guardian": "connected" if resource_guardian_connected else "disconnected",
                    "debug_manager": "connected" if "debug_manager" in central_monitor.subscribers else "disconnected"
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "status": "inactive",
                "message": "Central monitoring system not initialized",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        return {
            "status": "error",
            "message": f"Error checking monitoring status: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/system/info")
async def system_info():
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ…"""
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    return {
        "system": {
            "python_version": sys.version,
            "platform": sys.platform,
            "server_time": datetime.now().isoformat(),
            "uptime_seconds": int(time.time() - psutil.boot_time())
        },
        "resources": {
            "cpu_usage_percent": psutil.cpu_percent(interval=1),
            "memory_usage_percent": memory.percent,
            "memory_used_gb": round(memory.used / (1024**3), 2),
            "memory_total_gb": round(memory.total / (1024**3), 2),
            "disk_usage_percent": disk.percent,
            "disk_used_gb": round(disk.used / (1024**3), 2),
            "disk_total_gb": round(disk.total / (1024**3), 2)
        },
        "api_status": {
            "total_endpoints": len(app.routes),
            "coinstats_available": COINSTATS_AVAILABLE,
            "debug_system_available": DEBUG_SYSTEM_AVAILABLE,
            "debug_system_status": "active" if DEBUG_SYSTEM_AVAILABLE else "inactive",
            "version": "4.0.0",
            "ai_ready": True
        },
        "timestamp": datetime.now().isoformat()
    }

# Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ 404
@app.exception_handler(404)
async def not_found_exception_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "Endpoint not found",
            "message": "The requested endpoint does not exist",
            "timestamp": datetime.now().isoformat(),
            "suggestions": {
                "check_docs": "Visit /api/docs/complete for complete documentation",
                "check_roadmap": "Visit /api/roadmap for system overview", 
                "check_health": "Visit /api/health/status to check system health",
                "common_endpoints": {
                    "health": "/api/health/status",
                    "coins_list": "/api/coins/list", 
                    "news": "/api/news/all",
                    "insights": "/api/insights/fear-greed",
                    "ai_data": "/api/raw/coins/metadata",
                    "debug_endpoints": "/api/health/debug/endpoints"
                }
            }
        }
    )

# ğŸ¯ **ØªØ£Ø®ÛŒØ± Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ…**: Ø§ÛŒÙ† Ú©Ø¯ Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹ Ø³Ø±ÙˆØ± Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
print("=" * 60)
print("ğŸ¯ VORTEXAI - CPU OPTIMIZATION MODE ACTIVATED")
print("=" * 60)

# ØªØ£Ø®ÛŒØ± Û²Û° Ø«Ø§Ù†ÛŒÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø± Ø´Ø¯Ù† Ø³ÛŒØ³ØªÙ…
print("â³ SYSTEM STABILIZATION: Waiting 20 seconds before server start...")
import time
time.sleep(20)

print("âœ… System stabilization complete - Starting server now")
print("=" * 60)

# ğŸ”¥ Ø§ØµÙ„Ø§Ø­ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² CPU Ø¨Ø§Ù„Ø§ - Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ£Ø®ÛŒØ± Ù‡ÙˆØ´Ù…Ù†Ø¯
if __name__ != "__main__":  # ÙÙ‚Ø· Ø¯Ø± Ø­Ø§Ù„Øª import Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
    # ğŸ¯ ØªØ£Ø®ÛŒØ± Û±Ûµ Ø«Ø§Ù†ÛŒÙ‡â€ŒØ§ÛŒ Ù‚Ø¨Ù„ Ø§Ø² ÙØ¹Ø§Ù„ Ø´Ø¯Ù† central_monitor
    print("â³ Starting 15-second stabilization period before activating monitoring systems...")
    import time
    time.sleep(15)
    
    # ğŸ¯ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ central_monitor Ø¨Ø§ ØªØ£Ø®ÛŒØ±
    print("ğŸ¯ Delayed initialization of Central Monitoring System...")
    try:
        from debug_system.monitors.system_monitor import central_monitor
        
        if central_monitor:
            central_monitor.start_monitoring()
            print(f"âœ… Central Monitoring System activated with {len(central_monitor.subscribers)} subscribers")
        else:
            print("âš ï¸ Central monitor not available in main.py")
    except Exception as e:
        print(f"âš ï¸ Central monitor activation in main.py failed: {e}")
    import uvicorn
    port = int(os.getenv("PORT", 10000))
    
    print("ğŸš€" * 50)
    print("ğŸ¯ VORTEXAI API SERVER v4.0.0 - AI READY")
    print("ğŸš€" * 50)
    print(f"ğŸ“Š Total Routes: {len(app.routes)}")
    print(f"ğŸŒ Server URL: http://localhost:{port}")
    print(f"ğŸ“š Documentation: http://localhost:{port}/docs")
    print(f"ğŸ—ºï¸  Roadmap: http://localhost:{port}/api/roadmap")
    print(f"ğŸ“– Complete Docs: http://localhost:{port}/api/docs/complete")
    print("ğŸ¯ Quick Start:")
    print(f"   â€¢ Health Check: http://localhost:{port}/api/health/status")
    print(f"   â€¢ Bitcoin Details: http://localhost:{port}/api/coins/details/bitcoin") 
    print(f"   â€¢ Latest News: http://localhost:{port}/api/news/all?limit=5")
    print(f"   â€¢ Fear & Greed: http://localhost:{port}/api/insights/fear-greed")
    print(f"   â€¢ AI Data Samples: http://localhost:{port}/api/raw/coins/metadata")
    print(f"   â€¢ Debug Endpoints: http://localhost:{port}/api/health/debug/endpoints")
    print(f"   â€¢ Debug System: http://localhost:{port}/api/health/debug/system")
    print("ğŸ”§ Debug System: " + ("âœ… FULLY ACTIVE" if DEBUG_SYSTEM_AVAILABLE else "âŒ UNAVAILABLE"))
    if DEBUG_SYSTEM_AVAILABLE:
        print(f"   â€¢ Real-time Dashboard: http://localhost:{port}/debug/dashboard")
        print(f"   â€¢ Debug Console: http://localhost:{port}/debug/console")
        print(f"   â€¢ System Reports: http://localhost:{port}/api/health/debug/reports/daily")
    print("ğŸ¤– AI Ready: âœ… YES")
    print("ğŸ“ˆ CoinStats API: " + ("âœ… AVAILABLE" if COINSTATS_AVAILABLE else "âŒ UNAVAILABLE"))
    print("ğŸš€" * 50)
    
    uvicorn.run(app, host="0.0.0.0", port=port, access_log=True)
