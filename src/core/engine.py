# ğŸ“ src/core/engine.py

import asyncio
import logging
import signal
import sys
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd
import numpy as np
import torch

from ..data.data_manager import SmartDataManager
from ..data.processing_pipeline import DataProcessingPipeline
from .spiking_transformer.transformer_block import SpikingTransformerBlock
from .technical_analysis.signal_engine import IntelligentSignalEngine, TradingSignal
from .risk_management.position_sizing import DynamicPositionSizing, PositionSizingResult
from .multi_timeframe.timeframe_sync import MultiTimeframeAnalyzer, TimeFrame
from ..ai_ml.regime_classifier import MarketRegimeClassifier
from ..ai_ml.pattern_predictor import PatternPredictor
from ..backtesting.walk_forward import WalkForwardAnalyzer
from ..visualization.dashboard_builder import TradingDashboard
from ..monitoring.health_check import SystemHealthChecker
from ..utils.performance_tracker import PerformanceTracker
from ..utils.memory_monitor import MemoryMonitor

class CryptoAnalysisEngine:
    """Ù…ÙˆØªÙˆØ± Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.logger = self._setup_logging()
        self.performance_tracker = PerformanceTracker()
        self.memory_monitor = MemoryMonitor()
        self.health_checker = SystemHealthChecker()
        
        # Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        self.data_manager = None
        self.processing_pipeline = None
        self.spiking_transformer = None
        self.signal_engine = None
        self.risk_manager = None
        self.multi_timeframe_analyzer = None
        self.regime_classifier = None
        self.pattern_predictor = None
        self.backtester = None
        self.dashboard = None
        
        self.is_running = False
        
    def _setup_logging(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/crypto_engine.log'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        return logging.getLogger(__name__)
    
    async def initialize(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ØªÙ…Ø§Ù… Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§"""
        self.logger.info("ğŸ”„ Initializing Crypto Analysis Engine...")
        
        try:
            # Û±. Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡
            with self.performance_tracker.track("data_manager_init"):
                self.data_manager = SmartDataManager(
                    api_key=self.config.get('api_key')
                )
            
            # Û². Ù¾Ø§ÛŒÙ¾â€ŒÙ„Ø§ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´
            with self.performance_tracker.track("pipeline_init"):
                self.processing_pipeline = DataProcessingPipeline()
            
            # Û³. Spiking Transformer
            with self.performance_tracker.track("transformer_init"):
                self.spiking_transformer = SpikingTransformerBlock(
                    d_model=self.config['transformer']['d_model'],
                    n_heads=self.config['transformer']['n_heads'],
                    seq_len=self.config['transformer']['seq_len']
                )
            
            # Û´. Ù…ÙˆØªÙˆØ± Ø³ÛŒÚ¯Ù†Ø§Ù„
            with self.performance_tracker.track("signal_engine_init"):
                self.signal_engine = IntelligentSignalEngine()
            
            # Ûµ. Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©
            with self.performance_tracker.track("risk_manager_init"):
                self.risk_manager = DynamicPositionSizing(
                    total_capital=self.config['risk']['total_capital'],
                    max_risk_per_trade=self.config['risk']['max_risk_per_trade']
                )
            
            # Û¶. ØªØ­Ù„ÛŒÙ„ Ú†Ù†Ø¯Ø²Ù…Ø§Ù†Ù‡
            with self.performance_tracker.track("multi_timeframe_init"):
                self.multi_timeframe_analyzer = MultiTimeframeAnalyzer()
            
            # Û·. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
            with self.performance_tracker.track("ai_models_init"):
                self.regime_classifier = MarketRegimeClassifier()
                self.pattern_predictor = PatternPredictor()
                
                # Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡
                if not self.regime_classifier.load_model():
                    self.logger.warning("âš ï¸ Could not load pre-trained regime classifier")
                if not self.pattern_predictor.load_model():
                    self.logger.warning("âš ï¸ Could not load pre-trained pattern predictor")
            
            # Û¸. Ø³ÛŒØ³ØªÙ… Ø¨Ú©â€ŒØªØ³Øª
            with self.performance_tracker.track("backtester_init"):
                self.backtester = WalkForwardAnalyzer(
                    initial_capital=self.config['backtesting']['initial_capital']
                )
            
            # Û¹. Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
            with self.performance_tracker.track("dashboard_init"):
                self.dashboard = TradingDashboard()
            
            self.logger.info("âœ… All components initialized successfully")
            self.health_checker.update_component_status("all_components", "healthy")
            
        except Exception as e:
            self.logger.error(f"âŒ Initialization failed: {e}")
            self.health_checker.update_component_status("all_components", "failed")
            raise
    
    async def run_analysis_pipeline(self, symbols: List[str] = None) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ø§ÛŒÙ¾â€ŒÙ„Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§"""
        if symbols is None:
            symbols = self.config['default_symbols']
        
        self.logger.info(f"ğŸ” Starting analysis pipeline for {len(symbols)} symbols")
        
        analysis_results = {}
        
        for symbol in symbols:
            try:
                symbol_result = await self._analyze_symbol(symbol)
                analysis_results[symbol] = symbol_result
                
                self.logger.info(f"âœ… Analysis completed for {symbol}")
                
            except Exception as e:
                self.logger.error(f"âŒ Analysis failed for {symbol}: {e}")
                analysis_results[symbol] = {'error': str(e)}
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ù„ÛŒ
        summary = self._generate_analysis_summary(analysis_results)
        
        self.logger.info(f"ğŸ“Š Analysis pipeline completed. Processed {len(analysis_results)} symbols")
        
        return {
            'timestamp': datetime.now().isoformat(),
            'symbols_analyzed': list(analysis_results.keys()),
            'results': analysis_results,
            'summary': summary,
            'performance_metrics': self.performance_tracker.get_summary(),
            'memory_usage': self.memory_monitor.get_usage_stats()
        }
    
    async def _analyze_symbol(self, symbol: str) -> Dict:
        """Ø¢Ù†Ø§Ù„ÛŒØ² Ú©Ø§Ù…Ù„ ÛŒÚ© Ù†Ù…Ø§Ø¯"""
        symbol_result = {}
        
        # Û±. Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡
        with self.performance_tracker.track(f"data_fetch_{symbol}"):
            raw_data = self.data_manager.get_coins_data(symbols=[symbol], limit=100)
            if not raw_data:
                raise Exception(f"No data available for {symbol}")
            
            processed_data = self.processing_pipeline.process_raw_data(raw_data)
            symbol_result['raw_data_stats'] = {
                'data_points': len(raw_data.get('result', [])),
                'processing_time': processed_data.get('processing_stats', {})
            }
        
        # Û². ØªØ­Ù„ÛŒÙ„ Ú†Ù†Ø¯Ø²Ù…Ø§Ù†Ù‡
        with self.performance_tracker.track(f"multi_tf_analysis_{symbol}"):
            multi_tf_data = self._prepare_multi_timeframe_data(symbol)
            mt_analysis = self.multi_timeframe_analyzer.analyze_symbol(symbol, multi_tf_data)
            symbol_result['multi_timeframe'] = mt_analysis
        
        # Û³. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Spiking Transformer
        with self.performance_tracker.track(f"transformer_prediction_{symbol}"):
            try:
                transformer_input = self._prepare_transformer_input(processed_data)
                with self.memory_monitor.track("transformer_inference"):
                    with torch.no_grad():
                        transformer_output = self.spiking_transformer(transformer_input)
                    
                    symbol_result['transformer_prediction'] = {
                        'output': transformer_output.detach().numpy().tolist(),
                        'spike_stats': self.spiking_transformer.get_spike_statistics(),
                        'prediction_direction': 'BULLISH' if transformer_output[0, -1, 0] > 0.5 else 'BEARISH',
                        'confidence': float(transformer_output[0, -1, 0])
                    }
            except Exception as e:
                self.logger.warning(f"Transformer prediction failed for {symbol}: {e}")
                symbol_result['transformer_prediction'] = {'error': str(e)}
        
        # Û´. ØªØ´Ø®ÛŒØµ Ø±Ú˜ÛŒÙ… Ø¨Ø§Ø²Ø§Ø±
        with self.performance_tracker.track(f"regime_classification_{symbol}"):
            try:
                regime_prediction = self.regime_classifier.predict_regime(processed_data)
                symbol_result['market_regime'] = regime_prediction
            except Exception as e:
                self.logger.warning(f"Regime classification failed for {symbol}: {e}")
                symbol_result['market_regime'] = {'error': str(e)}
        
        # Ûµ. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ù„Ú¯Ùˆ
        with self.performance_tracker.track(f"pattern_prediction_{symbol}"):
            try:
                pattern_prediction = self.pattern_predictor.predict_pattern(processed_data)
                symbol_result['pattern_prediction'] = pattern_prediction
            except Exception as e:
                self.logger.warning(f"Pattern prediction failed for {symbol}: {e}")
                symbol_result['pattern_prediction'] = {'error': str(e)}
        
        # Û¶. ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„
        with self.performance_tracker.track(f"signal_generation_{symbol}"):
            try:
                market_data = {symbol: processed_data}
                technical_indicators = self._extract_technical_indicators(processed_data)
                
                signals = self.signal_engine.generate_signals(market_data, {symbol: technical_indicators})
                symbol_signals = [s for s in signals if s.symbol == symbol]
                
                symbol_result['signals'] = [self._signal_to_dict(s) for s in symbol_signals]
            except Exception as e:
                self.logger.warning(f"Signal generation failed for {symbol}: {e}")
                symbol_result['signals'] = []
        
        # Û·. Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
        with self.performance_tracker.track(f"risk_assessment_{symbol}"):
            try:
                risk_assessments = []
                market_data = {symbol: self._prepare_multi_timeframe_data(symbol)['1h']}
                
                for signal in symbol_signals:
                    position_size = self.risk_manager.calculate_position_size(
                        signal, market_data
                    )
                    risk_assessments.append(self._position_to_dict(position_size))
                
                symbol_result['risk_assessment'] = risk_assessments
            except Exception as e:
                self.logger.warning(f"Risk assessment failed for {symbol}: {e}")
                symbol_result['risk_assessment'] = []
        
        # Û¸. Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        symbol_result['analysis_summary'] = self._generate_symbol_summary(symbol_result)
        symbol_result['timestamp'] = datetime.now().isoformat()
        
        return symbol_result
    
    def _prepare_multi_timeframe_data(self, symbol: str) -> Dict:
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ø²Ù…Ø§Ù†Ù‡"""
        # Ø¯Ø± Ù†Ø³Ø®Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        # Ø§ÛŒÙ†Ø¬Ø§ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        
        base_price = 50000
        volatility = 0.02
        
        # Ø¯Ø§Ø¯Ù‡ 1h
        hours_1h = 100
        prices_1h = base_price + np.cumsum(np.random.randn(hours_1h) * base_price * volatility)
        
        data_1h = pd.DataFrame({
            'open': prices_1h + np.random.randn(hours_1h) * 10,
            'high': prices_1h + np.abs(np.random.randn(hours_1h) * 20),
            'low': prices_1h - np.abs(np.random.randn(hours_1h) * 20),
            'close': prices_1h,
            'volume': np.random.randint(1000, 10000, hours_1h)
        }, index=pd.date_range(end=datetime.now(), periods=hours_1h, freq='1h'))
        
        # Ø¯Ø§Ø¯Ù‡ 4h (ØªØ¹Ø¯Ø§Ø¯ Ú©Ù…ØªØ±)
        hours_4h = 25
        prices_4h = base_price + np.cumsum(np.random.randn(hours_4h) * base_price * volatility * 2)
        
        data_4h = pd.DataFrame({
            'open': prices_4h + np.random.randn(hours_4h) * 20,
            'high': prices_4h + np.abs(np.random.randn(hours_4h) * 40),
            'low': prices_4h - np.abs(np.random.randn(hours_4h) * 40),
            'close': prices_4h,
            'volume': np.random.randint(5000, 20000, hours_4h)
        }, index=pd.date_range(end=datetime.now(), periods=hours_4h, freq='4h'))
        
        return {
            '1h': data_1h,
            '4h': data_4h
        }
    
    def _prepare_transformer_input(self, processed_data):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Transformer"""
        # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ù‡ ØªÙ†Ø³ÙˆØ±
        features = []
        
        for coin in processed_data.get('result', []):
            feature_vector = []
            for key, value in coin.items():
                if isinstance(value, (int, float)) and not key.endswith('_id'):
                    feature_vector.append(value)
            # Ø§Ú¯Ø± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ú©Ù… Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¨Ø§ ØµÙØ± Ù¾Ø± Ú©Ù†ÛŒÙ…
            while len(feature_vector) < 20:
                feature_vector.append(0.0)
            features.append(feature_vector[:20])  # Ø­Ø¯Ø§Ú©Ø«Ø± 20 ÙˆÛŒÚ˜Ú¯ÛŒ
        
        if not features:
            # Ø¯Ø§Ø¯Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù†Ø¨ÙˆØ¯
            features = [[0.0] * 20 for _ in range(10)]
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØªÙ†Ø³ÙˆØ±: (batch_size, seq_len, features)
        tensor_data = torch.tensor([features], dtype=torch.float32)
        return tensor_data
    
    def _extract_technical_indicators(self, processed_data):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡"""
        if not processed_data.get('result'):
            return {}
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÙˆÙ„ÛŒÙ† Ú©ÙˆÛŒÙ† Ø¯Ø± Ù†ØªØ§ÛŒØ¬
        coin_data = processed_data['result'][0]
        
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ - Ø¯Ø± Ù†Ø³Ø®Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ø§Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return {
            'rsi': pd.Series([coin_data.get('price', 50000) / 1000 + 30]),  # RSI Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
            'macd': pd.Series([coin_data.get('price', 50000) / 10000]),
            'macd_signal': pd.Series([coin_data.get('price', 50000) / 12000]),
            'bollinger_upper': pd.Series([coin_data.get('price', 50000) * 1.02]),
            'bollinger_lower': pd.Series([coin_data.get('price', 50000) * 0.98]),
            'volume': pd.Series([coin_data.get('volume', 1000)]),
            'price_change_1h': pd.Series([coin_data.get('price', 50000) / 50000 - 1])
        }
    
    def _signal_to_dict(self, signal: TradingSignal) -> Dict:
        """ØªØ¨Ø¯ÛŒÙ„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ"""
        return {
            'symbol': signal.symbol,
            'signal_type': signal.signal_type.value,
            'confidence': signal.confidence,
            'price': signal.price,
            'timestamp': signal.timestamp.isoformat(),
            'reasons': signal.reasons,
            'targets': signal.targets,
            'stop_loss': signal.stop_loss,
            'time_horizon': signal.time_horizon,
            'risk_reward_ratio': signal.risk_reward_ratio
        }
    
    def _position_to_dict(self, position: PositionSizingResult) -> Dict:
        """ØªØ¨Ø¯ÛŒÙ„ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ"""
        return {
            'symbol': position.symbol,
            'position_size': position.position_size,
            'risk_amount': position.risk_amount,
            'stop_loss': position.stop_loss,
            'take_profit': position.take_profit,
            'leverage': position.leverage,
            'max_position_value': position.max_position_value
        }
    
    def _generate_symbol_summary(self, symbol_result: Dict) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯"""
        summary = {
            'overall_score': 0.0,
            'recommendation': 'HOLD',
            'confidence': 0.0,
            'key_factors': []
        }
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
        scores = []
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø§Ø² Transformer
        if 'transformer_prediction' in symbol_result and 'error' not in symbol_result['transformer_prediction']:
            transformer_conf = symbol_result['transformer_prediction'].get('confidence', 0)
            scores.append(transformer_conf)
            summary['key_factors'].append('AI Prediction')
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø§Ø² Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
        if symbol_result.get('signals'):
            best_signal = max(symbol_result['signals'], key=lambda x: x['confidence'])
            scores.append(best_signal['confidence'])
            summary['recommendation'] = best_signal['signal_type']
            summary['key_factors'].append('Technical Signals')
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø§Ø² Ø±Ú˜ÛŒÙ… Ø¨Ø§Ø²Ø§Ø±
        if 'market_regime' in symbol_result and 'error' not in symbol_result['market_regime']:
            regime_conf = symbol_result['market_regime'].get('confidence', 0)
            scores.append(regime_conf)
            summary['key_factors'].append('Market Regime')
        
        if scores:
            summary['overall_score'] = sum(scores) / len(scores)
            summary['confidence'] = summary['overall_score']
        
        return summary
    
    def _generate_analysis_summary(self, analysis_results: Dict) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„"""
        total_symbols = len(analysis_results)
        successful_analysis = len([r for r in analysis_results.values() if 'error' not in r.get('analysis_summary', {})])
        
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ø±Ú˜ÛŒÙ…â€ŒÙ‡Ø§
        all_signals = []
        market_regimes = {}
        
        for symbol, result in analysis_results.items():
            if 'signals' in result:
                all_signals.extend(result['signals'])
            
            if 'market_regime' in result and 'error' not in result['market_regime']:
                regime = result['market_regime']['regime']
                market_regimes[regime] = market_regimes.get(regime, 0) + 1
        
        buy_signals = [s for s in all_signals if s.get('signal_type') in ['BUY', 'STRONG_BUY']]
        sell_signals = [s for s in all_signals if s.get('signal_type') in ['SELL', 'STRONG_SELL']]
        
        return {
            'total_symbols_analyzed': total_symbols,
            'successful_analysis': successful_analysis,
            'success_rate': (successful_analysis / total_symbols * 100) if total_symbols > 0 else 0,
            'total_signals': len(all_signals),
            'buy_signals': len(buy_signals),
            'sell_signals': len(sell_signals),
            'strong_buy_signals': len([s for s in buy_signals if s.get('signal_type') == 'STRONG_BUY']),
            'strong_sell_signals': len([s for s in sell_signals if s.get('signal_type') == 'STRONG_SELL']),
            'market_regimes': market_regimes,
            'timestamp': datetime.now().isoformat(),
            'average_confidence': np.mean([s.get('confidence', 0) for s in all_signals]) if all_signals else 0
        }
    
    async def run_backtest(self, strategy_config: Dict) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ú©â€ŒØªØ³Øª Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ"""
        self.logger.info("ğŸ§ª Running strategy backtest...")
        
        try:
            # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ú©â€ŒØªØ³Øª
            backtest_data = self._generate_backtest_data()
            
            # Ø§Ø¬Ø±Ø§ÛŒ Walk-Forward Analysis
            result = self.backtester.run_walk_forward_analysis(
                strategy=self._load_strategy(strategy_config),
                data=backtest_data,
                window_size=strategy_config.get('window_size', 100),
                step_size=strategy_config.get('step_size', 20)
            )
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
            if result['window_results']:
                dashboard = self.dashboard.create_performance_dashboard(result['window_results'][0]['result'])
                dashboard_html = "Dashboard generated successfully"
            else:
                dashboard_html = "No results to display"
            
            return {
                'backtest_id': f"bt_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'strategy_config': strategy_config,
                'results': result,
                'dashboard': dashboard_html,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Backtest failed: {e}")
            raise
    
    def _generate_backtest_data(self):
        """ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ú©â€ŒØªØ³Øª"""
        dates = pd.date_range('2023-01-01', periods=1000, freq='1h')
        base_price = 50000
        returns = np.random.randn(1000) * 0.001  # Ø¨Ø§Ø²Ø¯Ù‡ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ ~0.1%
        prices = base_price * np.exp(np.cumsum(returns))
        
        return pd.DataFrame({
            'open': prices + np.random.randn(1000) * 10,
            'high': prices + np.abs(np.random.randn(1000) * 20),
            'low': prices - np.abs(np.random.randn(1000) * 20),
            'close': prices,
            'volume': np.random.randint(1000, 10000, 1000)
        }, index=dates)
    
    def _load_strategy(self, config: Dict):
        """Ù„ÙˆØ¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ"""
        # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒØŒ Ø§Ø² Ù‡Ù…Ø§Ù† IntelligentSignalEngine Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        return IntelligentSignalEngine()
    
    async def start(self):
        """Ø´Ø±ÙˆØ¹ Ù…ÙˆØªÙˆØ± ØªØ­Ù„ÛŒÙ„"""
        self.logger.info("ğŸš€ Starting Crypto Analysis Engine...")
        self.is_running = True
        
        # ØªÙ†Ø¸ÛŒÙ… handler Ø¨Ø±Ø§ÛŒ shutdown
        signal.signal(signal.SIGINT, self._shutdown_signal_handler)
        signal.signal(signal.SIGTERM, self._shutdown_signal_handler)
        
        try:
            await self.initialize()
            
            # Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ
            while self.is_running:
                try:
                    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ
                    analysis_results = await self.run_analysis_pipeline()
                    
                    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…
                    self.health_checker.record_successful_cycle()
                    
                    self.logger.info(f"ğŸ“ˆ Analysis cycle completed. Signals: {analysis_results['summary']['total_signals']}")
                    
                    # Ø®ÙˆØ§Ø¨ Ù‚Ø¨Ù„ Ø§Ø² Ø³ÛŒÚ©Ù„ Ø¨Ø¹Ø¯ÛŒ
                    await asyncio.sleep(self.config.get('analysis_interval', 300))  # 5 Ø¯Ù‚ÛŒÙ‚Ù‡
                    
                except Exception as e:
                    self.logger.error(f"âŒ Error in main loop: {e}")
                    self.health_checker.record_failed_cycle()
                    await asyncio.sleep(60)  # Ø®ÙˆØ§Ø¨ Ú©ÙˆØªØ§Ù‡ Ù‚Ø¨Ù„ Ø§Ø² ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯
                    
        except Exception as e:
            self.logger.error(f"âŒ Fatal error: {e}")
        finally:
            await self.shutdown()
    
    def _shutdown_signal_handler(self, signum, frame):
        """Handler Ø¨Ø±Ø§ÛŒ shutdown"""
        self.logger.info(f"ğŸ›‘ Received shutdown signal {signum}")
        self.is_running = False
    
    async def shutdown(self):
        """Ø®Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† ØªÙ…ÛŒØ² Ù…ÙˆØªÙˆØ±"""
        self.logger.info("ğŸ›‘ Shutting down Crypto Analysis Engine...")
        self.is_running = False
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        self.performance_tracker.save_summary()
        self.memory_monitor.save_usage_stats()
        
        self.logger.info("âœ… Crypto Analysis Engine shutdown complete")

    def get_system_status(self) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…"""
        return {
            'status': 'running' if self.is_running else 'stopped',
            'components_healthy': self.health_checker.get_system_status(),
            'performance_metrics': self.performance_tracker.get_summary(),
            'memory_usage': self.memory_monitor.get_usage_stats(),
            'timestamp': datetime.now().isoformat()
        }
