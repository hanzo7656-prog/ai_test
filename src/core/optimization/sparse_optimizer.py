# ğŸ“ src/core/optimization/sparse_optimizer.py

import torch
import torch.nn as nn
from typing import Dict

class SparseOptimizer:
    """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø² ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ù¾Ø§Ø±Ø³"""
    
    def __init__(self, sparsity_level: float = 0.9):
        self.sparsity_level = sparsity_level
    
    def apply_sparsity(self, model):
        """Ø§Ø¹Ù…Ø§Ù„ Ø§Ø³Ù¾Ø§Ø±Ø³ÛŒØªÛŒ Ø¨Ù‡ Ù…Ø¯Ù„"""
        for name, param in model.named_parameters():
            if 'weight' in name and param.dim() > 1:
                self._make_sparse(param)
    
    def _make_sparse(self, tensor):
        """ØªØ¨Ø¯ÛŒÙ„ ØªÙ†Ø³ÙˆØ± Ø¨Ù‡ Ø§Ø³Ù¾Ø§Ø±Ø³"""
        with torch.no_grad():
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³Ù¾Ø§Ø±Ø³ÛŒØªÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
            threshold = torch.quantile(
                torch.abs(tensor.flatten()), 
                self.sparsity_level
            )
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§Ø³Ú© Ø§Ø³Ù¾Ø§Ø±Ø³
            mask = torch.abs(tensor) > threshold
            tensor.data *= mask.float()
    
    def calculate_sparsity(self, model) -> Dict:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·Ø­ Ø§Ø³Ù¾Ø§Ø±Ø³ÛŒØªÛŒ Ù…Ø¯Ù„"""
        total_params = 0
        zero_params = 0
        
        for name, param in model.named_parameters():
            if 'weight' in name:
                total_params += param.numel()
                zero_params += (param == 0).sum().item()
        
        sparsity = zero_params / total_params if total_params > 0 else 0
        
        return {
            'total_parameters': total_params,
            'zero_parameters': zero_params,
            'sparsity_percentage': sparsity * 100,
            'effective_parameters': total_params - zero_params
        }
