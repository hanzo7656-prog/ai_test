# ๐ src/ai_ml/regime_classifier.py

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from typing import Dict, List, Tuple, Optional
import joblib
import os

class MarketRegimeClassifier:
    """ุทุจููโุจูุฏ ุฑฺูโูุง ุจุงุฒุงุฑ ุจุง Random Forest"""
    
    def __init__(self, model_path: str = "models/market_regime_classifier.pkl"):
        self.model_path = model_path
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.scaler = StandardScaler()
        self.is_trained = False
        
        # ุชุนุฑู ุฑฺูโูุง ุจุงุฒุงุฑ
        self.regimes = {
            0: 'BULL_NORMAL',      # ุฑููุฏ ุตุนูุฏ ูุฑูุงู
            1: 'BULL_ACCELERATING', # ุดุชุงุจ ุตุนูุฏ
            2: 'BEAR_NORMAL',      # ุฑููุฏ ูุฒูู ูุฑูุงู  
            3: 'BEAR_ACCELERATING', # ุดุชุงุจ ูุฒูู
            4: 'SIDEWAYS_LOW_VOL', # ุฑูุฌ ุจุง ููุณุงู ฺฉู
            5: 'SIDEWAYS_HIGH_VOL', # ุฑูุฌ ุจุง ููุณุงู ุจุงูุง
            6: 'VOLATILE_BREAKOUT' # ููุณุงู ุจุงูุง ุจุง ุดฺฉุณุช
        }
    
    def prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ุขูุงุฏูโุณุงุฒ ูฺฺฏโูุง ุจุฑุง ูุฏู"""
        features = pd.DataFrame(index=data.index)
        
        # ูฺฺฏโูุง ููุช
        features['returns_1d'] = data['close'].pct_change(1)
        features['returns_5d'] = data['close'].pct_change(5)
        features['returns_20d'] = data['close'].pct_change(20)
        
        # ููุณุงู
        features['volatility_5d'] = data['close'].pct_change().rolling(5).std()
        features['volatility_20d'] = data['close'].pct_change().rolling(20).std()
        
        # ุฑููุฏ
        features['ma_ratio_20_50'] = (
            data['close'].rolling(20).mean() / 
            data['close'].rolling(50).mean() - 1
        )
        features['price_vs_ma20'] = (
            data['close'] / data['close'].rolling(20).mean() - 1
        )
        
        # ุญุฌู
        if 'volume' in data.columns:
            features['volume_ratio'] = (
                data['volume'] / data['volume'].rolling(20).mean()
            )
        
        # ูุญุฏูุฏู ูุนุงููุงุช
        features['range_5d'] = (
            (data['high'].rolling(5).max() - data['low'].rolling(5).min()) / 
            data['close'].rolling(5).mean()
        )
        
        # ููููุชูู
        features['momentum_5d'] = data['close'] / data['close'].shift(5) - 1
        features['momentum_20d'] = data['close'] / data['close'].shift(20) - 1
        
        return features.dropna()
    
    def create_labels(self, data: pd.DataFrame, features: pd.DataFrame) -> pd.Series:
        """ุงุฌุงุฏ ูุจูโูุง ุฑฺู ุจุงุฒุงุฑ"""
        labels = pd.Series(index=features.index, dtype=int)
        
        returns_20d = data['close'].pct_change(20)
        volatility_20d = data['close'].pct_change().rolling(20).std()
        
        for i in range(len(features)):
            ret = returns_20d.iloc[i]
            vol = volatility_20d.iloc[i]
            
            if ret > 0.05 and vol < 0.02:
                labels.iloc[i] = 0  # BULL_NORMAL
            elif ret > 0.10 and vol > 0.03:
                labels.iloc[i] = 1  # BULL_ACCELERATING
            elif ret < -0.05 and vol < 0.02:
                labels.iloc[i] = 2  # BEAR_NORMAL
            elif ret < -0.10 and vol > 0.03:
                labels.iloc[i] = 3  # BEAR_ACCELERATING
            elif abs(ret) < 0.02 and vol < 0.015:
                labels.iloc[i] = 4  # SIDEWAYS_LOW_VOL
            elif abs(ret) < 0.03 and vol > 0.025:
                labels.iloc[i] = 5  # SIDEWAYS_HIGH_VOL
            else:
                labels.iloc[i] = 6  # VOLATILE_BREAKOUT
        
        return labels
    
    def train(self, data: pd.DataFrame) -> Dict:
        """ุขููุฒุด ูุฏู ุทุจููโุจูุฏ"""
        print("๐ Training Market Regime Classifier...")
        
        # ุขูุงุฏูโุณุงุฒ ูฺฺฏโูุง ู ูุจูโูุง
        features = self.prepare_features(data)
        labels = self.create_labels(data, features)
        
        if len(features) < 100:
            print("โ Insufficient data for training")
            return {}
        
        # ุชูุณู ุฏุงุฏู
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels, test_size=0.2, random_state=42, shuffle=False
        )
        
        # ูุฑูุงูโุณุงุฒ
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ุขููุฒุด ูุฏู
        self.model.fit(X_train_scaled, y_train)
        
        # ุงุฑุฒุงุจ ูุฏู
        train_score = self.model.score(X_train_scaled, y_train)
        test_score = self.model.score(X_test_scaled, y_test)
        
        self.is_trained = True
        
        # ุฐุฎุฑู ูุฏู
        os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
        joblib.dump({
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': features.columns.tolist()
        }, self.model_path)
        
        print(f"โ Model trained successfully")
        print(f"   Train Accuracy: {train_score:.3f}")
        print(f"   Test Accuracy: {test_score:.3f}")
        
        return {
            'train_accuracy': train_score,
            'test_accuracy': test_score,
            'training_samples': len(X_train),
            'feature_importance': dict(zip(
                features.columns, 
                self.model.feature_importances_
            ))
        }
    
    def predict_regime(self, data: pd.DataFrame) -> Dict:
        """ูพุดโุจู ุฑฺู ุจุงุฒุงุฑ ุจุฑุง ุฏุงุฏู ุฌุฏุฏ"""
        if not self.is_trained:
            # ุชูุงุด ุจุฑุง ููุฏ ูุฏู ุฐุฎุฑู ุดุฏู
            if not self.load_model():
                return {'regime': 'UNKNOWN', 'confidence': 0.0}
        
        # ุขูุงุฏูโุณุงุฒ ูฺฺฏโูุง
        features = self.prepare_features(data)
        if features.empty:
            return {'regime': 'UNKNOWN', 'confidence': 0.0}
        
        # ุงุณุชูุงุฏู ุงุฒ ุขุฎุฑู ุฏุงุฏู
        latest_features = features.iloc[-1:].values
        latest_features_scaled = self.scaler.transform(latest_features)
        
        # ูพุดโุจู
        prediction = self.model.predict(latest_features_scaled)[0]
        probabilities = self.model.predict_proba(latest_features_scaled)[0]
        
        confidence = probabilities[prediction]
        regime = self.regimes.get(prediction, 'UNKNOWN')
        
        return {
            'regime': regime,
            'confidence': confidence,
            'all_probabilities': {
                self.regimes[i]: prob for i, prob in enumerate(probabilities)
            },
            'features_used': features.columns.tolist()
        }
    
    def load_model(self) -> bool:
        """ููุฏ ูุฏู ุฐุฎุฑู ุดุฏู"""
        try:
            if os.path.exists(self.model_path):
                saved_data = joblib.load(self.model_path)
                self.model = saved_data['model']
                self.scaler = saved_data['scaler']
                self.is_trained = True
                print("โ Model loaded successfully")
                return True
        except Exception as e:
            print(f"โ Error loading model: {e}")
        
        return False
    
    def get_regime_description(self, regime: str) -> str:
        """ุชูุถุญุงุช ูุฑ ุฑฺู ุจุงุฒุงุฑ"""
        descriptions = {
            'BULL_NORMAL': 'ุฑููุฏ ุตุนูุฏ ูพุงุฏุงุฑ ุจุง ููุณุงู ูุชูุณุท - ููุงุณุจ ุจุฑุง ูููุนุชโูุง ุฎุฑุฏ',
            'BULL_ACCELERATING': 'ุดุชุงุจ ุตุนูุฏ ุจุง ููุณุงู ุจุงูุง - ูุฑุตุชโูุง ุณูุฏ ุณุฑุน ุงูุง ูพุฑุฑุณฺฉ',
            'BEAR_NORMAL': 'ุฑููุฏ ูุฒูู ูพุงุฏุงุฑ - ููุงุณุจ ุจุฑุง ูููุนุชโูุง ูุฑูุด',
            'BEAR_ACCELERATING': 'ุดุชุงุจ ูุฒูู ุจุง ููุณุงู ุจุงูุง - ุฑุณฺฉ ุฒุงุฏุ ูุงุฒ ุจู ูุฏุฑุช ุฏูู',
            'SIDEWAYS_LOW_VOL': 'ุจุงุฒุงุฑ ุฑูุฌ ุจุง ููุณุงู ฺฉู - ููุงุณุจ ุจุฑุง ุงุณุชุฑุงุชฺโูุง ุฑูุฌ',
            'SIDEWAYS_HIGH_VOL': 'ุจุงุฒุงุฑ ุฑูุฌ ุจุง ููุณุงู ุจุงูุง - ูุฑุตุช ุจุฑุง ููุณุงูโฺฏุฑ',
            'VOLATILE_BREAKOUT': 'ููุณุงู ุจุงูุง ุจุง ูพุชุงูุณู ุดฺฉุณุช - ูุงุฒ ุจู ุงุญุชุงุท ุจุงูุง'
        }
        return descriptions.get(regime, 'ุชูุถุญ ุฏุฑ ุฏุณุชุฑุณ ูุณุช')
