# self_learning/autonomous_trainer.py
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import torch
import torch.nn as nn
import numpy as np

logger = logging.getLogger(__name__)

class AutonomousTrainer:
    """Ø³ÛŒØ³ØªÙ… Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    
    def __init__(self, model_manager, data_integrator):
        self.model_manager = model_manager
        self.data_integrator = data_integrator
        self.training_schedule = {}
        self.training_history = []
        
        # Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ú©Ø´ Ù…ÙˆØ¬ÙˆØ¯
        from debug_system.storage.cache_debugger import cache_debugger
        self.cache_manager = cache_debugger
        
        logger.info("ðŸŽ“ Autonomous Trainer initialized")

    async def continuous_training_loop(self):
        """Ø­Ù„Ù‚Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù¾ÛŒÙˆØ³ØªÙ‡"""
        logger.info("ðŸ”„ Starting continuous training loop...")
        
        while True:
            try:
                # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´
                training_needed = await self._check_training_need()
                
                if training_needed:
                    logger.info("ðŸ“š Training needed, starting training session...")
                    await self._conduct_training_session()
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯
                await asyncio.sleep(300)  # Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†
                
            except Exception as e:
                logger.error(f"âŒ Error in training loop: {e}")
                await asyncio.sleep(60)  # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ 1 Ø¯Ù‚ÛŒÙ‚Ù‡ ØµØ¨Ø± Ú©Ù†

    async def _check_training_need(self) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§
            performance_report = self._get_performance_report()
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            data_report = await self.data_integrator.collect_raw_data()
            
            # Ø´Ø±Ø§ÛŒØ· Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´:
            # 1. Ú©Ø§Ù‡Ø´ performance
            # 2. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ú©Ø§ÙÛŒ
            # 3. Ø²Ù…Ø§Ù† Ø§Ø² Ø¢Ù…ÙˆØ²Ø´ Ú¯Ø°Ø´ØªÙ‡ Ú¯Ø°Ø´ØªÙ‡ Ú©Ø§ÙÛŒ
            needs_training = (
                self._has_performance_degradation(performance_report) and
                data_report['metadata']['successful_sources'] >= 2 and
                self._sufficient_time_since_last_training()
            )
            
            return needs_training
            
        except Exception as e:
            logger.error(f"âŒ Error checking training need: {e}")
            return False

    def _get_performance_report(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø² performance tracker"""
        try:
            # Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ performance tracker Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø±Ù‚Ø±Ø§Ø± Ú©Ù†ÛŒØ¯
            # Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ ÛŒÚ© Ø³Ø§Ø®ØªØ§Ø± mock Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
            return {
                'models': {
                    'technical_analyzer': {
                        'success_rate': 0.92,
                        'avg_confidence': 0.85,
                        'trend': 'stable'
                    }
                }
            }
        except Exception as e:
            logger.error(f"âŒ Error getting performance report: {e}")
            return {'models': {}}

    def _has_performance_degradation(self, performance_report: Dict[str, Any]) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø§Ù‡Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø·Ù‚ ØªØ´Ø®ÛŒØµ Ú©Ø§Ù‡Ø´ performance
        for model_name, metrics in performance_report.get('models', {}).items():
            success_rate = metrics.get('success_rate', 1.0)
            avg_confidence = metrics.get('avg_confidence', 1.0)
            
            if success_rate < 0.9 or avg_confidence < 0.8:
                return True
                
        return False

    def _sufficient_time_since_last_training(self) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø²Ù…Ø§Ù† Ú©Ø§ÙÛŒ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯"""
        if not self.training_history:
            return True
            
        last_training = max([t['timestamp'] for t in self.training_history])
        last_training_time = datetime.fromisoformat(last_training)
        time_since_training = datetime.now() - last_training_time
        
        return time_since_training > timedelta(hours=4)  # Ø­Ø¯Ø§Ù‚Ù„ 4 Ø³Ø§Ø¹Øª ÙØ§ØµÙ„Ù‡

    async def _conduct_training_session(self):
        """Ø§Ù†Ø¬Ø§Ù… ÛŒÚ© Ø¬Ù„Ø³Ù‡ Ø¢Ù…ÙˆØ²Ø´"""
        training_session = {
            'session_id': f"train_{datetime.now().strftime('%Y%m%d_%H%M')}",
            'timestamp': datetime.now().isoformat(),
            'models_trained': [],
            'results': {},
            'status': 'started'
        }
        
        try:
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
            training_data = await self.data_integrator.get_structured_training_data()
            
            if not training_data['training_ready']:
                logger.warning("âš ï¸ Training data not ready, skipping session")
                training_session['status'] = 'skipped'
                training_session['reason'] = 'insufficient_data'
                return
            
            # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            for model_name in self.model_manager.active_models.keys():
                try:
                    result = await self._train_single_model(model_name, training_data)
                    training_session['models_trained'].append(model_name)
                    training_session['results'][model_name] = result
                    
                except Exception as e:
                    logger.error(f"âŒ Error training {model_name}: {e}")
                    training_session['results'][model_name] = {'error': str(e)}
            
            training_session['status'] = 'completed'
            training_session['completion_time'] = datetime.now().isoformat()
            
            logger.info(f"âœ… Training session completed: {len(training_session['models_trained'])} models trained")
            
        except Exception as e:
            logger.error(f"âŒ Training session failed: {e}")
            training_session['status'] = 'failed'
            training_session['error'] = str(e)
        
        finally:
            # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¢Ù…ÙˆØ²Ø´
            self.training_history.append(training_session)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
            self.cache_manager.set_data(
                "utb", 
                f"training_session:{training_session['session_id']}", 
                training_session, 
                expire=86400
            )

    async def _train_single_model(self, model_name: str, training_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¢Ù…ÙˆØ²Ø´ ÛŒÚ© Ù…Ø¯Ù„ Ø®Ø§Øµ"""
        training_result = {
            'model': model_name,
            'timestamp': datetime.now().isoformat(),
            'training_data_quality': training_data['statistics']['data_quality'],
            'samples_used': training_data['statistics']['total_samples'],
            'improvement_metrics': {}
        }
        
        try:
            # Ø§ÛŒÙ†Ø¬Ø§ Ù…Ù†Ø·Ù‚ Ø¢Ù…ÙˆØ²Ø´ Ø®Ø§Øµ Ù‡Ø± Ù…Ø¯Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            # Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ØŒ ÛŒÚ© Ø¢Ù…ÙˆØ²Ø´ Ø³Ø§Ø¯Ù‡ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            
            if model_name == "technical_analyzer":
                result = await self._train_technical_analyzer(training_data)
                training_result.update(result)
            else:
                training_result['status'] = 'skipped'
                training_result['reason'] = 'no_training_logic'
            
            return training_result
            
        except Exception as e:
            logger.error(f"âŒ Error in model training {model_name}: {e}")
            training_result['status'] = 'failed'
            training_result['error'] = str(e)
            return training_result

    async def _train_technical_analyzer(self, training_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¢Ù…ÙˆØ²Ø´ ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± ØªÚ©Ù†ÛŒÚ©Ø§Ù„"""
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¢Ù…ÙˆØ²Ø´
        await asyncio.sleep(2)  # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´
        
        return {
            'status': 'completed',
            'training_time': '2 seconds (simulated)',
            'improvement_metrics': {
                'accuracy_improvement': 0.02,
                'confidence_improvement': 0.03,
                'loss_reduction': 0.15
            },
            'new_metrics': {
                'accuracy': 0.94,
                'confidence': 0.88,
                'loss': 0.12
            }
        }

    def get_training_history(self, days: int = 7) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¢Ù…ÙˆØ²Ø´"""
        cutoff_time = datetime.now() - timedelta(days=days)
        
        return [
            session for session in self.training_history
            if datetime.fromisoformat(session['timestamp']) > cutoff_time
        ]

    def schedule_training(self, model_name: str, schedule: Dict[str, Any]):
        """Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø®Ø§Øµ"""
        self.training_schedule[model_name] = {
            'schedule': schedule,
            'last_trained': None,
            'next_training': self._calculate_next_training(schedule)
        }
        
        logger.info(f"ðŸ“… Training scheduled for {model_name}: {schedule}")

    def _calculate_next_training(self, schedule: Dict[str, Any]) -> datetime:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø¹Ø¯ÛŒ"""
        if schedule.get('interval') == 'daily':
            return datetime.now() + timedelta(days=1)
        elif schedule.get('interval') == 'weekly':
            return datetime.now() + timedelta(weeks=1)
        else:  # hourly
            return datetime.now() + timedelta(hours=schedule.get('hours', 4))

# Ù†Ù…ÙˆÙ†Ù‡ global
autonomous_trainer = None

def initialize_autonomous_trainer(model_manager, data_integrator):
    """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ autonomous trainer"""
    global autonomous_trainer
    autonomous_trainer = AutonomousTrainer(model_manager, data_integrator)
    return autonomous_trainer
