from fastapi import APIRouter, HTTPException, Query
from datetime import datetime
from typing import List, Optional, Dict, Any
import logging
from complete_coinstats_manager import coin_stats_manager

logger = logging.getLogger(__name__)

news_router = APIRouter(prefix="/api/news", tags=["News"])

@news_router.get("/all", summary="Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ")
async def get_news(
    limit: int = Query(50, ge=1, le=100, description="ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± (Û± ØªØ§ Û±Û°Û°)"),
    page: int = Query(1, ge=1, description="Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡")
):
    """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø² CoinStats API"""
    try:
        logger.info(f"ğŸ“° Fetching news - Limit: {limit}")
        
        raw_data = coin_stats_manager.get_news(limit=limit)
        
        if "error" in raw_data:
            logger.error(f"âŒ News API error: {raw_data['error']}")
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        news_items = raw_data.get('data', [])
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø§Ø¯Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        processed_news = []
        for news_item in news_items:
            processed_news.append({
                'id': news_item.get('id'),
                'title': news_item.get('title'),
                'description': news_item.get('description'),
                'url': news_item.get('url'),
                'source': news_item.get('source'),
                'published_at': news_item.get('published_at', news_item.get('publishedAt')),
                'image_url': news_item.get('imageUrl'),
                'tags': news_item.get('tags', []),
                'categories': news_item.get('categories', []),
                'last_updated': datetime.now().isoformat()
            })
        
        response = {
            'status': 'success',
            'data': processed_news,
            'meta': {
                'total': len(processed_news),
                'limit': limit,
                'page': page
            },
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… News fetched successfully - Total: {len(processed_news)}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸš¨ Unexpected error in news: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@news_router.get("/type/{news_type}", summary="Ø§Ø®Ø¨Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹")
async def get_news_by_type(
    news_type: str,
    limit: int = Query(10, ge=1, le=50, description="ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± (Û± ØªØ§ ÛµÛ°)")
):
    """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹"""
    try:
        # Ø§Ù†ÙˆØ§Ø¹ Ù…Ø¹ØªØ¨Ø±
        valid_types = ["latest", "trending", "featured", "breaking", "analysis", "handpicked"]
        if news_type not in valid_types:
            raise HTTPException(status_code=400, detail=f"Invalid news type. Valid types: {valid_types}")
        
        logger.info(f"ğŸ“° Fetching {news_type} news - Limit: {limit}")
        
        raw_data = coin_stats_manager.get_news_by_type(news_type, limit=limit)
        
        if "error" in raw_data:
            logger.error(f"âŒ {news_type} news API error: {raw_data['error']}")
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        news_items = raw_data.get('data', [])
        
        processed_news = []
        for news_item in news_items:
            processed_news.append({
                'id': news_item.get('id'),
                'title': news_item.get('title'),
                'description': news_item.get('description'),
                'url': news_item.get('url'),
                'source': news_item.get('source'),
                'published_at': news_item.get('published_at', news_item.get('publishedAt')),
                'image_url': news_item.get('imageUrl'),
                'type': news_type,
                'tags': news_item.get('tags', []),
                'last_updated': datetime.now().isoformat()
            })
        
        response = {
            'status': 'success',
            'data': processed_news,
            'meta': {
                'type': news_type,
                'total': len(processed_news),
                'limit': limit
            },
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… {news_type} news fetched successfully - Total: {len(processed_news)}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸš¨ Error in {news_type} news: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@news_router.get("/sources", summary="Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ")
async def get_news_sources():
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ"""
    try:
        logger.info("ğŸ“° Fetching news sources")
        
        raw_data = coin_stats_manager.get_news_sources()
        
        if "error" in raw_data:
            logger.error(f"âŒ News sources API error: {raw_data['error']}")
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        sources = raw_data.get('data', [])
        
        processed_sources = []
        for source in sources:
            processed_sources.append({
                'id': source.get('id'),
                'name': source.get('name'),
                'url': source.get('url'),
                'description': source.get('description'),
                'language': source.get('language', 'en'),
                'country': source.get('country'),
                'category': source.get('category', 'crypto'),
                'last_updated': datetime.now().isoformat()
            })
        
        response = {
            'status': 'success',
            'data': processed_sources,
            'meta': {
                'total': len(processed_sources)
            },
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… News sources fetched successfully - Total: {len(processed_sources)}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸš¨ Error in news sources: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@news_router.get("/detail/{news_id}", summary="Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø¨Ø±")
async def get_news_detail(news_id: str):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ ÛŒÚ© Ø®Ø¨Ø±"""
    try:
        logger.info(f"ğŸ“° Fetching news detail: {news_id}")
        
        raw_data = coin_stats_manager.get_news_detail(news_id)
        
        if "error" in raw_data:
            logger.error(f"âŒ News detail API error: {raw_data['error']}")
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        news_data = raw_data.get('data', {})
        
        processed_detail = {
            'id': news_data.get('id'),
            'title': news_data.get('title'),
            'content': news_data.get('content', news_data.get('description')),
            'url': news_data.get('url'),
            'source': news_data.get('source'),
            'author': news_data.get('author'),
            'published_at': news_data.get('published_at', news_data.get('publishedAt')),
            'image_url': news_data.get('imageUrl'),
            'tags': news_data.get('tags', []),
            'categories': news_data.get('categories', []),
            'last_updated': datetime.now().isoformat()
        }
        
        response = {
            'status': 'success',
            'data': processed_detail,
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… News detail fetched successfully: {news_id}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸš¨ Error in news detail {news_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@news_router.get("/raw/all", summary="Ø§Ø®Ø¨Ø§Ø± Ø®Ø§Ù…")
async def get_raw_news(
    limit: int = Query(50, ge=1, le=100, description="ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± (Û± ØªØ§ Û±Û°Û°)")
):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´"""
    try:
        logger.info(f"ğŸ“° Fetching raw news - Limit: {limit}")
        
        raw_data = coin_stats_manager.get_news(limit=limit)
        
        if "error" in raw_data:
            logger.error(f"âŒ Raw news API error: {raw_data['error']}")
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        response = {
            'status': 'success',
            'data': raw_data.get('data', []),
            'meta': {
                'total': len(raw_data.get('data', [])),
                'limit': limit,
                'data_type': 'raw'
            },
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… Raw news fetched successfully - Total: {len(raw_data.get('data', []))}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸš¨ Error in raw news: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@news_router.get("/raw/type/{news_type}", summary="Ø§Ø®Ø¨Ø§Ø± Ø®Ø§Ù… Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹")
async def get_raw_news_by_type(
    news_type: str,
    limit: int = Query(10, ge=1, le=50, description="ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± (Û± ØªØ§ ÛµÛ°)")
):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´"""
    try:
        valid_types = ["latest", "trending", "featured", "breaking", "analysis", "handpicked"]
        if news_type not in valid_types:
            raise HTTPException(status_code=400, detail=f"Invalid news type. Valid types: {valid_types}")
        
        logger.info(f"ğŸ“° Fetching raw {news_type} news - Limit: {limit}")
        
        raw_data = coin_stats_manager.get_news_by_type(news_type, limit=limit)
        
        if "error" in raw_data:
            logger.error(f"âŒ Raw {news_type} news API error: {raw_data['error']}")
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        response = {
            'status': 'success',
            'data': raw_data.get('data', []),
            'meta': {
                'type': news_type,
                'total': len(raw_data.get('data', [])),
                'limit': limit,
                'data_type': 'raw'
            },
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… Raw {news_type} news fetched successfully - Total: {len(raw_data.get('data', []))}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸš¨ Error in raw {news_type} news: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@news_router.get("/debug/{news_type}", summary="Ø¯ÛŒØ¨Ø§Ú¯ Ø§Ø®Ø¨Ø§Ø±")
async def debug_news_data(news_type: str = "handpicked"):
    """Ø§Ø¨Ø²Ø§Ø± Ø¯ÛŒØ¨Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ Ø§Ø®Ø¨Ø§Ø±"""
    try:
        raw_data = coin_stats_manager.get_news_by_type(news_type)
        
        # Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
        sample_data = raw_data.get('data', [])
        sample_item = sample_data[0] if sample_data else {}
        
        return {
            'status': 'debug',
            'endpoint': f"news/type/{news_type}",
            'manager_response_keys': list(raw_data.keys()) if isinstance(raw_data, dict) else 'not_dict',
            'data_count': len(sample_data),
            'sample_item_structure': {
                'keys': list(sample_item.keys()) if sample_item else 'no_data',
                'sample_values': {k: type(v).__name__ for k, v in list(sample_item.items())[:5]} if sample_item else 'no_data'
            },
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }
