from fastapi import APIRouter, HTTPException, Query
from datetime import datetime
from typing import List, Optional, Dict, Any
import logging
from complete_coinstats_manager import coin_stats_manager

logger = logging.getLogger(__name__)

# ğŸ”§ Ø§ØµÙ„Ø§Ø­ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª
try:
    from debug_system.storage.cache_decorators import cache_raw_news_with_archive
    logger.info("âœ… Cache System: Archive Enabled")
except ImportError as e:
    logger.error(f"âŒ Cache system unavailable: {e}")
    # Fallback Ù†Ù‡Ø§ÛŒÛŒ
    def cache_raw_news_with_archive():
        def decorator(func):
            return func
        return decorator

raw_news_router = APIRouter(prefix="/api/raw/news", tags=["Raw News"])

@raw_news_router.get("/all", summary="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ")
@cache_raw_news_with_archive()
async def get_raw_news(limit: int = Query(50, ge=1, le=100)):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø² CoinStats API"""
    try:
        raw_data = coin_stats_manager.get_news()
        
        if "error" in raw_data:
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        news_items = raw_data.get('data', [])
        limited_data = news_items[:limit]
        
        return {
            'status': 'success',
            'data_type': 'raw_news_feed',
            'source': 'coinstats_api',
            'api_version': 'v1',
            'timestamp': datetime.now().isoformat(),
            'limit_applied': limit,
            'total_available': len(news_items),
            'data': {
                'result': limited_data,
                'meta': raw_data.get('meta', {})
            }
        }
        
    except Exception as e:
        logger.error(f"Error in raw news: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@raw_news_router.get("/type/{news_type}", summary="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡")
@cache_raw_news_with_archive()
async def get_raw_news_by_type(
    news_type: str,
    limit: int = Query(10, ge=1, le=50)
):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ"""
    try:
        # Ø§Ù†ÙˆØ§Ø¹ Ù…Ø¹ØªØ¨Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø³ØªÙ†Ø¯Ø§Øª
        valid_types = ["handpicked", "trending", "latest", "bullish", "bearish"]
        if news_type not in valid_types:
            raise HTTPException(status_code=400, detail=f"Invalid news type. Valid types: {valid_types}")
        
        raw_data = coin_stats_manager.get_news_by_type(news_type, limit=limit)
        
        if "error" in raw_data:
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        news_items = raw_data.get('data', [])
        limited_data = news_items[:limit]
        
        return {
            'status': 'success',
            'data_type': 'raw_categorized_news',
            'source': 'coinstats_api',
            'api_version': 'v1',
            'news_type': news_type,
            'timestamp': datetime.now().isoformat(),
            'limit_applied': limit,
            'total_available': len(news_items),
            'data': {
                'result': limited_data,
                'meta': raw_data.get('meta', {})
            }
        }
        
    except Exception as e:
        logger.error(f"Error in raw news by type {news_type}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@raw_news_router.get("/sources", summary="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ")
@cache_raw_news_with_archive()
async def get_raw_news_sources():
    """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ø§Ø² CoinStats API"""
    try:
        raw_data = coin_stats_manager.get_news_sources()
        
        if "error" in raw_data:
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² manager Ù…ÛŒâ€ŒØ¢ÛŒÙ†Ø¯
        sources_list = raw_data.get('data', [])
        
        return {
            'status': 'success',
            'data_type': 'raw_news_sources',
            'source': 'coinstats_api',
            'api_version': 'v1',
            'timestamp': datetime.now().isoformat(),
            'data': {
                'sources': sources_list,
                'total_count': len(sources_list)
            }
        }
        
    except Exception as e:
        logger.error(f"Error in raw news sources: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@raw_news_router.get("/detail/{news_id}", summary="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø¨Ø±")
@cache_raw_news_with_archive()
async def get_raw_news_detail(news_id: str):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ ÛŒÚ© Ø®Ø¨Ø±"""
    try:
        raw_data = coin_stats_manager.get_news_detail(news_id)
        
        if "error" in raw_data:
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        return {
            'status': 'success',
            'data_type': 'raw_news_detail',
            'source': 'coinstats_api',
            'api_version': 'v1',
            'news_id': news_id,
            'timestamp': datetime.now().isoformat(),
            'data': raw_data
        }
        
    except Exception as e:
        logger.error(f"Error in raw news detail {news_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@raw_news_router.get("/sentiment-analysis", summary="ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§Ø®Ø¨Ø§Ø±")
@cache_raw_news_with_archive()
async def get_news_sentiment_analysis(
    limit: int = Query(20, ge=1, le=50),
    news_type: str = Query(None, description="Ù†ÙˆØ¹ Ø®Ø¨Ø±: handpicked, trending, latest, bullish, bearish")
):
    """ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ"""
    try:
        if news_type:
            raw_data = coin_stats_manager.get_news_by_type(news_type)
        else:
            raw_data = coin_stats_manager.get_news()
        
        if "error" in raw_data:
            raise HTTPException(status_code=500, detail=raw_data["error"])
        
        news_items = raw_data.get('data', [])[:limit]
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø³Ø§Ø¯Ù‡
        sentiment_analysis = _perform_sentiment_analysis(news_items)
        
        return {
            'status': 'success',
            'data_type': 'news_sentiment_analysis',
            'source': 'coinstats_api',
            'api_version': 'v1',
            'timestamp': datetime.now().isoformat(),
            'parameters': {
                'limit': limit,
                'news_type': news_type or 'all'
            },
            'sentiment_analysis': sentiment_analysis,
            'sample_data': news_items[:5]
        }
        
    except Exception as e:
        logger.error(f"Error in news sentiment analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@raw_news_router.get("/metadata", summary="Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ø§Ø®Ø¨Ø§Ø± Ùˆ Ù…Ù†Ø§Ø¨Ø¹")
@cache_raw_news_with_archive()
async def get_news_metadata():
    """Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø®Ø¨Ø§Ø± Ùˆ Ù…Ù†Ø§Ø¨Ø¹"""
    try:
        return {
            'status': 'success',
            'data_type': 'news_metadata',
            'source': 'coinstats_api',
            'api_version': 'v1',
            'timestamp': datetime.now().isoformat(),
            'available_endpoints': [
                {
                    'endpoint': '/api/raw/news/all',
                    'description': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ',
                    'parameters': ['limit'],
                    'use_case': 'ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§Ø²Ø§Ø±'
                },
                {
                    'endpoint': '/api/raw/news/type/{news_type}',
                    'description': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡',
                    'parameters': ['news_type', 'limit'],
                    'news_types': ['handpicked', 'trending', 'latest', 'bullish', 'bearish']
                },
                {
                    'endpoint': '/api/raw/news/sources',
                    'description': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ',
                    'parameters': [],
                    'use_case': 'ØªØ­Ù„ÛŒÙ„ Ø§Ø¹ØªØ¨Ø§Ø± Ùˆ ØªÙˆØ²ÛŒØ¹ Ù…Ù†Ø§Ø¨Ø¹'
                },
                {
                    'endpoint': '/api/raw/news/detail/{news_id}',
                    'description': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ Ø®Ø¨Ø±',
                    'parameters': ['news_id'],
                    'use_case': 'ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù‚ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø®Ø¨Ø±'
                },
                {
                    'endpoint': '/api/raw/news/sentiment-analysis',
                    'description': 'ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§Ø®Ø¨Ø§Ø±',
                    'parameters': ['limit', 'news_type'],
                    'use_case': 'Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª'
                }
            ],
            'news_categories': {
                'handpicked': 'Ø§Ø®Ø¨Ø§Ø± Ù…Ù†ØªØ®Ø¨ Ùˆ Ù…Ù‡Ù…',
                'trending': 'Ø§Ø®Ø¨Ø§Ø± Ø¯Ø§Øº Ùˆ Ù¾Ø±Ø·Ø±ÙØ¯Ø§Ø±',
                'latest': 'Ø¢Ø®Ø±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø±',
                'bullish': 'Ø§Ø®Ø¨Ø§Ø± Ù…Ø«Ø¨Øª Ùˆ ØµØ¹ÙˆØ¯ÛŒ',
                'bearish': 'Ø§Ø®Ø¨Ø§Ø± Ù…Ù†ÙÛŒ Ùˆ Ù†Ø²ÙˆÙ„ÛŒ'
            },
            'data_structure': {
                'news_item': {
                    'id': 'Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§ÛŒ Ø®Ø¨Ø±',
                    'title': 'Ø¹Ù†ÙˆØ§Ù† Ø®Ø¨Ø±',
                    'description': 'Ø®Ù„Ø§ØµÙ‡ Ø®Ø¨Ø±',
                    'url': 'Ù„ÛŒÙ†Ú© Ù…Ù†Ø¨Ø¹ Ø§ØµÙ„ÛŒ',
                    'source': 'Ù…Ù†Ø¨Ø¹ Ø®Ø¨Ø±',
                    'publishedAt': 'Ø²Ù…Ø§Ù† Ø§Ù†ØªØ´Ø§Ø±',
                    'tags': 'ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ',
                    'content': 'Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ (Ø¯Ø± Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø¨Ø±)'
                },
                'news_source': {
                    'sourcename': 'Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹',
                    'weburl': 'Ø¢Ø¯Ø±Ø³ ÙˆØ¨Ø³Ø§ÛŒØª',
                    'feedurl': 'Ø¢Ø¯Ø±Ø³ ÙÛŒØ¯ RSS',
                    'sourceImg': 'Ø¢Ø¯Ø±Ø³ Ù„ÙˆÚ¯Ùˆ'
                }
            }
        }
        
    except Exception as e:
        logger.error(f"Error in news metadata: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@raw_news_router.get("/debug/simple", summary="Ø¯ÛŒØ¨Ø§Ú¯ Ø³Ø§Ø¯Ù‡ Ù…Ø¯ÛŒØ±")
@cache_raw_news_with_archive()
async def debug_simple():
    """Ø¯ÛŒØ¨Ø§Ú¯ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ manager"""
    try:
        # ØªØ³Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´
        test_data = coin_stats_manager.get_news_sources()
        
        return {
            'status': 'debug',
            'timestamp': datetime.now().isoformat(),
            'data_type': type(test_data).__name__,
            'is_list': isinstance(test_data, list),
            'is_dict': isinstance(test_data, dict),
            'length': len(test_data) if hasattr(test_data, '__len__') else 'no_length',
            'raw_preview': str(test_data)[:500] if test_data else 'empty'
        }
    except Exception as e:
        return {
            'status': 'error',
            'error_type': type(e).__name__,
            'error_message': str(e),
            'timestamp': datetime.now().isoformat()
        }

# ============================ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ============================

def _perform_sentiment_analysis(news_items: List[Dict]) -> Dict[str, Any]:
    """Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø³Ø§Ø¯Ù‡ Ø±ÙˆÛŒ Ø§Ø®Ø¨Ø§Ø±"""
    if not news_items:
        return {'analysis': 'no_news_data_available'}
    
    sentiment_results = []
    
    for news in news_items:
        sentiment = _analyze_basic_sentiment(news)
        sentiment_results.append({
            'news_id': news.get('id'),
            'title': news.get('title'),
            'sentiment': sentiment
        })
    
    # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª
    sentiment_counts = {
        'positive': 0,
        'negative': 0,
        'neutral': 0
    }
    
    for result in sentiment_results:
        sentiment_counts[result['sentiment']] += 1
    
    return {
        'total_analyzed': len(news_items),
        'sentiment_distribution': sentiment_counts,
        'dominant_sentiment': max(sentiment_counts, key=sentiment_counts.get),
        'detailed_results': sentiment_results[:5]
    }

def _analyze_basic_sentiment(news: Dict) -> str:
    """ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù¾Ø§ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
    text = (news.get('title', '') + ' ' + news.get('description', '')).lower()
    
    positive_words = ['bullish', 'surge', 'rally', 'gain', 'positive', 'growth', 'up', 'rise', 'profit']
    negative_words = ['bearish', 'drop', 'crash', 'loss', 'negative', 'decline', 'down', 'fall', 'warning']
    
    positive_count = sum(1 for word in positive_words if word in text)
    negative_count = sum(1 for word in negative_words if word in text)
    
    if positive_count > negative_count:
        return 'positive'
    elif negative_count > positive_count:
        return 'negative'
    else:
        return 'neutral'
