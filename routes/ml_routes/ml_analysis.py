# routes/ml_routes/ml_analysis.py
from fastapi import APIRouter, HTTPException, Depends
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging

from ml_core import ml_model_manager, ml_health_monitor, data_integrator
from data_pipeline import feature_engineer, data_validator

logger = logging.getLogger(__name__)

ml_analysis_router = APIRouter(prefix="/api/ml", tags=["ML Analysis"])

@ml_analysis_router.get("/health")
async def get_ml_health():
    """Ø¯Ø±ÛŒØ§ÙØª Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    try:
        health_report = ml_health_monitor.get_system_health()
        return {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "data": health_report
        }
    except Exception as e:
        logger.error(f"âŒ Error getting ML health: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@ml_analysis_router.get("/models")
async def get_models_list():
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„"""
    try:
        models_info = {}
        for model_name, model_info in ml_model_manager.active_models.items():
            models_info[model_name] = {
                "version": model_info['version'],
                "created_at": model_info['created_at'].isoformat(),
                "last_used": model_info['last_used'].isoformat(),
                "parameters": model_info['model'].config.total_neurons if hasattr(model_info['model'], 'config') else 'unknown'
            }
        
        return {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "total_models": len(models_info),
                "models": models_info
            }
        }
    except Exception as e:
        logger.error(f"âŒ Error getting models list: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@ml_analysis_router.post("/analyze/market")
async def analyze_market_data():
    """Ø¢Ù†Ø§Ù„ÛŒØ² Ø¬Ø§Ù…Ø¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±"""
    try:
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…
        logger.info("ðŸ” Starting comprehensive market analysis...")
        
        raw_data = await data_integrator.collect_raw_data()
        
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        validation_report = data_validator.validate_data_quality(raw_data)
        
        if validation_report['overall_quality'] == 'poor':
            logger.warning("âš ï¸ Poor data quality, analysis may be limited")
        
        # Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        engineered_features = feature_engineer.engineer_market_features(raw_data)
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
        analysis_results = {}
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…Ø¯Ù„ ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± ØªÚ©Ù†ÛŒÚ©Ø§Ù„
        if 'technical_analyzer' in ml_model_manager.active_models:
            try:
                # ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
                model_input = await _prepare_model_input(engineered_features)
                technical_analysis = await ml_model_manager.predict('technical_analyzer', model_input)
                analysis_results['technical_analysis'] = technical_analysis
            except Exception as e:
                logger.error(f"âŒ Technical analysis failed: {e}")
                analysis_results['technical_analysis'] = {'error': str(e)}
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
        final_report = {
            "timestamp": datetime.now().isoformat(),
            "analysis_id": f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "data_quality": validation_report['overall_quality'],
            "feature_engineering": {
                "total_features": engineered_features.get('feature_metadata', {}).get('total_features', 0),
                "feature_quality": engineered_features.get('feature_metadata', {}).get('feature_quality', 'unknown')
            },
            "analysis_results": analysis_results,
            "raw_data_summary": {
                "sources_collected": raw_data['metadata']['successful_sources'],
                "total_sources": raw_data['metadata']['total_sources']
            }
        }
        
        logger.info(f"âœ… Market analysis completed: {final_report['analysis_id']}")
        
        return {
            "status": "success",
            "data": final_report
        }
        
    except Exception as e:
        logger.error(f"âŒ Error in market analysis: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@ml_analysis_router.get("/performance/metrics")
async def get_performance_metrics(model_name: Optional[str] = None, time_window: str = "24h"):
    """Ø¯Ø±ÛŒØ§ÙØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
    try:
        from ml_core import performance_tracker
        
        if model_name:
            # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ù…Ø¯Ù„ Ø®Ø§Øµ
            if model_name not in ml_model_manager.active_models:
                raise HTTPException(status_code=404, detail=f"Model {model_name} not found")
            
            performance_data = performance_tracker.get_model_performance(model_name, time_window)
        else:
            # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
            performance_data = performance_tracker.get_comparative_analysis()
        
        return {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "data": performance_data
        }
        
    except Exception as e:
        logger.error(f"âŒ Error getting performance metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@ml_analysis_router.get("/data/quality")
async def get_data_quality_report():
    """Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ Ú©ÛŒÙÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
    try:
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ
        raw_data = await data_integrator.collect_raw_data()
        validation_report = data_validator.validate_data_quality(raw_data)
        
        # Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ú©ÛŒÙÛŒØª
        quality_trends = data_validator.get_data_quality_trends()
        
        return {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "current_quality": validation_report,
                "quality_trends": quality_trends,
                "validation_history": data_validator.get_validation_history(24)
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Error getting data quality report: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@ml_analysis_router.get("/features/engineered")
async def get_engineered_features():
    """Ø¯Ø±ÛŒØ§ÙØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø´Ø¯Ù‡ Ø¢Ø®Ø±"""
    try:
        from debug_system.storage.cache_debugger import cache_debugger
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ú©Ø´
        features = cache_debugger.get_data("utb", "engineered_features:latest")
        
        if not features:
            # Ø§Ú¯Ø± Ø¯Ø± Ú©Ø´ Ù†Ø¨ÙˆØ¯ØŒ Ø¬Ø¯ÛŒØ¯ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
            raw_data = await data_integrator.collect_raw_data()
            features = feature_engineer.engineer_market_features(raw_data)
        
        return {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "data": features
        }
        
    except Exception as e:
        logger.error(f"âŒ Error getting engineered features: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@ml_analysis_router.get("/alerts/active")
async def get_active_alerts():
    """Ø¯Ø±ÛŒØ§ÙØª Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ø³ÛŒØ³ØªÙ…"""
    try:
        from ml_core import performance_tracker
        
        alerts = performance_tracker.get_active_alerts()
        
        return {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "total_active_alerts": len(alerts),
                "alerts": alerts
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Error getting active alerts: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def _prepare_model_input(engineered_features: Dict[str, Any]):
    """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø¯Ù„ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø´Ø¯Ù‡"""
    # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ØªØ§Ù†Ø³ÙˆØ± ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
    
    import torch
    import numpy as np
    
    try:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        numeric_values = []
        
        def extract_numbers(data, prefix=""):
            if isinstance(data, dict):
                for key, value in data.items():
                    if isinstance(value, (int, float)):
                        numeric_values.append(value)
                    elif isinstance(value, dict):
                        extract_numbers(value, f"{prefix}{key}.")
                    elif isinstance(value, list) and all(isinstance(x, (int, float)) for x in value[:5]):
                        numeric_values.extend(value[:5])
        
        extract_numbers(engineered_features)
        
        if numeric_values:
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØªØ§Ù†Ø³ÙˆØ±
            values_array = np.array(numeric_values)
            if len(values_array) > 100:  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
                values_array = values_array[:100]
            elif len(values_array) < 100:  # padding Ø§Ú¯Ø± Ú©Ù… Ø¨ÙˆØ¯
                values_array = np.pad(values_array, (0, 100 - len(values_array)), 'constant')
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø´Ú©Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ù…Ø¯Ù„ (batch_size, sequence_length, features)
            input_tensor = torch.FloatTensor(values_array).unsqueeze(0).unsqueeze(0)
            return input_tensor
        else:
            raise ValueError("No numeric features found for model input")
            
    except Exception as e:
        logger.error(f"âŒ Error preparing model input: {e}")
        raise
