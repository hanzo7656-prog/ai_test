# ai_analysis_routes.py - Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
from fastapi import APIRouter, HTTPException, Query
from typing import List, Dict, Any, Optional
import json
import os
import time
from datetime import datetime
import logging
from pydantic import BaseModel

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø¯ÛŒØ±Ø§Ù†
from complete_coinstats_manager import coin_stats_manager
from lbank_websocket import get_websocket_manager
from debug_manager import debug_endpoint, debug_manager

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/ai", tags=["AI Analysis"])

# ==================== Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ trading_ai ====================

try:
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ÙˆØªÙˆØ± ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙˆØ§Ù‚Ø¹ÛŒ Ø´Ù…Ø§
    from trading_ai.advanced_technical_engine import technical_engine
    logger.info("âœ… Advanced Technical Engine loaded from trading_ai")
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø³Ù¾Ø§Ø±Ø³ ÙˆØ§Ù‚Ø¹ÛŒ Ø´Ù…Ø§
    from trading_ai.sparse_technical_analyzer import SparseTechnicalNetwork, SparseConfig
    logger.info("âœ… Sparse Technical Network loaded from trading_ai")
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒØªØ±ÛŒÙ†Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø´Ù…Ø§
    from trading_ai.model_trainer import model_trainer
    logger.info("âœ… Model Trainer loaded from trading_ai")
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² database manager Ø¬Ø¯ÛŒØ¯
    from database_manager import trading_db
    logger.info("âœ… Database Manager loaded")
    
except ImportError as e:
    logger.error(f"âŒ Error loading trading_ai modules: {e}")
    # Fallback Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªÙ†Ø¯
    technical_engine = None
    model_trainer = None
    trading_db = None

# ==================== Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ====================

class RealTradingSignalPredictor:
    """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³Ù¾Ø§Ø±Ø³"""
    
    def __init__(self):
        self.config = SparseConfig()
        self.model = SparseTechnicalNetwork(self.config)
        self.is_trained = False
        
    def train_model(self, symbols: List[str]):
        """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§"""
        try:
            if not model_trainer:
                logger.error("âŒ Model trainer not available")
                return False
                
            logger.info(f"ðŸ‹ï¸ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø§Ø³Ù¾Ø§Ø±Ø³ Ø±ÙˆÛŒ {len(symbols)} Ù†Ù…Ø§Ø¯...")
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒØªØ±ÛŒÙ†Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø´Ù…Ø§
            results = model_trainer.train_technical_analysis(symbols, epochs=50)
            
            if results and results.get('final_accuracy', 0) > 0.6:
                self.is_trained = True
                self.model = model_trainer.model
                logger.info(f"âœ… Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ - Ø¯Ù‚Øª: {results['final_accuracy']:.3f}")
                return True
            else:
                logger.warning("âš ï¸ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ù‚Øª Ù¾Ø§ÛŒÛŒÙ† ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„: {e}")
            return False
    
    def get_ai_prediction(self, symbol: str, data: Dict) -> Dict[str, Any]:
        """Ù…ØªØ¯ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ - Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…ØªØ¯ Ù…ÙÙ‚ÙˆØ¯"""
        return self.predict_signals({
            'price_data': {
                'historical_prices': data.get('prices', []),
                'volume_data': data.get('volumes', [])
            },
            'technical_indicators': data.get('technical_indicators', {})
        })
    
    def predict_signals(self, market_data: Dict) -> Dict[str, Any]:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³Ù¾Ø§Ø±Ø³"""
        try:
            if not self.is_trained:
                return {
                    "signals": {
                        "primary_signal": "HOLD",
                        "signal_confidence": 0.3,
                        "model_confidence": 0.3,
                        "all_probabilities": {"BUY": 0.33, "SELL": 0.33, "HOLD": 0.34},
                        "error": "Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù†Ø¯ÛŒØ¯Ù‡ Ø§Ø³Øª"
                    }
                }
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø§Ø³Ù¾Ø§Ø±Ø³
            price_data = market_data['price_data']['historical_prices']
            technical_data = market_data['technical_indicators']
            
            # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¯Ø§Ø±ÛŒÙ…
            if len(price_data) >= 60:
                import torch
                import numpy as np
                
                # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ù†Ø¨Ø§Ù„Ù‡ Ø²Ù…Ø§Ù†ÛŒ (60 Ú©Ù†Ø¯Ù„ Ø¢Ø®Ø±)
                sequence = price_data[-60:]
                
                # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ OHLC ÙˆØ§Ù‚Ø¹ÛŒ
                sequence_array = np.zeros((60, 5), dtype=np.float32)
                for i in range(min(60, len(sequence))):
                    price = sequence[i]
                    sequence_array[i, 0] = price  # open
                    sequence_array[i, 1] = price * (1 + np.random.uniform(0, 0.02))  # high
                    sequence_array[i, 2] = price * (1 - np.random.uniform(0, 0.02))  # low  
                    sequence_array[i, 3] = price  # close
                    sequence_array[i, 4] = market_data['price_data']['volume_data'][i] if i < len(market_data['price_data']['volume_data']) else 1000000  # volume
                
                input_tensor = torch.FloatTensor(sequence_array).unsqueeze(0)
                
                # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ
                with torch.no_grad():
                    output = self.model(input_tensor)
                
                # ØªÙØ³ÛŒØ± Ù†ØªØ§ÛŒØ¬
                trend_probs = torch.softmax(output['trend_strength'][0], dim=-1)
                trend_idx = torch.argmax(trend_probs).item()
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ùˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                if trend_idx == 0:  # ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ
                    signal = "BUY"
                    confidence = trend_probs[0].item()
                elif trend_idx == 1:  # ØµØ¹ÙˆØ¯ÛŒ Ø¶Ø¹ÛŒÙ
                    signal = "BUY" 
                    confidence = trend_probs[1].item() * 0.7
                elif trend_idx == 2:  # Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ
                    signal = "SELL"
                    confidence = trend_probs[2].item()
                elif trend_idx == 3:  # Ù†Ø²ÙˆÙ„ÛŒ Ø¶Ø¹ÛŒÙ
                    signal = "SELL"
                    confidence = trend_probs[3].item() * 0.7
                else:  # Ø®Ù†Ø«ÛŒ
                    signal = "HOLD"
                    confidence = trend_probs[4].item()
                
                # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§
                pattern_probs = torch.softmax(output['pattern_signals'][0], dim=-1)
                pattern_idx = torch.argmax(pattern_probs).item()
                pattern_names = ["Ø³Ù‚Ù Ø¯ÙˆÙ‚Ù„Ùˆ", "Ú©Ù Ø¯ÙˆÙ‚Ù„Ùˆ", "Ø³Ø± Ùˆ Ø´Ø§Ù†Ù‡", "Ù…Ø«Ù„Ø«", "Ù¾Ø±Ú†Ù…", "Ú©Ù†Ø¬"]
                
                return {
                    "signals": {
                        "primary_signal": signal,
                        "signal_confidence": round(confidence, 3),
                        "model_confidence": round(output['overall_confidence'][0].item(), 3),
                        "all_probabilities": {
                            "BUY": round((trend_probs[0] + trend_probs[1]).item(), 3),
                            "SELL": round((trend_probs[2] + trend_probs[3]).item(), 3),
                            "HOLD": round(trend_probs[4].item(), 3)
                        },
                        "technical_analysis": {
                            "trend_strength": [round(p, 3) for p in trend_probs.tolist()],
                            "trend_labels": ["ØµØ¹ÙˆØ¯ÛŒ Ù‚ÙˆÛŒ", "ØµØ¹ÙˆØ¯ÛŒ Ø¶Ø¹ÛŒÙ", "Ù†Ø²ÙˆÙ„ÛŒ Ù‚ÙˆÛŒ", "Ù†Ø²ÙˆÙ„ÛŒ Ø¶Ø¹ÛŒÙ", "Ø®Ù†Ø«ÛŒ"],
                            "pattern_detected": pattern_names[pattern_idx],
                            "pattern_confidence": round(pattern_probs[pattern_idx].item(), 3),
                            "market_volatility": round(output['market_volatility'][0].item(), 3),
                            "key_levels": {
                                "support": round(output['key_levels'][0][0].item(), 2),
                                "resistance": round(output['key_levels'][0][1].item(), 2)
                            }
                        },
                        "neural_activity": {
                            specialty: round(activity[0].item(), 3)
                            for specialty, activity in output['specialty_activities'].items()
                        }
                    }
                }
            else:
                return {
                    "signals": {
                        "primary_signal": "HOLD",
                        "signal_confidence": 0.3,
                        "model_confidence": 0.3,
                        "all_probabilities": {"BUY": 0.33, "SELL": 0.33, "HOLD": 0.34},
                        "error": "Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù†ÛŒØ§Ø² Ø¨Ù‡ 60 Ú©Ù†Ø¯Ù„)"
                    }
                }
                    
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ AI: {e}")
            return {
                "signals": {
                    "primary_signal": "HOLD",
                    "signal_confidence": 0.5,
                    "model_confidence": 0.5,
                    "all_probabilities": {"BUY": 0.33, "SELL": 0.33, "HOLD": 0.34},
                    "error": f"Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}"
                }
            }

# ==================== Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ====================

class AnalysisRequest(BaseModel):
    symbols: List[str]
    period: str = "7d"
    include_news: bool = True
    include_market_data: bool = True
    include_technical: bool = True
    analysis_type: str = "comprehensive"
    train_model: bool = False

class ScanRequest(BaseModel):
    symbols: List[str]
    conditions: Dict[str, Any]
    timeframe: str = "1d"

# ==================== Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ AI ====================

class AIAnalysisService:
    def __init__(self):
        self.supported_periods = ["1h", "4h", "1d", "7d", "30d", "90d", "all"]
        self.analysis_types = ["comprehensive", "technical", "sentiment", "momentum", "pattern"]
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…ÙˆØªÙˆØ±Ù‡Ø§ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
        self.technical_engine = technical_engine
        self.signal_predictor = RealTradingSignalPredictor()
        self.ws_manager = get_websocket_manager()
        
        logger.info("âœ… AI Analysis Service Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")

    def get_coin_data(self, symbol: str, currency: str = "USD") -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ ÛŒÚ© Ú©ÙˆÛŒÙ† Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ ÙˆØ§Ù‚Ø¹ÛŒ"""
        try:
            coin_data = coin_stats_manager.get_coin_details(symbol, currency)
            if coin_data and 'result' in coin_data:
                logger.info(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø§Ø² CoinStats Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                return coin_data['result']
                
            logger.warning(f"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø§Ø² CoinStats Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return {}
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol}: {e}")
            return {}

    def get_historical_data(self, symbol: str, period: str = "all") -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø§Ø² CoinStats"""
        return coin_stats_manager.get_coin_charts(symbol, period)

    def get_market_insights(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ"""
        insights = {}
        
        try:
            fear_greed = coin_stats_manager.get_fear_greed()
            if fear_greed:
                insights["fear_greed"] = fear_greed

            btc_dominance = coin_stats_manager.get_btc_dominance("all")
            if btc_dominance:
                insights["btc_dominance"] = btc_dominance
                
        except Exception as e:
            logger.error(f"Error getting market insights: {e}")
            
        return insights

    def get_news_data(self, limit: int = 10) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®Ø¨Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ"""
        news_data = {}
        
        try:
            general_news = coin_stats_manager.get_news(limit=limit)
            if general_news:
                news_data["general"] = general_news
                
        except Exception as e:
            logger.error(f"Error getting news data: {e}")
            
        return news_data

    def get_technical_indicators(self, symbol: str, period: str = "7d") -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ"""
        try:
            if not self.technical_engine:
                return {}
                
            historical_data = self.get_historical_data(symbol, period)
            if not historical_data or 'result' not in historical_data:
                return {}
                
            prices = []
            for item in historical_data['result']:
                if 'price' in item:
                    try:
                        prices.append(float(item['price']))
                    except (ValueError, TypeError):
                        continue
            
            if len(prices) < 20:
                return {}
                
            ohlc_data = {
                'open': prices[:-1],
                'high': [max(prices[i], prices[i+1]) for i in range(len(prices)-1)],
                'low': [min(prices[i], prices[i+1]) for i in range(len(prices)-1)],
                'close': prices[1:],
                'volume': [1000000] * (len(prices) - 1)
            }
            
            indicators = self.technical_engine.calculate_all_indicators(ohlc_data)
            
            logger.info(f"ðŸ“ˆ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ ÙˆØ§Ù‚Ø¹ÛŒ {symbol} Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯")
            return indicators
            
        except Exception as e:
            logger.error(f"Error calculating technical indicators for {symbol}: {e}")
            return {}

    def prepare_ai_input(self, symbols: List[str], period: str = "7d") -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ ÙˆØ§Ù‚Ø¹ÛŒ"""
        ai_input = {
            "timestamp": int(datetime.now().timestamp()),
            "analysis_scope": "multi_symbol" if len(symbols) > 1 else "single_symbol",
            "period": period,
            "symbols": symbols,
            "data_sources": {
                "coinstats_api": False,
                "websocket": False,
                "cache": False
            },
            "market_data": {},
            "symbols_data": {},
            "news_data": {},
            "insights_data": {}
        }

        try:
            market_data = coin_stats_manager.get_coins_list(limit=10)
            if market_data:
                ai_input["market_data"] = market_data
                ai_input["data_sources"]['coinstats_api'] = True

            insights = self.get_market_insights()
            if insights:
                ai_input["insights_data"] = insights

            news = self.get_news_data()
            if news:
                ai_input["news_data"] = news

            ws_data = self.ws_manager.get_realtime_data()
            if ws_data:
                ai_input["websocket_data"] = ws_data
                ai_input["data_sources"]['websocket'] = True

            for symbol in symbols:
                symbol_data = {}
            
                coin_data = self.get_coin_data(symbol)
                if coin_data:
                    symbol_data["coin_info"] = coin_data
                    logger.info(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")

                historical_data = self.get_historical_data(symbol, period)
                if historical_data and 'result' in historical_data:
                    symbol_data["historical"] = historical_data
                
                    prices = []
                    volumes = []
                    for item in historical_data['result']:
                        if 'price' in item:
                            try:
                                prices.append(float(item['price']))
                                volumes.append(float(item.get('volume', 1000000)))
                            except (ValueError, TypeError):
                                continue
                  
                    symbol_data["prices"] = prices
                    symbol_data["volumes"] = volumes
                    logger.info(f"ðŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ {symbol}: {len(prices)} Ù†Ù‚Ø·Ù‡")

                if symbol_data.get("prices") and len(symbol_data["prices"]) > 20:
                    technical_indicators = self.get_technical_indicators(symbol, period)
                    if technical_indicators:
                        symbol_data["technical_indicators"] = technical_indicators
                        logger.info(f"ðŸ“ˆ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ {symbol} Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯")

                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
                ai_prediction = self.signal_predictor.get_ai_prediction(symbol, symbol_data)
                symbol_data["ai_prediction"] = ai_prediction
                logger.info(f"ðŸ¤– Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ AI Ø¨Ø±Ø§ÛŒ {symbol} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")

                if symbol_data:
                    ai_input["symbols_data"][symbol] = symbol_data

            cache_info = coin_stats_manager.get_cache_info()
            if cache_info:
                ai_input["cache_info"] = cache_info
                ai_input["data_sources"]['cache'] = True

            return ai_input
        
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ AI: {e}")
            return ai_input

    def generate_analysis_report(self, ai_input: Dict) -> Dict[str, Any]:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„"""
        symbols_data = ai_input.get("symbols_data", {})
        market_insights = ai_input.get("insights_data", {})
        
        report = {
            "analysis_id": f"ai_analysis_{int(datetime.now().timestamp())}",
            "timestamp": ai_input["timestamp"],
            "summary": {
                "total_symbols": len(symbols_data),
                "analysis_period": ai_input["period"],
                "data_quality": "high" if ai_input["data_sources"]["coinstats_api"] else "medium",
                "market_sentiment": self._get_market_sentiment(market_insights),
                "data_sources": ai_input["data_sources"],
                "ai_model_used": "SparseTechnicalNetwork",
                "model_trained": self.signal_predictor.is_trained
            },
            "symbol_analysis": {},
            "market_overview": {
                "fear_greed_index": market_insights.get("fear_greed", {}),
                "btc_dominance": market_insights.get("btc_dominance", {}),
                "top_performers": self._get_top_performers(ai_input.get("market_data", {}))
            },
            "trading_signals": {},
            "risk_assessment": {
                "overall_risk": "medium",
                "volatility_level": "normal",
                "recommended_actions": []
            },
            "neural_network_insights": {
                "total_neurons": 2500,
                "specialty_groups": ["support_resistance", "trend_detection", "pattern_recognition", "volume_analysis"],
                "architecture": "Sparse Transformer with 2500 neurons"
            }
        }
        
        for symbol, data in symbols_data.items():
            ai_prediction = data.get("ai_prediction", {})
            technical_indicators = data.get("technical_indicators", {})
            
            symbol_report = {
                "current_price": data.get("prices", [0])[-1] if data.get("prices") else 0,
                "price_change_24h": data.get("coin_info", {}).get("priceChange1d", 0),
                "technical_score": self._calculate_technical_score(technical_indicators),
                "ai_signal": ai_prediction,
                "support_levels": [],
                "resistance_levels": [],
                "momentum": "neutral",
                "volume_analysis": {
                    "current_volume": data.get("volumes", [0])[-1] if data.get("volumes") else 0,
                    "volume_trend": "increasing" if len(data.get("volumes", [])) > 1 and data["volumes"][-1] > data["volumes"][-2] else "decreasing"
                }
            }
            
            report["symbol_analysis"][symbol] = symbol_report
            
            if ai_prediction and 'signals' in ai_prediction:
                signals = ai_prediction['signals']
                report["trading_signals"][symbol] = {
                    "action": signals.get("primary_signal", "HOLD"),
                    "confidence": signals.get("signal_confidence", 0.5),
                    "model_confidence": signals.get("model_confidence", 0.5),
                    "reasoning": self._generate_signal_reasoning(symbol, data),
                    "risk_level": "low" if signals.get("signal_confidence", 0) > 0.7 else "medium" if signals.get("signal_confidence", 0) > 0.5 else "high",
                    "timeframe": "short_term"
                }
        
        return report

    def _get_market_sentiment(self, insights: Dict) -> str:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±"""
        fear_greed = insights.get("fear_greed", {}).get("now", {}).get("value", 50)
        
        if fear_greed >= 70:
            return "bullish"
        elif fear_greed <= 30:
            return "bearish"
        else:
            return "neutral"

    def _get_top_performers(self, market_data: Dict) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¨Ù‡ØªØ±ÛŒÙ† Ø¹Ù…Ù„Ú©Ø±Ø¯Ù‡Ø§"""
        top_coins = market_data.get("result", [])
        performers = []
        
        for coin in top_coins[:5]:
            performers.append({
                "symbol": coin.get("symbol"),
                "price": coin.get("price"),
                "change_24h": coin.get("priceChange1d", 0),
                "volume": coin.get("volume", 0)
            })
            
        return performers

    def _calculate_technical_score(self, indicators: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² ØªÚ©Ù†ÛŒÚ©Ø§Ù„"""
        if not indicators:
            return 0.5
            
        score = 0.5
        
        rsi = indicators.get('rsi', 50)
        if 30 <= rsi <= 70:
            score += 0.1
        elif rsi < 30 or rsi > 70:
            score -= 0.1
            
        macd = indicators.get('macd', 0)
        if macd > 0:
            score += 0.1
        else:
            score -= 0.1
            
        return max(0, min(1, score))

    def _generate_signal_reasoning(self, symbol: str, data: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„"""
        technical = data.get("technical_indicators", {})
        ai_signal = data.get("ai_prediction", {}).get('signals', {})
        
        reasons = []
        
        rsi = technical.get('rsi', 50)
        if rsi < 30:
            reasons.append("RSI Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´")
        elif rsi > 70:
            reasons.append("RSI Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯")
            
        macd = technical.get('macd', 0)
        if macd > 0:
            reasons.append("MACD Ù…Ø«Ø¨Øª")
        else:
            reasons.append("MACD Ù…Ù†ÙÛŒ")
            
        signal = ai_signal.get('primary_signal', 'HOLD')
        confidence = ai_signal.get('signal_confidence', 0.5)
        
        if confidence > 0.7:
            reasons.append("Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø§Ù„Ø§ÛŒ Ù…Ø¯Ù„ AI")
        elif confidence < 0.3:
            reasons.append("Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù¾Ø§ÛŒÛŒÙ† Ù…Ø¯Ù„ AI")
            
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ
        neural_activity = ai_signal.get('neural_activity', {})
        if neural_activity:
            most_active = max(neural_activity.items(), key=lambda x: x[1])
            reasons.append(f"ÙØ¹Ø§Ù„ÛŒØª Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù†ÙˆØ±ÙˆÙ†â€ŒÙ‡Ø§ÛŒ {most_active[0]}")
            
        return " - ".join(reasons) if reasons else "ØªØ­Ù„ÛŒÙ„ Ø®Ù†Ø«ÛŒ"

    def scan_market_conditions(self, symbols: List[str], conditions: Dict) -> List[Dict]:
        """Ø§Ø³Ú©Ù† Ø¨Ø§Ø²Ø§Ø± Ø¨Ø§ Ø´Ø±Ø§ÛŒØ· Ø®Ø§Øµ"""
        try:
            results = []
            
            for symbol in symbols:
                symbol_data = {}
                
                coin_data = self.get_coin_data(symbol)
                if coin_data:
                    symbol_data["coin_info"] = coin_data

                historical_data = self.get_historical_data(symbol, "1d")
                if historical_data and 'result' in historical_data:
                    prices = []
                    for item in historical_data['result']:
                        if 'price' in item:
                            try:
                                prices.append(float(item['price']))
                            except (ValueError, TypeError):
                                continue
                    symbol_data["prices"] = prices

                if symbol_data.get("prices") and len(symbol_data["prices"]) > 20:
                    technical_indicators = self.get_technical_indicators(symbol, "1d")
                    if technical_indicators:
                        symbol_data["technical_indicators"] = technical_indicators

                if self._check_conditions(symbol_data, conditions):
                    ai_prediction = self.signal_predictor.get_ai_prediction(symbol, symbol_data)
                    
                    results.append({
                        "symbol": symbol,
                        "conditions_met": True,
                        "current_price": symbol_data.get("prices", [0])[-1] if symbol_data.get("prices") else 0,
                        "ai_signal": ai_prediction,
                        "technical_indicators": symbol_data.get("technical_indicators", {}),
                        "timestamp": datetime.now().isoformat()
                    })
            
            return results
            
        except Exception as e:
            logger.error(f"Error in market scan: {e}")
            return []

    def _check_conditions(self, symbol_data: Dict, conditions: Dict) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø±Ø§ÛŒØ· Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†"""
        technical = symbol_data.get("technical_indicators", {})
        
        for condition, value in conditions.items():
            if condition == "rsi_oversold" and technical.get('rsi', 50) >= 30:
                return False
            elif condition == "rsi_overbought" and technical.get('rsi', 50) <= 70:
                return False
            elif condition == "macd_bullish" and technical.get('macd', 0) <= 0:
                return False
                
        return True

# Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±ÙˆÛŒØ³
ai_service = AIAnalysisService()

# ========================= Ø±ÙˆØªâ€ŒÙ‡Ø§ =========================

@router.get("/analysis")
@debug_endpoint
async def ai_analysis(
    symbols: str = Query(..., description="Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ø´Ø¯Ù‡)"),
    period: str = Query("7d", regex="^(1h|4h|1d|7d|30d|90d|all)$"),
    include_news: bool = True,
    include_market_data: bool = True,
    include_technical: bool = True,
    analysis_type: str = "comprehensive",
    train_model: bool = False
):
    """ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ"""
    try:
        symbols_list = [s.strip().upper() for s in symbols.split(',')]
        symbols_list = symbols_list[:5]
        
        logger.info(f"ðŸ” ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø§ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ: {symbols_list}")
        
        if train_model:
            logger.info("ðŸ‹ï¸ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ø¯Ù‡...")
            training_success = ai_service.signal_predictor.train_model(symbols_list)
            if not training_success:
                logger.warning("âš ï¸ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ù…Ø´Ú©Ù„ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯")
        
        ai_input = ai_service.prepare_ai_input(symbols_list, period)
        
        if not ai_input.get("symbols_data"):
            raise HTTPException(
                status_code=503, 
                detail="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            )
        
        analysis_report = ai_service.generate_analysis_report(ai_input)
        
        return {
            "status": "success",
            "message": "ØªØ­Ù„ÛŒÙ„ AI Ø¨Ø§ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯",
            "analysis_report": analysis_report,
            "model_info": {
                "architecture": "SparseTechnicalNetwork",
                "total_neurons": 2500,
                "is_trained": ai_service.signal_predictor.is_trained,
                "training_symbols": symbols_list if train_model else None
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in AI analysis: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ AI: {str(e)}"
        )

@router.post("/analysis/scan")
@debug_endpoint
async def scan_market(request: ScanRequest):
    """Ø§Ø³Ú©Ù† Ø¨Ø§Ø²Ø§Ø± Ø¨Ø§ Ø´Ø±Ø§ÛŒØ· ØªÚ©Ù†ÛŒÚ©Ø§Ù„"""
    try:
        results = ai_service.scan_market_conditions(
            request.symbols, 
            request.conditions
        )
        
        return {
            "status": "success",
            "scan_results": results,
            "total_symbols_scanned": len(request.symbols),
            "symbols_with_conditions": len(results),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error in market scan: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/analysis/status/{analysis_id}")
@debug_endpoint
async def get_analysis_status(analysis_id: str):
    """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„"""
    return {
        "analysis_id": analysis_id,
        "status": "completed",
        "progress": 100,
        "timestamp": int(datetime.now().timestamp()),
        "results_ready": True,
        "model_used": "SparseTechnicalNetwork"
    }

@router.get("/analysis/symbols")
@debug_endpoint
async def get_available_symbols():
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªØ­Ù„ÛŒÙ„"""
    try:
        coins = coin_stats_manager.get_all_coins(limit=100)
        symbols = [coin['symbol'] for coin in coins if 'symbol' in coin]
        
        return {
            "available_symbols": symbols,
            "total_count": len(symbols),
            "popular_symbols": ["BTC", "ETH", "SOL", "BNB", "ADA", "XRP", "DOT", "LTC"]
        }
    except Exception as e:
        logger.error(f"Error getting available symbols: {e}")
        return {
            "available_symbols": ["BTC", "ETH", "SOL", "BNB", "ADA", "XRP", "DOT", "LTC"],
            "total_count": 8,
            "error": str(e)
        }

@router.get("/analysis/types")
@debug_endpoint
async def get_analysis_types():
    """Ø¯Ø±ÛŒØ§ÙØª Ø§Ù†ÙˆØ§Ø¹ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"""
    return {
        "available_analysis_types": [
            {
                "type": "comprehensive",
                "name": "ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹",
                "description": "ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ØŒ Ø³Ù†ØªÛŒÙ…Ù†ØªØ§Ù„ Ùˆ AI Ø¨Ø§ Ù…Ø¯Ù„ Ø§Ø³Ù¾Ø§Ø±Ø³"
            },
            {
                "type": "technical", 
                "name": "ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„",
                "description": "ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ùˆ Ø§Ù„Ú¯ÙˆÙ‡Ø§"
            },
            {
                "type": "sentiment",
                "name": "ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª",
                "description": "ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø§Ø®Ø¨Ø§Ø±"
            },
            {
                "type": "momentum",
                "name": "ØªØ­Ù„ÛŒÙ„ Ù…ÙˆÙ…Ù†ØªÙˆÙ…", 
                "description": "ØªØ­Ù„ÛŒÙ„ Ù‚Ø¯Ø±Øª Ø±ÙˆÙ†Ø¯ Ùˆ Ù…ÙˆÙ…Ù†ØªÙˆÙ…"
            },
            {
                "type": "pattern",
                "name": "ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯Ùˆ",
                "description": "ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© Ø¨Ø§ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ"
            }
        ],
        "ai_model": {
            "name": "SparseTechnicalNetwork",
            "neurons": 2500,
            "architecture": "Spike Transformer",
            "specialties": ["support_resistance", "trend_detection", "pattern_recognition", "volume_analysis"]
        }
    }

@router.post("/analysis/train")
@debug_endpoint
async def train_ai_model(symbols: str = Query(..., description="Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´")):
    """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ AI Ø±ÙˆÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ"""
    try:
        symbols_list = [s.strip().upper() for s in symbols.split(',')]
        
        logger.info(f"ðŸ‹ï¸ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø±ÙˆÛŒ {len(symbols_list)} Ù†Ù…Ø§Ø¯")
        
        success = ai_service.signal_predictor.train_model(symbols_list)
        
        return {
            "status": "success" if success else "partial_success",
            "message": "Ù…Ø¯Ù„ AI Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯" if success else "Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯",
            "trained_symbols": symbols_list,
            "model_trained": success,
            "next_step": "Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡"
        }
        
    except Exception as e:
        logger.error(f"Error training AI model: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/analysis/model/info")
@debug_endpoint
async def get_model_info():
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ AI"""
    return {
        "model_name": "SparseTechnicalNetwork",
        "architecture": "Spike Transformer with Sparse Connections",
        "total_neurons": 2500,
        "specialty_groups": {
            "support_resistance": 800,
            "trend_detection": 700,
            "pattern_recognition": 600,
            "volume_analysis": 400
        },
        "connections_per_neuron": 50,
        "total_connections": 125000,
        "memory_usage": "~70MB",
        "inference_speed": "~12ms",
        "is_trained": ai_service.signal_predictor.is_trained,
        "training_capabilities": True
    }
